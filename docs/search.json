[
  {
    "objectID": "rethinkingfirm.html",
    "href": "rethinkingfirm.html",
    "title": "Rethinking the Firm",
    "section": "",
    "text": "Chapter 2: Rethinking the Firm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rethinking the Firm</span>"
    ]
  },
  {
    "objectID": "rethinkingfirm.html#chapter-2-rethinking-the-firm",
    "href": "rethinkingfirm.html#chapter-2-rethinking-the-firm",
    "title": "Rethinking the Firm",
    "section": "",
    "text": "Reference: Chapter 2 from lansiti and Karim (2020) focuses on how AI reshapes the boundaries, structure, and strategy of firms\n\n\nWhat Does It Means to Become an AI Company?\n\nBecoming an AI company is not just about adopting new tools—it’s about transforming how your organization thinks, decides, and operates.\nAI-driven firms require deep organizational transformation: mission, data architecture, governance, product-centric agility.\nSuccess depends not just on adopting AI tools, but on embedding AI into the firm’s strategy and operating model.\nCompanies that treat AI as a bolt-on tool (just automation or one-off projects) miss the real value.\nCompanies that use AI as a strategic driver reshape their boundaries, competitive dynamics, and industry positioning.\n\n\n\nBecoming an AI Company\n\nAI isn’t just a feature; it reshapes how decisions are made, and work is executed. It requires moving beyond basic automation to a new AI-driven operating model.\nFirms must shift from human-centric to algorithm-centric workflows. This shift demands reimagining roles, processes, and accountability.\nAI success is powered by data-driven thinking, agility, and a culture of continuous experimentation. Organizations must encourage learning over certainty, and evidence over intuition.\nBecoming an AI company involves organizational change: new teams, roles, and cross-functional collaboration. Leadership must foster trust in algorithmic decision-making and promote transparency.\n\n\n\nAI Readiness\n\nAI readiness refers to an organization’s ability to successfully adopt, implement, and scale artificial intelligence technologies to enhance operations, decision-making, and value creation.\n\nDigital Infrastructure: Having the cloud platforms, computing power, and integration tools to support AI systems.\nData Maturity: Accessible, high-quality, well-organized data pipelines that AI systems can learn from.\nTalent & Culture: Teams with AI/ML skills and a culture that supports experimentation, agility, and data-driven decision-making.\nLeadership Commitment: Executives who understand AI’s strategic importance and invest accordingly.\nExperimentation & Learning: A mindset and capability to test, measure, and refine AI applications over time.\n\nA high level of AI readiness means a firm is not just equipped with technology—but aligned across strategy, talent, and process to gain real value from AI.\n\n\n\nAI Readiness and the 350 Firm Study\n\nThe 350 Firm Study is a large-scale analysis of over 350 organizations that measured their AI maturity—based on digital infrastructure, data integration, analytics use, and AI deployment—and demonstrated a strong positive correlation between higher AI maturity and superior financial performance.\nIncluded firms from sectors like manufacturing, consumer goods, financial services, and retail.\n\nUsed an AI maturity index built from about 40 business processes.\nTracked progression from siloed data to integrated AI factories.\nShowed that leaders in AI maturity significantly outperformed laggards in metrics like gross margin, net income, and earnings before taxes (e.g., top firms had 55% gross margin vs. 37% for laggards).\n\n\n\n\nAI Readiness Index (350 Firms Study) Key Factors for AI Maturity\n\nDigital infrastructure refers to the scalable, cloud-based systems and modern IT architecture needed to support real-time data processing and AI deployment across the enterprise.\nData accessibility and quality involves integrating siloed data into centralized platforms with strong governance to ensure the data is usable, secure, and valuable for AI-driven decision-making.\nTalent and leadership alignment means recruiting and empowering cross-functional teams—including technical, strategic, and governance leaders—to drive transformation with clarity, conviction, and collaboration.\nExperimentation capability refers to the organization’s ability to test and iterate AI applications quickly through agile methods, empowered by modular architectures and a culture that embraces continuous learning and adaptation.\n\n\n\nOperating Models in the Age of AI\n\nStrategy, without a consistent operating model, is where the rubber meets the air. —Somewhat famous Italian proverb\n\n\n\nTraditional firms are built around physical assets & labor.\nAI-driven firms are built around data, algorithms, and digital platforms.\nThis shift transforms how firms scale, diversify, and learn.\n\n\n\nTraditional Vs AI Driven Operating Model\n\nTraditional Operating Model\nOptimized for efficiency in production & coordination.\nKey features:\n\nPhysical supply chains\nHuman decision-making\nGrowth requires proportional increases in people/assets\n\nAI-Driven Operating Model\nCore = AI Factory: data → algorithms → learning → action.\nOperations embedded into digital platforms.\nGrowth comes from:\n\nUser interactions generating data\nAutomated decisions at scale\nAlgorithms continuously improving\n\n\n\n\nScale and Scope Economies\n\nScale Economies: Cost advantages that companies gain as they increase production, often enhanced by AI automation.\nScale Without Mass\n\nTraditional: scaling = more factories, workers, capital.\nAI-driven: scaling = more data & users with minimal costs.\n\n\n\n\nExample: Ant Financial → handles millions of loans without adding staff.\nScope Economies: Efficiencies formed by variety (offering multiple products or services), where AI can help leverage shared data and infrastructure.\nScope Without Complexity\n\nTraditional: diversification adds costly coordination layers.\nAI-driven: reuse same data + algorithms + infrastructure across domains.\n\n\n\n\nExample: Amazon uses AI for retail, AWS, logistics, streaming.\n\n\n\nBusiness Model and Operating Model\n\n\n\nFigure 2-1\n\n\n\nAdapted from Figure 2-1, “The AI factory,” in Iansiti & Lakhani (2020, p. 38)\n\n\n\nContinuous Learning Model\n\nThe learning function of an operating model is essential to driving continuous improvement, increasing operating performance over time, and developing new products and services.\n\nRun frequent A/B tests on products, pricing, or interfaces.\nUse controlled trials to evaluate new algorithms, workflows, or customer journeys.\nBuild feedback loops that connect experimentation results directly back into product design and decision-making.\n\nEach interaction → data → algorithm refinement.\nCreates positive feedback loops:\n\nMore users → more data → better service → more users.\n\nContinuous experimentation enables firms to learn quickly, adapt strategies, and improve performance in an AI-driven world. Shifts decision-making from intuition-driven to evidence-based.\n\n\n\nStrategic Implications\n\nContinuous experimentation enables firms to learn quickly, adapt strategies, and improve performance in an AI-driven world. Shifts decision-making from intuition-driven to evidence-based.\nAgility as a Competitive Advantage\n\nFirms can pivot quickly as markets, customer preferences, and technologies change.\n\nData-Informed Strategy\n\nStrategic choices are validated with real-world results, not assumptions.\n\nScalable Learning Loops\n\nExperimentation feeds back into product design, operations, and business models.\n\nReduced Risk of Large Failures\n\nSmall, fast experiments minimize costly mistakes while accelerating innovation.\n\nCultural Shift\n\nLeaders and teams adopt a mindset where “failing fast” is acceptable if it creates learning.\n\n\n\n\nRemoving the Human Bottleneck\n\nHuman decision-making is often too slow, limited in scale, and inconsistent for the speed and complexity of digital environments\nAI removes bottlenecks caused by human limits to facilitate speed, scale, and consistency.\nExamples:\n\nAlgorithmic trading in finance.\nRecommendation engines in retail.\nFraud detection\nDynamic pricing\n\nImplication: Organizations that automate core processes can achieve greater efficiency, adaptability, and competitive advantage in AI-driven markets.\n\n\n\nThe Irresistible Digital Bicycle\n\nWe see ourselves more akin to an Apple, a Tesla, or a Nest or a GoPro—where it’s a consumer product that has a foundation of sexy hardware technology and sexy software technology. —John Foley, founder and CEO, Peloton\n\n\n\nAnalogy: Just as the bicycle amplified human physical power, AI amplifies human cognitive power.\nAmplification Effect: AI enables people to process vast amounts of data, make faster decisions, and extend their problem-solving capacity beyond natural limits.\nAccessibility: Like bicycles, AI tools are becoming widely available and affordable, not just for large firms but also startups and individuals.\nTransformative Impact: AI doesn’t just make existing tasks more efficient—it creates new possibilities for innovation, strategy, and value creation.\n\n\n\nTacit vs. Strategic Use of AI\n\nTactically means using AI for specific, short-term goals—often focused on operational improvements. It’s about applying AI as a tool to solve clearly defined problems like automating customer service, improving demand forecasting, or streamlining data entry. Tactical use tends to be incremental, often siloed within departments, and relatively easy to implement without changing the organization’s core strategy.\n\n\n\nStrategically, on the other hand, means adopting AI in a way that reshapes the organization’s long-term direction, business model, or competitive advantage. Strategic adoption involves aligning AI with the company’s mission, investing in infrastructure and talent, rethinking how value is created and delivered, and often reimagining entire workflows or offerings. It’s about integrating AI into the organization’s DNA.\nTactical AI is about doing things better, while strategic AI is about doing better things.\n\n\n\nTacit vs. Strategic Use of AI\n\nTacit Use of AI (Incremental, Operational)\n\nAI applied to narrow tasks like automation, simple analytics, local optimizations.\nExample: Using AI to speed up loan approvals at a bank, or to forecast inventory in retail.\nValue is immediate but limited; it doesn’t fundamentally change the business model.\nAI as a “tool”, not a transformation.\n\nStrategic Use of AI (Transformational, Systemic)\n\nAI becomes the core operating model, shaping how the company creates and captures value.\nExample: Microsoft embedding AI into every product and workflow, Fidelity reorganizing around data + agile product teams.\nValue is compounding, as AI drives new platforms, ecosystems, and industry leadership.\nAI as the foundation of a new enterprise architecture.\n\nTacit vs. Strategic Use of AI\n\nTacit Use of AI (Incremental, Operational)\n\nAI applied to narrow tasks like automation, simple analytics, local optimizations.\nExample: Using AI to speed up loan approvals at a bank, or to forecast inventory in retail.\nValue is immediate but limited; it doesn’t fundamentally change the business model.\nAI as a “tool”, not a transformation.\n\nStrategic Use of AI (Transformational, Systemic)\n\nAI becomes the core operating model, shaping how the company creates and captures value.\nExample: Microsoft embedding AI into every product and workflow, Fidelity reorganizing around data + agile product teams.\nValue is compounding, as AI drives new platforms, ecosystems, and industry leadership.\nAI as the foundation of a new enterprise architecture.\n\n\n\n\n\nDiscussion Questions\n\nCan every company become an AI company, or are some better suited than others?\n\n\n\nWhat organizational or cultural barriers might prevent a company from trusting algorithmic decisions?\n\n\n\nValue Creation Capture vs Value Delivery\n\n\n\nFigure 2-2\n\n\n\nAdapted from Figure 2-2, “Value creation and capture versus value delivery,” in Iansiti & Lakhani (2020, p. 39)\n\n\n\nWhat Makes A High Performer?\n\nFirms excelling in the areas above saw stronger growth and profitability.\nAdaptability and learning were central advantages.\n\n\n\nWhich factor (infrastructure, data, talent, experimentation) do you think is hardest to build? Why?\nWhat metrics or indicators might you track to assess a company’s AI readiness?\n\n\n\nImplementation Scenarios for AI in the Enterprise\n\nAutomation: Streamlining repetitive tasks and decisions.\nPersonalization: Tailoring customer experiences at scale.\nForecasting & Optimization: Enhancing planning with predictive analytics.\nRecommendation Systems: Driving engagement and sales through AI-curated suggestions.\n\n\n\nWhich AI use case (automation, personalization, forecasting, recommendation) would bring the most value in a retail company? What about healthcare?\nHow might implementing AI in one area (e.g., personalization) impact customer trust or privacy concerns?\n\n\n\nThe World’s Toughest AI Business\n\nHealthcare is described as the most challenging arena for AI adoption.\n\nComplexity of Data: Medical data is highly fragmented (across hospitals, insurers, labs), sensitive (privacy laws like HIPAA), and often unstructured (clinical notes, images).\nHigh Stakes: Mistakes carry life-or-death consequences, unlike other industries where errors may just affect profits.\nRegulatory Environment: Strict oversight makes experimentation, scaling, and deployment much slower than in other industries.\nTrust & Adoption: Doctors, patients, and regulators must trust AI recommendations before adoption; building this trust takes time.\nStrategic Insight: Success in healthcare AI requires deep integration of data, multidisciplinary expertise, and careful governance.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rethinking the Firm</span>"
    ]
  },
  {
    "objectID": "genAI.html",
    "href": "genAI.html",
    "title": "GenAI",
    "section": "",
    "text": "Chapter 3: Multimodal Generative AI",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GenAI</span>"
    ]
  },
  {
    "objectID": "genAI.html#chapter-3-multimodal-generative-ai",
    "href": "genAI.html#chapter-3-multimodal-generative-ai",
    "title": "GenAI",
    "section": "",
    "text": "Reference: Together, Chapter 1 and 3 of Multimodal Generative AI present an overview of the foundations, architectures, and ethical considerations of multimodal generative systems, and examine how emerging multimodal large language models extend these capabilities with advanced cross-modal reasoning and generation—while grappling with challenges in complexity, data integration, and responsible deployment.\n\n\nGenerative AI\n\nGenerative AI refers to a type of AI that creates new content (text, audio, images) based on patterns learned from training data. It contrasts with predictive AI, which forecasts outcomes from historical data.\nSome Examples:\n\nChatGPT – conversational text generation\nCodex / GitHub Copilot – code generation and completion\nDALL·E – image generation from text prompts\nPerplexity AI – conversational search + generative synthesis\n\n\n\n\nWhat is Generative AI?\n\n\nGenerative AI represents a Paradigm Shift\n\n\nLM vs LLM\n\nFrom Generative AI to LLMs\n\nGenerative AI is the broad field of AI that can create new content (text, images, audio, video, code).\n\n\n\n\nA Language Model (LM) is a core branch of GenAI focused on predicting and generating text based on patterns in language data.\n\nLM are designed to predict the likelihood of words or phrases in a sentence.\nIts main tasks include generating text, completing sentences, and suggesting new ideas based on context.\nExample, “The stock market is…”\n\n\n\n\nA Large Language Model (LLM) is a scaled-up LMs trained on massive datasets with billions of parameters, enabling advanced capabilities in reasoning, summarization, translation, and dialogue.\n\nYou can refer to an LLM as an advanced type of language model that uses deep learning, especially transformer architectures, to understand complex patterns in large text datasets.\nLLMs, like GPT-3 and GPT-4, can generate human-like text and handle a wide variety of language tasks.\n\n\n\n\nMLLM\n\nA Multimodal Large Language Model (MLLM) refers to a special kind of LLM that can work with more than just text—it can also process and produce images, audio, and video. MLLMs combine different types of data and are capable of tasks like describing images, understanding memes, or generating website code from a visual prompt.\nThese emergent capabilities of MLLMs are rarely seen in conventional models and are viewed as steps toward Artificial General Intelligence (AGI).\nResearchers across academia and industry are rapidly developing MLLMs that aim to match or surpass the capabilities of models like GPT-4V.\n\n\n\nWhy It Matters Now\n\nThere has recently been an explosion of LLMs and MLLM (e.g., GPT-4, Gemini, Claude)\nThere is a convergence of content generation and decision-making in business, healthcare, security, and creative work\nAI brings transformational potential but introduces new risks\n\nAutomates workflows\nEnhances productivity\nIntroduces bias, explainability, control\n\n\n\n\nAI Evolution\n\nEarly Beginnings: Origins trace back to Pascal’s mechanical calculator (1642) and Ada Lovelace’s work on analytical engines (1837).\nThese inventions paved the way for automated computation and logic-based operations.\nModern AI Milestones: Progressed through neural networks, statistical machine learning, and deep learning.\nAdvances in hardware (e.g., GPUs) enabled training of large, complex models.\nGenerative AI Breakthroughs: Tools like GPT-4, DALL·E 2, and Copilot have redefined content creation and automation.\nApplications span IT helpdesks, creative arts, medical advice, and recipe suggestions.\nEconomic Impact: Generative AI is projected to increase global GDP by 7% and could replace up to 300 million knowledge worker jobs.\n\n\n\nInspiration for Game Theory in Gen AI\n\nGame Theory inspires Generative AI by modeling competition, cooperation, and strategic decision-making—core elements in adversarial training, multi-agent learning, and safe, interactive AI design like in Generative Adversarial Networks (GANs).\nIn GANs, two players—the generator and the discriminator—compete:\n\nThe generator tries to create realistic data.\nThe discriminator tries to distinguish real data from generated (fake) data.\n\nThis dynamic mirrors a non-cooperative game, where both improve over time through feedback.\nThe equilibrium of this game is when the Generator fools the Discriminator perfectly.\n\n\n\nGame Theory in Gen AI\n\nData-Driven Workflow:\n\nThe process starts with diverse datasets (text, image, sound, etc.).\nTraining involves iterative learning of patterns from this data.\nFine-tuning further adapts models to specific tasks or domains.\n\nFine-Tuning refers to the process of taking a pretrained foundational model and adapting it to a specific task or domain using additional labeled data. Essential for industry-specific applications of Generative AI.\n\n\n\n\n\nReal-World Application Path\n\nAfter training and fine-tuning, the model is used for inference—i.e., generating outputs from new inputs.\n\nInference refers to the stage where a trained AI model is used to generate outputs (e.g., answering a question, completing a sentence) based on new input.\n\nThese outputs can power apps, APIs, and digital platforms.\n\n\n\nEarly AI: Chatbots Beginnings\n\n1960s Origins: The earliest chatbots were rule-based systems using predefined keyword responses from expert knowledge bases (e.g., ELIZA).\n\nNot scalable or flexible—responses were rigid and failed in open-ended or dynamic conversations.\n\nRise of Statistical AI (1990s):\n\nIntroduced machine learning for pattern recognition from labeled text.\nEnabled more adaptive and context-aware text classification.\n\nNeural Networks & NLP Breakthroughs (2010s):\n\nDeep learning and Recurrent Neural Networks (RNNs) enhanced language understanding.\nImproved contextual awareness in sentence-level processing.\n\n\n\n\nEarly AI: Chatbots Beginnings: Transformers & LLMs:\n\nThe introduction of transformer models (e.g., GPT) revolutionized chatbot capabilities (≈2017).\n\nTransformer Architecture is a neural network design that allows models to process sequences (like text) with attention mechanisms, enabling context-aware and parallelized language generation.\n\nTransformers are based on attention mechanisms that allow models to give different weights to inputs they receive, giving “more attention” to the most relevant information centered in the text sequence, regardless of the order in which it is placed.\n\nTokenization is the process of breaking text into tokens (subwords or characters), which are then used as inputs for LLMs to understand and generate language.\nAttention Mechanisms allow models to focus on the most relevant parts of an input when generating outputs—critical for LLMs and multimodal systems.\n\nPowered tools like ChatGPT and Bing Chat, capable of multi-turn conversations and creative output (2020).\n\n\n\nImportance of GPU Innovation\n\nA GPU (Graphics Processing Unit) is a specialized processor designed to accelerate the rendering of images, animations, and video for display on a computer screen. Unlike a CPU (Central Processing Unit), which handles a wide variety of tasks, a GPU is optimized for performing many mathematical operations in parallel—especially those involving vectors and matrices.\n\n\n\nEnabling Large-Scale Models:\n\nGPU (Graphics Processing Unit) advancements have been critical in enabling the training and deployment of large language models (LLMs) like GPT-4.\nFaster computation and greater efficiency have made AI more accessible and cost-effective.\n\nModel Accessibility:\n\nEven smaller models can now be deployed on mobile devices, thanks to efficient GPU-based architectures (e.g., Google’s Palm Prompt2).\n\nDemocratization of AI:\n\nCheaper, more powerful chips allow a broader range of organizations (not just big tech) to build and fine-tune AI models.\nEncourages open-source participation and innovation at scale.\n\n\n\n\nOpen-Source Generative AI Index (GenOS)\n\nThe Generative Open-Source Index (GenOS) is a comprehensive tracker that ranks and evaluates open-source generative AI projects across various modalities and applications.\n\nGenOS helps developers, researchers, and organizations discover, compare, and leverage top-performing open-source GenAI tools.\nThis encourages transparency, collaboration, and accessibility in the generative AI ecosystem.\n\nUses Ranking Criteria: The index evaluates projects based on multiple factors including:\n\nGitHub popularity (stars, forks, issues)\nRecency of updates\nCommunity contributions and forks\nTechnical features and use cases\n\n\n\n\nConnecting GPU’s to GenOS\n\nGPUs alone don’t create value — Instead, we need systems that organize, orchestrate, and scale AI capabilities across applications.\n\nA Generative AI Operating System (GenOS) builds on GPU-enabled model power. It provides the layer that manages foundation models, prompt engineering, data pipelines, safety mechanisms, and deployment — much like how traditional operating systems manage applications and hardware.\n\nIf GPUs are the engines, then GenOS is the driver’s dashboard and control system — turning raw compute into usable, business-ready intelligence.\n\n\n\nTraining Methodologies for LLMs\n\nData Collection:\n\nTraining begins with collecting massive, diverse, and high-quality datasets from sources like web text, books, code, and forums to ensure the model learns varied language patterns.\n\nPretraining:\n\nThe model undergoes unsupervised learning using objectives like next-word prediction (causal language modeling) or masked word prediction (as in BERT), enabling it to learn general language understanding.\n\nMasked word prediction refers to a training technique where certain words in a sentence are intentionally hidden (or “masked”) and the model is trained to predict the missing words based on the surrounding context.\n\nInput to the model: “The cat sat on the [MASK].”\nThe model learns to predict: “mat”\n\n\n\n\n\n\nTraining Methodologies for LLMs Cont. Fine-Tuning (Supervised Training)\n\nAfter a large model is pretrained on broad, general data (often self-supervised), fine-tuning specializes it by training on smaller, labeled datasets.\nAligns the pretrained model with specific tasks (e.g., summarization, question answering, translation, sentiment analysis).\nHow it works:\n\nUses supervised learning: input–output pairs are provided (e.g., an article with its summary).\nAdjusts the weights of the pretrained model slightly (compared to full retraining).\n\nVariants:\n\nFull fine-tuning (all parameters updated).\nParameter-efficient fine-tuning (e.g., LoRA, adapters), where only a fraction of parameters are updated.\n\nBenefit: Much cheaper and faster than pretraining from scratch, while tailoring the model to domain or task.\n\n\n\nTraining Methodologies for LLMs Cross-Modal Embeddings\n\nWhat they are: Representations in a shared vector space that connect different modalities (like text, images, audio, video) by their semantic meaning.\nExample:\n\nAn image of a dog and the word “dog” map close to each other in the embedding space.\nEnables searching for images with text queries (“golden retriever playing frisbee”) or generating captions from images.\n\nWhy it matters:\n\nBreaks down the barrier between modalities.\nPowers applications like multimodal retrieval, captioning, cross-lingual video search, and multimodal reasoning.\n\n\n\n\nTraining Methodologies for LLMs Cont.\n\nReinforcement Learning with Human Feedback (RLHF): A feedback loop where human preferences guide the model’s responses—used to make assistant models more aligned, coherent, and safe (e.g., GPT-3.5-turbo, ChatGPT).\n\nRLHF is a specialized fine-tuning methodology that comes after pretraining (and often after supervised fine-tuning). Human feedback is used to adjust the model’s outputs, rewarding “good” responses (helpful, safe, aligned) and discouraging “bad” ones (toxic, incoherent, misleading).\nThe goal is to make models more aligned with human values and conversational needs, not just good at predicting the next token.\n\n\n\n\nIn what ways do LLMs handle unstructured, messy web data differently than traditional rule-based systems?\n\n\n\nLLMs vs Rule-based systems\n\n\n\n\nPrompting Using Gen AI\n\nFor extra information review O’Reilly Video on Prompt Engineering: https://learning.oreilly.com/videos/prompt-engineering/9781835881521/9781835881521-video1_1/\n\n\nRLHF vs Prompt Engineering\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\n\n\nRLHF is part of model training and fine tuning: It shapes the foundation of how the model responds to prompts by making it more “instruction-following” and aligned.\n\nRLHF = tuning the car’s steering system so it follows directions well.\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\nPrompt engineering = how you, the driver, actually steer it with the wheel.\n\n\n\n\nPrompt Engineering for Model Customization\n\n\n\nPrompt Engineering for Model Customization\n\n\n\n\nPrompt Engineering\n\nA well-crafted prompt can function like a “program” for the LLM, guiding it to generate structured outputs, perform reasoning, or simulate specific roles.\nPrompt Engineering is the art and science of crafting inputs to get desired outputs from AI systems\n\nCore idea: “Garbage in, garbage out”\nCrucial for improving reliability, tone, and relevance of LLM responses\n\n\n\n\nPrompting Paradigm\n\nPrompting Paradigm refers to the method of adapting LLMs through natural language instructions rather than retraining.\n\nBase models, such as GPT-3 or LLaMA-2, are pretrained on massive amounts of text data. This pretraining allows them to perform a wide variety of general tasks just from prompting.\nAssistant models, like ChatGPT or Claude, take this a step further. They are fine-tuned using Reinforcement Learning with Human Feedback. That means humans guide the model by rewarding helpful responses and discouraging unhelpful ones, shaping it to respond in a more conversational and task-specific way.\n\nWhy it matters\n\nPrompts shape how LLMs behave\nBetter prompts = better outcomes\nUseful across industries\n\n\n\n\nUnderstanding the Prompting Paradigm\n\nPrompting is foundational to in-context learning, where the model draws on prompt examples to infer new tasks dynamically.\n\nChain of Thought refers to a prompting strategy where the model is encouraged to generate step-by-step reasoning before arriving at a conclusion, improving accuracy in logic-based tasks.\nFew-Shot In-Context Learning refers to the ability of LLMs to learn patterns or tasks at inference time based solely on the context provided in a prompt, without requiring additional model training.\n\nPrompting is increasingly used as an interface layer between users and LLMs—minimizing the need for retraining while enabling flexible task execution.\n\n\n\nPrompt Types\n\n\n\nPrompt Type\n\n\n\n\nPrompt Engineering Iterations and Patterns\n\n\n\nPrompt Engineering Iterations\n\n\n\n\nPrinciples of Prompting\n\n\n\nPrinciples of Prompting\n\n\n\n\nSplit Complex Tasks into Subtasks\n\nMeta Prompt\nYou are an AI assistant that explains prompting paradigms, specifically: instructional, role-based, chain-of-thought, few-shot, and zero-shot.\nFollow these steps:\n\nIdentify which prompting paradigm is relevant to the user’s request.\nExplain the purpose of that paradigm and how it improves responses.\nProvide a short illustrative example showing the paradigm in action.\nIf asked, find an article related to prompting and summarize it concisely in 3–4 sentences.\n\nUser\nCan you find an article about the chain-of-thought prompting paradigm and summarize it in 3 sentences with a reference link?\nAnswer\nI found the article “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models” by Google Research. The paper introduces chain-of-thought prompting as a method where models generate intermediate reasoning steps before producing a final answer, which greatly improves performance on arithmetic, commonsense, and symbolic reasoning tasks. It demonstrates that this method is especially powerful when combined with large models, as reasoning accuracy scales with model size.\n📖 Reference: Wei, J. et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n\n\nPrompt the Model to Give an Explanation\n\nMeta prompt\n\nYou are a Dash expert that helps users build interactive dashboards in Python. You extract the necessary context from the user’s request and provide both natural-language explanations and code examples. ALWAYS explain what each part of the code is doing so the user understands how the app works. Take note that app.run_server is deprecated.\n\nUser\n\nCan you make a dashboard that shows the top 3 countries by sales revenue in a bar chart?\n\nAnswer\n\nHere’s a simple Dash app that displays the top 3 countries by sales revenue in a bar chart. To achieve this, I first created a small pandas DataFrame with sample data for countries and sales revenue. Then I sorted it and selected the top 3 entries. Finally, I built a bar chart using Plotly Express and served it in a Dash layout.\n\n**Provides code to include in python\n\n\n\nAsk for Justification\n\nMeta prompt\nYou are an AI assistant that decides whether a passage demonstrates statistical reasoning by its authors. Classify the passage as one of: Used statistical reasoning, No statistical reasoning, or Unclear. ALWAYS provide a justification that identifies the specific features in the passage that support your decision. Cite the exact part(s) of the passage where the sample size and treatment effect are stated.\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations to the text where the sample size and treatment effect are reported: “In a randomized controlled trial with 240 participants, the treatment group’s recovery rate was 12% higher than control (95% CI: 4%–20%, p = 0.01).”\nAnswer\nDecision: Used statistical reasoning.\nJustification: The passage demonstrates statistical reasoning by referencing an experimental design (“randomized controlled trial”), providing a sample size (“240 participants”), reporting a quantified treatment effect (“12% higher than control”), and presenting inferential measures (“95% CI: 4%–20%, p = 0.01”). Together, these show systematic use of statistics to draw conclusions.\n\n\n\nContinuing with an Unclear Example\n\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations (or explain their absence) for the sample size and treatment effect: “The treatment group recovered more often than the control group.”\nAnswer\nDecision: Unclear.\nJustification: The passage makes a comparative statement (“recovered more often”), but it does not include statistical details such as the sample size (not provided) or the magnitude of the treatment effect (not quantified). Without these, it is impossible to confirm whether statistical reasoning was applied; the authors only make a descriptive claim rather than presenting inferential evidence.\n\n\n\nLLM Hallucinations\n\nLLM Hallucinations refer to situations where the model generates plausible but false or fabricated content, often due to gaps in training data or the probabilistic nature of text prediction.\n\nPrompt from lawyer: “Can you provide legal cases where the U.S. Supreme Court ruled that AI-generated evidence is inadmissible in court?“\nChatGPT: “Yes. In the case of Smith v. United States, 2022, the Supreme Court ruled that evidence generated by an AI system without human oversight was inadmissible, citing concerns over transparency and accountability.“\n\nThere is no case called Smith v. United States (2022) that involves AI-generated evidence. The model fabricated a plausible-sounding court case based on the prompt. It may even invent quotes or legal reasoning that sound real but do not exist in any official ruling.\n\n\n\n\n\nReduce Hallucination with Prompt Engineering\n\n\n\nReducing Hallucination\n\n\n\n\nSpotting Hallucinations\n\nHallucinations are confident but factually incorrect responses generated by LLMs. To spot them look for These Red Flags:\n\nToo specific without source: “The GDP of Argentina in Q3 2023 was exactly $347.2 billion” (without citation).\nInvented sources or references: Fake articles, court cases, or journal titles.\nContradictions or inconsistencies within a response.\nOverly confident language in uncertain or speculative topics: “This is definitely true.”\nMissing common sense: “The Eiffel Tower is 1,200 miles tall.”\n\n\n\n\nWhy Prompting Doesn’t Guarantee Generative AI Is Good at Math\n\nEven if you give a well-crafted prompt, that doesn’t mean generative AI will solve math problems correctly.\n\nGenerative AI can imitate math, but it doesn’t understand it.\nFluency does not necessarily equal Accuracy\nLLMs Predict Language, Not Compute Logic\n\nLLMs Lack Internal Verification\n\nLLMs don’t check their answers unless explicitly prompted to do so.\nUnlike specific math engines, they don’t “know” math rules—they approximate them from training examples.\n\nErrors Increase with Complexity\n\n\n\nGive AI a Prompt Evaluation Rubric\n\n\n\nEvaluation_Rubric\n\n\n\n\nPaths Forward in Generative AI\n\nFine-Tuning & Domain Adaptation:\n\nTailoring general models to specific industry or task domains by training it on labeled datasets to improve relevance and reliability.\n\nHybrid Approaches:\n\nCombining symbolic AI (rules-based) with generative models may boost explainability and control.\n\nRegulation & Ethical Frameworks:\n\nEncouraging responsible use through AI governance, transparency, and auditable AI practices.\n\nOpen Collaboration:\n\nContinued progress through open-source communities, academic-industry partnerships, and shared benchmarks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GenAI</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html",
    "href": "analyticsproblem.html",
    "title": "Analytics Problem",
    "section": "",
    "text": "Food for Thought",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analytics Problem</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html#the-analytics-problem",
    "href": "analyticsproblem.html#the-analytics-problem",
    "title": "Analytics Problem",
    "section": "The Analytics Problem",
    "text": "The Analytics Problem\n\nChapters 1 and 2 from Weber and Zwingmann (2024) outline the journey of building a data-driven organization—from understanding the foundations of data acquisition, APIs, and web scraping, to progressing through the data maturity stages (Reactive → Active → Progressive → Fluent) by aligning culture, strategy, people, and technology.\n\nChapter 1 and 2 at Weber, W., & Zwingmann, T. (2024). Augmented analytics. O’Reilly Media, Inc. Available at https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\n\nHistorical Context: Industrial Transformations\n\nPast revolutions:\n\n1760s: Steam power.\nMid-1800s to 1910s: Electricity & mass production.\nLate 20th century–present: Computerization.\n\nCurrent shift: Digital transformation driven by multiple converging technologies (AI, IoT, cloud, analytics) is faster and more complex than prior eras.\n\n\n\nWhy are Business Transforming?\n\nSpeed of Change\n\nPrevious revolutions took decades; now transformation can occur in a few years.\nExample: Amazon vs. local bookstores; Uber vs. taxis; Industry 4.0 in manufacturing.\nRequires organizational agility and strong leadership.\n\n\n\n\n\nFigure 1-1. The growing amount of data worldwide. Adapted from Statista, as cited in Weber & Zwingmann (2024)\n\n\n\nConvergence of Multiple Technologies\n\nUnlike single-tech revolutions, today’s changes combine AI, cloud, IoT, and advanced analytics.\nLeads to multidimensional complexity and unpredictable disruption timelines.\n\nImportance of Data\n\nData has shifted from being a byproduct to being a core strategic asset.\nGrowth in unstructured data (text, images, video) creates new challenges.\nThe “data as oil” analogy is flawed: data increases with use, is not scarce, but needs “refining” (cleaning, governance) to be valuable.\n\nChanging Consumer Behavior & Customer Centricity\n\n“iPhone moments” reshape entire industries (examples: Shopify, Tesla, Amazon Prime, Netflix).\nDigital transformation now spans all sectors and is often triggered by heightened customer expectations.\n\n\n\n\nIndustries Most Impacted\n\nMcKinsey research highlights industries where big data & analytics are transformative:\n\nAgriculture – Precision farming, automation.\nCommercial insurance – Pricing, underwriting efficiency.\nFinance – Fraud detection, credit risk modeling.\nHealthcare – Personalized medicine, predictive diagnostics.\nIT – Automation, cybersecurity.\nManufacturing – Predictive maintenance, supply chain optimization.\nTransportation – Route optimization, demand prediction.\nUtilities – Grid stability, renewable integration.\n\n\n\n\n\nFigure 1-2. Industries heavily impacted by big data and analytics. Adapted from McKinsey, as cited in Weber & Zwingmann (2024)\n\n\n\n\nConsequences for Businesses\n\nShift from internal efficiency to customer-centricity: Digital tools allow deep customer journey insights.\nAnalytics adoption gap:\n\nMany analytics teams fail to deliver perceived value.\nTools are often “too technical” for average employees.\nLesson from history:\n\nWidespread adoption comes from simplicity (e.g., mouse for computers, touchscreens for phones).\n\n\n\n\n\nThe Case for Augmented Analytics\n\nLimitations of traditional analytics:\n\nCan’t handle the variety of today’s data (structured, semi-structured, unstructured).\nManual tools like Excel or static BI dashboards are insufficient.\n\nAugmented analytics goal:\n\nBring insights to non-data professionals (80% of workforce).\nMake analytics intuitive, embedded in workflows, and actionable.\n\n\n\n\nData-Driven Culture\n\nDefinition: Culture where decisions routinely reference “What does the data say?”\nCurrent reality: Most companies lack data literacy—only ~24% of decision-makers feel confident with data.\nNeed: Foster curiosity, analysis, and communication skills alongside technical tools.\n\n\n\nThe People Problem & Limits of Upskilling\n\nAging populations and shrinking workforces mean you can’t simply replace staff.\nUpskilling is essential but cannot make everyone a “data person.”\n\nUpskilling refers to the process of learning new skills or improving existing ones, typically to keep up with changes in technology, industry practices, or job requirements. It often involves acquiring more advanced, specialized, or updated capabilities that make a person more effective in their current role or prepare them for new opportunities.\n\nFor individuals, upskilling helps maintain competitiveness in the job market, adapt to evolving roles, and enhance career growth.\nFor organizations, upskilling initiatives improve workforce productivity, reduce skill gaps, and strengthen adaptability in fast-changing industries.\n\n\nSuggested Solution: Meet people where they are and give them augmented tools rather than forcing advanced analytics expertise.\n\n\n\nTransition from Data-Driven to Insight-Driven\n\nData-driven: Focuses on collecting/analyzing data.\nInsight-driven: Focuses on delivering actionable, user-friendly insights to the majority of employees.\nAugmented analytics is positioned as the “mouse” of the analytics world—bridging the gap between complexity and usability.\n\n\n\nDeveloping Analytical Maturity\n\n\n\nAnalytical Maturity: The Four-Tier IPTOP Framework\n\nThe IPTOP framework is operational in nature because it guides data teams on infrastructure, tools, and processes.\n\n\n\nInfrastructure: How data is collected, stored, made reliable, and accessible.\nPeople: Cultivating data literacy, a data-driven culture, and ongoing learning.\nTools: The analytics and data tools used at various skill levels, plus reusable frameworks.\nOrganization: Structuring data talent—centralized, decentralized, or hybrid models—for scalable analytics.\nProcesses: Workflows and practices that support collaboration, consistency, and alignment with business goals.\n\n\n\n\nFigure 2-1. The four-tier IPTOP analytics maturity framework. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nCombining IPTOP and Data Maturity\n\n\n\nThe SPEC Framework for Transformation\n\nThe SPEC framework is strategic because it helps executives align analytics with business vision and culture.\n\nIPTOP = How do we build it? (infrastructure, tools, processes, literacy, governance).\nSPEC = Why and who drives it? (strategy, people, leadership, culture).\n\nStrategy – Align analytics vision with business objectives.\nPeople & Organization – Build data talent, bridge business and analytics roles, promote continuous learning.\nData Ecosystem – Reliable, secure, accessible data infrastructure with governance.\nCultural Change – Foster collaboration, experimentation, and data-driven mindsets.\n\n\n\n\nFigure 2-2. The SPEC framework. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nBeing Data Active\n\nThe chart shows the transition from Data Reactive to Data Active in analytics maturity, guided by improvements in culture, strategy, people & organization, and data ecosystem.\n\nCulture (green line)\nEnsure CEO support – Top-level commitment is essential.\nInvolve and convince management – Get buy-in from leadership.\n\nStrategy (green & red mixed)\n\nDevelop a data strategy – Create a plan for how analytics will support business goals.\nAlign with business strategy, finding the purpose – Make analytics initiatives serve clear organizational objectives.\n\nPeople & Organization (red line)\n\nConsider the importance of data literacy – Raise awareness of skills needed to understand and use data.\n\nData Ecosystem (blue line)\n\nStart with an initial governance – Establish basic rules, processes, and ownership for data.\nPursue a consistent use-case-oriented approach – Focus on solving specific, high-value problems with analytics rather than abstract projects.\n\nEnd Goal – By applying these cultural, strategic, organizational, and technical steps, an organization can move from a reactive approach to data to a proactive, structured use of analytics.\n\n\n\n\nFigure 2-3. Actions on the path from Data Reactive to Data Active. Reprinted from Weber & Zwingmann (2024).\n\n\n\n\nMoving to Data Progressive\n\nCulture (green)\n\nDefine collaboration models to encourage cross-team work.\nDrive adoption of first analytics solutions to show value early.\nFoster a data liberalization approach, making data accessible to more users.\n\nStrategy (green line)\n\nDefine a clear data analytics strategy aligned with business goals.\n\nPeople/Organization (red)\n\nDefine your operation model to structure data initiatives.\nEstablish a center of excellence to centralize expertise.\nDefine roles and personas for clarity in responsibilities.\nSet up a data literacy program to build skills.\nExecute along an analytics transformation roadmap for consistent progress.\nDevelop talents within the organization for long-term capability.\n\nData Ecosystem (blue)\n\nFinalize your target tool stack for consistency in technology.\nSet up a use case pipeline and process to manage analytics projects.\n\nOverall Goal:\n\nTransition from simply being active with data to being progressive, meaning analytics is deeply embedded, strategically driven, culturally embraced, and supported by robust tools, processes, and skilled people.\n\n\n\n\n\nFigure 2-4. Actions on the path from Data Active to Data Progressive. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nOvercoming Gulfs and Chasms\n\n\n\nFigure 2-5. Impact and establishment of the four steps of analytical maturity. Reprinted from Weber & Zwingmann (2024)\n\n\n\nComplexity & Market Establishment:\n\nAs organizations progress, complexity increases (vertical axis on top) and market establishment grows (vertical axis on bottom).\nGulfs and a chasm indicate key transition points where many organizations struggle to advance to the next stage.\n\nMoving from reactive to fluent requires overcoming organizational, technical, and cultural barriers at these gulfs and chasms, with each stage demanding higher sophistication and broader adoption.\n\nGulfs refer to incremental adoption hurdles.\nChasms refer to the big leap from being data-aware to making analytics part of the organizational DNA",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analytics Problem</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html#augmented-analytics",
    "href": "analyticsproblem.html#augmented-analytics",
    "title": "Analytics Problem",
    "section": "Augmented Analytics",
    "text": "Augmented Analytics\n\nChapter 3 of Weber and Zwingmann discuss why augmented analytics (AA) is critical in today’s fast-changing business environment.\n\nChapter 3 at Weber, W., & Zwingmann, T. (2024). Augmented analytics. O’Reilly Media, Inc. Available at https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\n\nAugmented Analytics (AA)\n\nAugmented analytics means adding value by providing people with access to technology that gives them the analytical leverage they need to accomplish the business task at hand in a better way.\nAugmented analytics offers a path to scaling insights across an organization by making them accessible, intuitive, and embedded in decision-making.\nAA is not just about better tech—it’s about human-centric augmentation that finds the right “sweet spot” between automation and judgment.\nDone right, it becomes integrated, essential, and empowering—helping organizations progress toward Data Fluent maturity.\n\n\n\nAA maters because it breaks down the data expert vs. business user divide. Embeds analytics in daily work to make data use habitual and unobtrusive. Uses augmented workflows (analytics inside existing processes) and augmented frames (context-specific, just-in-time insights).\n\n\n\nFive Key Components Moving from Data Reactive to Data Fluent\n\nPeople – Human creativity, experience, and judgment remain at the center of analytics. Tools support people, but it’s people who frame questions, interpret results, and make decisions.\nTechnology – AI, automation, and analytics platforms provide the computational power to process large datasets and enable advanced analytics.\nAnalytical Leverage – Analytics amplifies human thinking by improving speed, scale, accuracy, and predictive ability—making insights more powerful than intuition alone.\nBusiness Task – Analytics should always be applied to solve real-world, value-driven business problems, not just generate reports for their own sake.\nBetter Way – The goal is to make decisions that are faster, more reliable, and less biased—leading to better outcomes than gut instinct or outdated methods.\n\n\n\n\nFigure 3-1. Enablers for each maturity stage. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nFive Traits of Effective AA\n\nInsightful – turns data into actionable knowledge.\nIntegrated – embedded into existing workflows and tools.\nInvisible – works seamlessly in the background.\nIndispensable – delivers consistent value, becomes essential.\nInclusive – usable by all, not just data experts.\n\n\n\n\nFigure 3-2. Augmented workflow efficiency. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nTypes of Bias\n\nSurvivorship Bias\n\nDefinition: Focusing only on people or things that “survived” a process, ignoring those that did not.\nExample: Studying successful companies and assuming their strategies guarantee success, without analyzing the failed ones.\n\nConfirmation Bias\n\nDefinition: Tendency to seek out or favor information that confirms existing beliefs, while ignoring contradictory evidence.\nExample: Only reading news sources that support your political views.\n\nSample Bias\n\nDefinition: Drawing conclusions from a dataset that is not representative of the entire population.\nExample: Running a survey only among college students to estimate national voting behavior.\n\nAvailability Bias\n\nDefinition: Overestimating the importance of information that is easiest to recall, often because it is recent or vivid.\nExample: Believing plane crashes are common after seeing news coverage of one, despite statistics showing they are rare.\n\nOutlier Bias\n\nDefinition: Placing too much emphasis on unusual or extreme cases that may not represent the norm.\nExample: Using one extraordinary sales month to predict future performance.\n\n\n\n\n\nFigure 3-3.Improvability of various types of biases.Reprinted from Weber & Zwingmann (2024)\n\n\n\nSelection Bias\n\nDefinition: Systematic error caused by choosing non-random data that skews results.\nExample: Studying only patients who complete a treatment program, ignoring those who dropped out.\n\nCognitive Bias\n\nDefinition: A systematic pattern of deviation from rational judgment that affects decisions and thinking.\nExample: Stereotyping people based on limited personal experiences.\n\nAnchoring Bias\n\nDefinition: Relying too heavily on the first piece of information (the “anchor”) when making decisions.\nExample: Negotiating a salary based primarily on the initial number offered.\n\nHistorical Bias\n\nDefinition: Bias introduced by data that reflects outdated or inequitable historical conditions.\nExample: Predictive policing models reinforcing past discriminatory arrest patterns.\n\n\n\n\nThe Five AI Archetypes\n\n\n\nFigure 3-4.The five AI archetypes. Reprinted from Weber & Zwingmann (2024).\n\n\nAutomation – repeatable, deterministic processes (data prep, reporting, alerts).\nAI archetypes –\n\nSupervised ML (prediction, classification, anomaly detection, recommendations)\nNatural Language Processing (NLP) (text analysis, search, summarization, sentiment)\nSpeech (voice-to-text/text-to-voice analytics)\nComputer vision (document/image analysis)\nGenerative AI (text-to-code, automated reports, conversational queries)\n\n\n\nSupervised Learning\n\nThis diagram shows the iterative process of building and maintaining a supervised machine learning model:\n\nCollect Data – Gather relevant, high-quality datasets containing both features (inputs) and labels (outputs).\nDefine Features and Labels – Identify which variables will be used as predictors (features) and what will be predicted (label).\nTrain/Test Split – Divide the data into training and testing sets to evaluate performance fairly.\nFind Best Model – Experiment with different algorithms and hyperparameters to determine the most effective model.\nEvaluate – Measure the model’s accuracy, precision, recall, or other metrics on the test set.\nDeploy – Integrate the model into a real-world application or workflow.\nMonitor – Continuously check performance, retrain when data drifts, and ensure predictions remain accurate over time.\n\nThis loop emphasizes continuous improvement — after monitoring, you may need to return to earlier steps to refine the model as new data arrives or conditions change.\n\n\n\n\nFigure 3-5.The supervised ML workflow. Reprinted from Weber & Zwingmann (2024).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analytics Problem</span>"
    ]
  },
  {
    "objectID": "preparingpeople.html",
    "href": "preparingpeople.html",
    "title": "Preparing People",
    "section": "",
    "text": "Preparing People and the Organization for Augmented Analytics",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preparing People</span>"
    ]
  },
  {
    "objectID": "preparingpeople.html#preparing-people-and-the-organization-for-augmented-analytics",
    "href": "preparingpeople.html#preparing-people-and-the-organization-for-augmented-analytics",
    "title": "Preparing People",
    "section": "",
    "text": "Preparing people and the organization for Augmented Analytics means building both the skills and the culture needed to embed analytics into daily decision-making. Leaders must champion data-driven practices, analytics translators must bridge business and technical teams, and employees need at least analytics awareness to trust and act on insights. A Center of Excellence (CoE), executive sponsorship, and structured training ensure that AA is not just a technology upgrade but an organizational transformation that empowers all roles to benefit from data in their workflows.\n\nReference: Chapters 4 from Weber, W., & Zwingmann, T. (2024). Augmented analytics. O’Reilly Media, Inc. Available at https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\n\nPreparing People & the Organization for AA\n\nFocus on roles (leaders, translators, users, professionals) and personas to structure the analytics transformation.\nBuild both technical readiness (data infrastructure, processes) and human readiness (mindset, skills, awareness).\nEstablish a Center of Excellence (CoE) to drive transformation, ideally business-anchored and federated over time.\n\nA CoE is an organizational structure set up to concentrate expertise, best practices, and resources around a specific domain, technology, or strategic priority. Its main purpose is to drive consistency, innovation, and efficiency across an organization.\n\n\n\n\nTailoring Augmented Analytics for Different Organizational Roles\n\nAnalytics Leader – Champions data-driven culture, aligns insights with strategy.\nAnalytics Translator – Bridges gap between business and technical teams, ensures use cases deliver value.\nAnalytics User – Consumes insights for better decisions; majority of workforce.\nAnalytics Professional – Technical experts building and maintaining analytics solutions.\n\n\n\n\nFigure 4-1.Analytics transformation personas in the three skill categories (Weber & Zwingmann, 2024)\n\n\n\n\n\nFigure 4-2. The four top-level roles in the analytics transformation (Weber & Zwingmann, 2024)\n\n\n\n\nCenter of Excellence (CoE)\n\nA CoE is a unit dedicated to organizing the analytics transformation.\nDuring the Data Active maturity phase, it collects and connects all the loose threads of analytics activities that emerge.\n\nPurpose: Organize and guide analytics transformation, connect business units, build culture.\n\nCore responsibilities:\n\nPromoting data literacy and liberalization.\nBuilding quick-win use cases (“lighthouse” projects).\nCreating shared governance and culture.\nSupporting business units and connecting their strategies.\nInspiring people across the company to take ownership of analytics\n\n\n\n\n\nFigure 4-4. A center of excellence drawn from both IT and business units (Weber & Zwingmann, 2024)\n\n\n\n\nApproaches to Organizing a CoE\n\nDecentralized Approach\n\nCommon in early-stage, Data Reactive organizations.\nBusiness units develop analytics independently, often using ad hoc tools (Excel, VBA, Python, R, etc.).\nPros: High independence and agility within business domains.\nCons: Lack of governance, scalability issues, silos, and inefficiencies.\nBottom line: Tempting but unsustainable without stronger coordination.\n\nCentralized Approach\n\nCommon in smaller organizations or when business units lack analytical skills.\nA single CoE or IT unit manages analytics, reporting, and infrastructure.\nPros: Efficient, well-designed solutions and processes.\nCons: Bottlenecks, slow responsiveness, weak business insight, lack of shared ownership.\nBottom line: Works for early stages or small orgs but limits growth and responsiveness.\n\n\n\n\nFederated Approach\n\nA hybrid model that balances centralized expertise with decentralized ownership.\nCoE starts as a strong driver, then gradually shifts responsibility to business units as data literacy grows.\nPros:\n\nEncourages shared responsibility and democratization of data.\nBusiness units handle routine analytics while the CoE tackles advanced challenges.\nBuilds a stronger data culture and faster responsiveness.\n\nCons: Requires strong governance, collaboration, and patience.\nBottom line: The most effective model for achieving Data Progressive (stage 3) maturity.\n\n\n\n\nDifficulties Preparing People\n\nInherent bias\n\nMany of us are unaware of our knowledge gaps because we are inherently biased. We don’t know what we don’t know.\n\nPerceived solvability\n\nPeople often assume that complex problems can be solved somehow, without actually tackling them and testing the approaches. This is particularly true in the AI environment, where the underlying technology accomplishes wonderful things in vaguely understood ways. It’s important that people understand how problem solving actually works, because finding a solution usually involves a lot of hard work.\n\nLearned helplessness\n\nRepeated mistakes or negative experiences can lead individuals to believe that they cannot change, creating a state of “learned helplessness.” Organizations must instill the belief that effort can lead to improvement. With the advent of analytics, there are more opportunities than ever to demonstrate this in action.\n\n\n\n\nCultivating Data Literacy\n\nKey Competencies\n\nAnalytics Awareness\n\nHelps non-specialists understand data processes, quality, visualization, and core AI/ML concepts.\nFosters effective communication with data professionals and realistic expectations for AI projects.\n\nStorytelling with Data\n\nTranslates complex insights into clear narratives for different audiences.\nRequires mastering visualization, decluttering, and tailoring tone/context to make data compelling and actionable.\n\nData-Driven Management\n\nManagers must commit to analytics strategy, ensure data integrity, and integrate analytics into decision-making.\nFocus on aligning analytics with business goals, fostering ownership, and promoting a culture of continuous learning.\n\nLeading in the Age of AI\n\nLeaders need to progress from AI awareness to active engagement.\nCompetencies include identifying AI opportunities, managing AI project lifecycles, and integrating AI into business strategy.\nGoal: build organizational capacity to leverage AI for transformation and innovation.\n\n\n\n\n\n\nFigure 4-7. Four key aspects of data literacy (Weber & Zwingmann, 2024)\n\n\n\n\nEnablement Programs\n\nAnalytics adoption requires different levels of data literacy depending on role.\n\nAnalytics translators need high literacy to identify and develop use cases.\nAnalytics users need analytics awareness—a general understanding of data’s value, processes, and visualization—to effectively use workflows without being experts.\nAnalytics leaders and practitioners need awareness, storytelling, and role-specific competencies.\n\nFor Leaders\n\nInitial workshops, executive roundtables, ThinkLabs, annual leadership summits.\n\nFor Translators\n\nDeep-dives into tools/methods, cross-disciplinary ThinkLabs, mentoring, project presentations\n\nFor Professionals\n\nOngoing technical training (SQL, Python, R, statistics, ML).\n\n\n\n\nWorkflow Augmentation\n\nA workflow is the repeatable sequence of steps, tasks, and decisions employees follow to achieve a business outcome.\nAugmented Analytics succeeds only when insights are embedded inside workflows, not delivered separately in dashboards or reports.\n\n\n\nTypes of Workflow Augmentation\n\nFixed-Rule, High-Confidence Augmentation\n\nAutomated actions when preset conditions are met.\nWorks best for routine, well-defined tasks.\nExample: routing claims or prepopulating CRM entries.\n\n\n\n\n\nIdea & Insight Enrichment\n\nSupports human decision-making with predictions, benchmarks, and visualizations.\nActs as a “copilot,” surfacing trends or comparisons.\nExample: benchmarking risks in insurance underwriting.\n\nConversational Augmentation\n\nUses GenAI/LLMs in interactive assistants.\nExample: GitHub Copilot for coding, or AI chat tools for summarizing contracts.\n\nContextual (Adaptive) Augmentation\n\nLearns from users’ context, tailoring responses to role, history, or task.\nExample: adaptive email or recommendation systems.\n\nCollaborative Augmentation\n\nEnhances teamwork through shared dashboards, repositories, and chatbots.\nExample: Azure chatbot integrated into Microsoft Teams for compliance support.\n\n\n\n\nFinding Workflows to Augment\n\nUse the Analytics Use-Case Approach: a structured pipeline from idea → concept → proof of concept → prototype → pilot → product.\n\nEach phase evaluates risk, ROI, and maturity before committing resources.\nSuccess depends on validating assumptions iteratively.\n\nBalancing Automation & Integration\n\nWorkflows vary by automation (how much is done without humans) and integration (how deeply embedded in systems).\n\nFour categories:\n\n\n\nFour Categories\n\n\nBest to start with assistants and copilots before scaling to autopilots and agents.\n\n\n\nThe Use-Case Library\n\nA central repository that tracks all analytics use cases from idea to deployment.\nBenefits: transparency, monitoring, innovation sharing, cultural motivation, visibility of stakeholders.\nOften includes Kanban boards, evaluation matrices, and documentation to foster collaboration and standardization.\n\n\n\n\nKanban Board (Businessmap, n.d.)\n\n\n\n\nTechnical & Organizational Requirements\n\nAPIs & microservices (REST, Python, R) are recommended for flexible, vendor-independent integration.\n\nREST stands for Representational State Transfer. It’s an architectural style for designing web services and APIs that allow systems to communicate over the internet.\n\nIt decouples front-end and back-end, letting different apps (web, mobile, IoT) consume the same API.\n\nIn the Augmented Workflows chapter, REST APIs are recommended to integrate analytics into business workflows because they are modular, secure, and reusable.\n\nChallenges: legacy systems, IT dependencies, governance, security, and compliance.\nAnalytics contracts (similar to data contracts) are proposed to ensure discoverability, trust, interoperability, and responsible use.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preparing People</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chapters 3 and 4 from Ravindran, Anton. Will AI Dictate the Future? From Successful Leaders and Managers from Around the World, Marshall Cavendish International (Asia) Private Limited, 2022. ProQuest Ebook Central, Retrieved from https://ebookcentral.proquest.com/lib/cwm/detail.action?docID=29354182\n\nChapters 1-4 from Weber, W., & Zwingmann, T. (2024). Augmented analytics. O’Reilly Media, Inc. Retrieved from https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\nSchmidt, A., Väänänen, K., Goyal, T., Kristensson, P. O., Peters, A., Mueller, S., Williamson, J. R., & Wilson, M. L. (Eds.). (2023). Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery. https://doi.org/10.1145/3544548 Additional Reading Material:\nWilke, C. O. (2019). Fundamentals of data visualization. O’Reilly Media. ISBN: 9781492031086.Retrieved from https://learning.oreilly.com/library/view/fundamentals-of-data/9781492031079/\nDabbas, E. (2021). Interactive dashboards and data apps with Plotly and Dash. Packt Publishing. ISBN 9781800568914. Retrieved from https://learning.oreilly.com/library/view/interactive-dashboards-and/9781800568914/",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Deploying a Site",
    "section": "",
    "text": "Overview",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Deploying a Site</span>"
    ]
  },
  {
    "objectID": "github.html#appendix-a-render-a-python-file-to-html-with-quarto",
    "href": "github.html#appendix-a-render-a-python-file-to-html-with-quarto",
    "title": "Deploying a Site",
    "section": "Appendix A: Render a Python file to HTML with Quarto",
    "text": "Appendix A: Render a Python file to HTML with Quarto\nQuarto can render a Python script (with outputs) to HTML.\nquarto render your_script.py --to html --output-dir docs",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Deploying a Site</span>"
    ]
  }
]