[
  {
    "objectID": "genAI.html",
    "href": "genAI.html",
    "title": "Understanding Generative AI",
    "section": "",
    "text": "This section introduces multimodal generative AI‚Äîsystems that create and reason across text, images, audio, and video‚Äîand situates them within the broader evolution from language models (LMs) to large language models (LLMs) and multimodal LLMs (MLLMs). It explains how advances in transformer architectures, GPUs, and training methods (pretraining, fine-tuning, RLHF, and cross-modal embeddings) enable cross-modal understanding and generation, while prompting techniques turn these capabilities into reliable workflows. The section also surveys high-impact applications (automation, personalization, retrieval, and decision support), highlights risks (hallucination, bias, transparency), and outlines practical guardrails‚Äîevaluation rubrics, prompt engineering, and governance‚Äîfor responsible deployment in real settings.\n\n\nReference: Together, Chapter 1 and 3 of Multimodal Generative AI present an overview of the foundations, architectures, and ethical considerations of multimodal generative systems, and examine how emerging multimodal large language models extend these capabilities with advanced cross-modal reasoning and generation‚Äîwhile grappling with challenges in complexity, data integration, and responsible deployment.\n\n\nGenerative AI\n\nGenerative AI refers to a type of AI that creates new content (text, audio, images) based on patterns learned from training data. It contrasts with predictive AI, which forecasts outcomes from historical data.\nSome Examples:\n\nChatGPT ‚Äì conversational text generation\nCodex / GitHub Copilot ‚Äì code generation and completion\nDALL¬∑E ‚Äì image generation from text prompts\nPerplexity AI ‚Äì conversational search + generative synthesis\n\n\n\n\nWhat is Generative AI?\n\n\nGenerative AI represents a Paradigm Shift\n\n\nLM vs LLM\n\nFrom Generative AI to LLMs\n\nGenerative AI is the broad field of AI that can create new content (text, images, audio, video, code).\n\n\n\n\nA Language Model (LM) is a core branch of GenAI focused on predicting and generating text based on patterns in language data.\n\nLM are designed to predict the likelihood of words or phrases in a sentence.\nIts main tasks include generating text, completing sentences, and suggesting new ideas based on context.\nExample, ‚ÄúThe stock market is‚Ä¶‚Äù\n\n\n\n\nA Large Language Model (LLM) is a scaled-up LMs trained on massive datasets with billions of parameters, enabling advanced capabilities in reasoning, summarization, translation, and dialogue.\n\nYou can refer to an LLM as an advanced type of language model that uses deep learning, especially transformer architectures, to understand complex patterns in large text datasets.\nLLMs, like GPT-3 and GPT-4, can generate human-like text and handle a wide variety of language tasks.\n\n\n\n\nMLLM\n\nA Multimodal Large Language Model (MLLM) refers to a special kind of LLM that can work with more than just text‚Äîit can also process and produce images, audio, and video. MLLMs combine different types of data and are capable of tasks like describing images, understanding memes, or generating website code from a visual prompt.\nThese emergent capabilities of MLLMs are rarely seen in conventional models and are viewed as steps toward Artificial General Intelligence (AGI).\nResearchers across academia and industry are rapidly developing MLLMs that aim to match or surpass the capabilities of models like GPT-4V.\n\n\n\nWhy It Matters Now\n\nThere has recently been an explosion of LLMs and MLLM (e.g., GPT-4, Gemini, Claude)\nThere is a convergence of content generation and decision-making in business, healthcare, security, and creative work\nAI brings transformational potential but introduces new risks\n\nAutomates workflows\nEnhances productivity\nIntroduces bias, explainability, control\n\n\n\n\nAI Evolution\n\nEarly Beginnings: Origins trace back to Pascal‚Äôs mechanical calculator (1642) and Ada Lovelace‚Äôs work on analytical engines (1837).\nThese inventions paved the way for automated computation and logic-based operations.\nModern AI Milestones: Progressed through neural networks, statistical machine learning, and deep learning.\nAdvances in hardware (e.g., GPUs) enabled training of large, complex models.\nGenerative AI Breakthroughs: Tools like GPT-4, DALL¬∑E 2, and Copilot have redefined content creation and automation.\nApplications span IT helpdesks, creative arts, medical advice, and recipe suggestions.\nEconomic Impact: Generative AI is projected to increase global GDP by 7% and could replace up to 300 million knowledge worker jobs.\n\n\n\nInspiration for Game Theory in Gen AI\n\nGame Theory inspires Generative AI by modeling competition, cooperation, and strategic decision-making‚Äîcore elements in adversarial training, multi-agent learning, and safe, interactive AI design like in Generative Adversarial Networks (GANs).\nIn GANs, two players‚Äîthe generator and the discriminator‚Äîcompete:\n\nThe generator tries to create realistic data.\nThe discriminator tries to distinguish real data from generated (fake) data.\n\nThis dynamic mirrors a non-cooperative game, where both improve over time through feedback.\nThe equilibrium of this game is when the Generator fools the Discriminator perfectly.\n\n\n\nGame Theory in Gen AI\n\nData-Driven Workflow:\n\nThe process starts with diverse datasets (text, image, sound, etc.).\nTraining involves iterative learning of patterns from this data.\nFine-tuning further adapts models to specific tasks or domains.\n\nFine-Tuning refers to the process of taking a pretrained foundational model and adapting it to a specific task or domain using additional labeled data. Essential for industry-specific applications of Generative AI.\n\n\n\n\n\nReal-World Application Path\n\nAfter training and fine-tuning, the model is used for inference‚Äîi.e., generating outputs from new inputs.\n\nInference refers to the stage where a trained AI model is used to generate outputs (e.g., answering a question, completing a sentence) based on new input.\n\nThese outputs can power apps, APIs, and digital platforms.\n\n\n\nEarly AI: Chatbots Beginnings\n\n1960s Origins: The earliest chatbots were rule-based systems using predefined keyword responses from expert knowledge bases (e.g., ELIZA).\n\nNot scalable or flexible‚Äîresponses were rigid and failed in open-ended or dynamic conversations.\n\nRise of Statistical AI (1990s):\n\nIntroduced machine learning for pattern recognition from labeled text.\nEnabled more adaptive and context-aware text classification.\n\nNeural Networks & NLP Breakthroughs (2010s):\n\nDeep learning and Recurrent Neural Networks (RNNs) enhanced language understanding.\nImproved contextual awareness in sentence-level processing.\n\n\n\n\nEarly AI: Chatbots Beginnings: Transformers & LLMs:\n\nThe introduction of transformer models (e.g., GPT) revolutionized chatbot capabilities (‚âà2017).\n\nTransformer Architecture is a neural network design that allows models to process sequences (like text) with attention mechanisms, enabling context-aware and parallelized language generation.\n\nTransformers are based on attention mechanisms that allow models to give different weights to inputs they receive, giving ‚Äúmore attention‚Äù to the most relevant information centered in the text sequence, regardless of the order in which it is placed.\n\nTokenization is the process of breaking text into tokens (subwords or characters), which are then used as inputs for LLMs to understand and generate language.\nAttention Mechanisms allow models to focus on the most relevant parts of an input when generating outputs‚Äîcritical for LLMs and multimodal systems.\n\nPowered tools like ChatGPT and Bing Chat, capable of multi-turn conversations and creative output (2020).\n\n\n\nImportance of GPU Innovation\n\nA GPU (Graphics Processing Unit) is a specialized processor designed to accelerate the rendering of images, animations, and video for display on a computer screen. Unlike a CPU (Central Processing Unit), which handles a wide variety of tasks, a GPU is optimized for performing many mathematical operations in parallel‚Äîespecially those involving vectors and matrices.\n\n\n\nEnabling Large-Scale Models:\n\nGPU (Graphics Processing Unit) advancements have been critical in enabling the training and deployment of large language models (LLMs) like GPT-4.\nFaster computation and greater efficiency have made AI more accessible and cost-effective.\n\nModel Accessibility:\n\nEven smaller models can now be deployed on mobile devices, thanks to efficient GPU-based architectures (e.g., Google‚Äôs Palm Prompt2).\n\nDemocratization of AI:\n\nCheaper, more powerful chips allow a broader range of organizations (not just big tech) to build and fine-tune AI models.\nEncourages open-source participation and innovation at scale.\n\n\n\n\nOpen-Source Generative AI Index (GenOS)\n\nThe Generative Open-Source Index (GenOS) is a comprehensive tracker that ranks and evaluates open-source generative AI projects across various modalities and applications.\n\nGenOS helps developers, researchers, and organizations discover, compare, and leverage top-performing open-source GenAI tools.\nThis encourages transparency, collaboration, and accessibility in the generative AI ecosystem.\n\nUses Ranking Criteria: The index evaluates projects based on multiple factors including:\n\nGitHub popularity (stars, forks, issues)\nRecency of updates\nCommunity contributions and forks\nTechnical features and use cases\n\n\n\n\nConnecting GPU‚Äôs to GenOS\n\nGPUs alone don‚Äôt create value ‚Äî Instead, we need systems that organize, orchestrate, and scale AI capabilities across applications.\n\nA Generative AI Operating System (GenOS) builds on GPU-enabled model power. It provides the layer that manages foundation models, prompt engineering, data pipelines, safety mechanisms, and deployment ‚Äî much like how traditional operating systems manage applications and hardware.\n\nIf GPUs are the engines, then GenOS is the driver‚Äôs dashboard and control system ‚Äî turning raw compute into usable, business-ready intelligence.\n\n\n\nTraining Methodologies for LLMs\n\nData Collection:\n\nTraining begins with collecting massive, diverse, and high-quality datasets from sources like web text, books, code, and forums to ensure the model learns varied language patterns.\n\nPretraining:\n\nThe model undergoes unsupervised learning using objectives like next-word prediction (causal language modeling) or masked word prediction (as in BERT), enabling it to learn general language understanding.\n\nMasked word prediction refers to a training technique where certain words in a sentence are intentionally hidden (or ‚Äúmasked‚Äù) and the model is trained to predict the missing words based on the surrounding context.\n\nInput to the model: ‚ÄúThe cat sat on the [MASK].‚Äù\nThe model learns to predict: ‚Äúmat‚Äù\n\n\n\n\n\n\nTraining Methodologies for LLMs Cont. Fine-Tuning (Supervised Training)\n\nAfter a large model is pretrained on broad, general data (often self-supervised), fine-tuning specializes it by training on smaller, labeled datasets.\nAligns the pretrained model with specific tasks (e.g., summarization, question answering, translation, sentiment analysis).\nHow it works:\n\nUses supervised learning: input‚Äìoutput pairs are provided (e.g., an article with its summary).\nAdjusts the weights of the pretrained model slightly (compared to full retraining).\n\nVariants:\n\nFull fine-tuning (all parameters updated).\nParameter-efficient fine-tuning (e.g., LoRA, adapters), where only a fraction of parameters are updated.\n\nBenefit: Much cheaper and faster than pretraining from scratch, while tailoring the model to domain or task.\n\n\n\nTraining Methodologies for LLMs Cross-Modal Embeddings\n\nWhat they are: Representations in a shared vector space that connect different modalities (like text, images, audio, video) by their semantic meaning.\nExample:\n\nAn image of a dog and the word ‚Äúdog‚Äù map close to each other in the embedding space.\nEnables searching for images with text queries (‚Äúgolden retriever playing frisbee‚Äù) or generating captions from images.\n\nWhy it matters:\n\nBreaks down the barrier between modalities.\nPowers applications like multimodal retrieval, captioning, cross-lingual video search, and multimodal reasoning.\n\n\n\n\nTraining Methodologies for LLMs Cont.\n\nReinforcement Learning with Human Feedback (RLHF): A feedback loop where human preferences guide the model‚Äôs responses‚Äîused to make assistant models more aligned, coherent, and safe (e.g., GPT-3.5-turbo, ChatGPT).\n\nRLHF is a specialized fine-tuning methodology that comes after pretraining (and often after supervised fine-tuning). Human feedback is used to adjust the model‚Äôs outputs, rewarding ‚Äúgood‚Äù responses (helpful, safe, aligned) and discouraging ‚Äúbad‚Äù ones (toxic, incoherent, misleading).\nThe goal is to make models more aligned with human values and conversational needs, not just good at predicting the next token.\n\n\n\n\nIn what ways do LLMs handle unstructured, messy web data differently than traditional rule-based systems?\n\n\n\nLLMs vs Rule-based systems\n\n\n\n\nPrompting Using Gen AI\n\nFor extra information review O‚ÄôReilly Video on Prompt Engineering: https://learning.oreilly.com/videos/prompt-engineering/9781835881521/9781835881521-video1_1/\n\n\nRLHF vs Prompt Engineering\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\n\n\nRLHF is part of model training and fine tuning: It shapes the foundation of how the model responds to prompts by making it more ‚Äúinstruction-following‚Äù and aligned.\n\nRLHF = tuning the car‚Äôs steering system so it follows directions well.\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\nPrompt engineering = how you, the driver, actually steer it with the wheel.\n\n\n\n\nPrompt Engineering for Model Customization\n\n\n\nPrompt Engineering for Model Customization\n\n\n\n\nPrompt Engineering\n\nA well-crafted prompt can function like a ‚Äúprogram‚Äù for the LLM, guiding it to generate structured outputs, perform reasoning, or simulate specific roles.\nPrompt Engineering is the art and science of crafting inputs to get desired outputs from AI systems\n\nCore idea: ‚ÄúGarbage in, garbage out‚Äù\nCrucial for improving reliability, tone, and relevance of LLM responses\n\n\n\n\nPrompting Paradigm\n\nPrompting Paradigm refers to the method of adapting LLMs through natural language instructions rather than retraining.\n\nBase models, such as GPT-3 or LLaMA-2, are pretrained on massive amounts of text data. This pretraining allows them to perform a wide variety of general tasks just from prompting.\nAssistant models, like ChatGPT or Claude, take this a step further. They are fine-tuned using Reinforcement Learning with Human Feedback. That means humans guide the model by rewarding helpful responses and discouraging unhelpful ones, shaping it to respond in a more conversational and task-specific way.\n\nWhy it matters\n\nPrompts shape how LLMs behave\nBetter prompts = better outcomes\nUseful across industries\n\n\n\n\nUnderstanding the Prompting Paradigm\n\nPrompting is foundational to in-context learning, where the model draws on prompt examples to infer new tasks dynamically.\n\nChain of Thought refers to a prompting strategy where the model is encouraged to generate step-by-step reasoning before arriving at a conclusion, improving accuracy in logic-based tasks.\nFew-Shot In-Context Learning refers to the ability of LLMs to learn patterns or tasks at inference time based solely on the context provided in a prompt, without requiring additional model training.\n\nPrompting is increasingly used as an interface layer between users and LLMs‚Äîminimizing the need for retraining while enabling flexible task execution.\n\n\n\nPrompt Types\n\n\n\nPrompt Type\n\n\n\n\nPrompt Engineering Iterations and Patterns\n\n\n\nPrompt Engineering Iterations\n\n\n\n\nPrinciples of Prompting\n\n\n\nPrinciples of Prompting\n\n\n\n\nSplit Complex Tasks into Subtasks\n\nMeta Prompt\nYou are an AI assistant that explains prompting paradigms, specifically: instructional, role-based, chain-of-thought, few-shot, and zero-shot.\nFollow these steps:\n\nIdentify which prompting paradigm is relevant to the user‚Äôs request.\nExplain the purpose of that paradigm and how it improves responses.\nProvide a short illustrative example showing the paradigm in action.\nIf asked, find an article related to prompting and summarize it concisely in 3‚Äì4 sentences.\n\nUser\nCan you find an article about the chain-of-thought prompting paradigm and summarize it in 3 sentences with a reference link?\nAnswer\nI found the article ‚ÄúChain-of-Thought Prompting Elicits Reasoning in Large Language Models‚Äù by Google Research. The paper introduces chain-of-thought prompting as a method where models generate intermediate reasoning steps before producing a final answer, which greatly improves performance on arithmetic, commonsense, and symbolic reasoning tasks. It demonstrates that this method is especially powerful when combined with large models, as reasoning accuracy scales with model size.\nüìñ Reference: Wei, J. et al.¬†(2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n\n\nPrompt the Model to Give an Explanation\n\nMeta prompt\n\nYou are a Dash expert that helps users build interactive dashboards in Python. You extract the necessary context from the user‚Äôs request and provide both natural-language explanations and code examples. ALWAYS explain what each part of the code is doing so the user understands how the app works. Take note that app.run_server is deprecated.\n\nUser\n\nCan you make a dashboard that shows the top 3 countries by sales revenue in a bar chart?\n\nAnswer\n\nHere‚Äôs a simple Dash app that displays the top 3 countries by sales revenue in a bar chart. To achieve this, I first created a small pandas DataFrame with sample data for countries and sales revenue. Then I sorted it and selected the top 3 entries. Finally, I built a bar chart using Plotly Express and served it in a Dash layout.\n\n**Provides code to include in python\n\n\n\nAsk for Justification\n\nMeta prompt\nYou are an AI assistant that decides whether a passage demonstrates statistical reasoning by its authors. Classify the passage as one of: Used statistical reasoning, No statistical reasoning, or Unclear. ALWAYS provide a justification that identifies the specific features in the passage that support your decision. Cite the exact part(s) of the passage where the sample size and treatment effect are stated.\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations to the text where the sample size and treatment effect are reported: ‚ÄúIn a randomized controlled trial with 240 participants, the treatment group‚Äôs recovery rate was 12% higher than control (95% CI: 4%‚Äì20%, p = 0.01).‚Äù\nAnswer\nDecision: Used statistical reasoning.\nJustification: The passage demonstrates statistical reasoning by referencing an experimental design (‚Äúrandomized controlled trial‚Äù), providing a sample size (‚Äú240 participants‚Äù), reporting a quantified treatment effect (‚Äú12% higher than control‚Äù), and presenting inferential measures (‚Äú95% CI: 4%‚Äì20%, p = 0.01‚Äù). Together, these show systematic use of statistics to draw conclusions.\n\n\n\nContinuing with an Unclear Example\n\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations (or explain their absence) for the sample size and treatment effect: ‚ÄúThe treatment group recovered more often than the control group.‚Äù\nAnswer\nDecision: Unclear.\nJustification: The passage makes a comparative statement (‚Äúrecovered more often‚Äù), but it does not include statistical details such as the sample size (not provided) or the magnitude of the treatment effect (not quantified). Without these, it is impossible to confirm whether statistical reasoning was applied; the authors only make a descriptive claim rather than presenting inferential evidence.\n\n\n\nLLM Hallucinations\n\nLLM Hallucinations refer to situations where the model generates plausible but false or fabricated content, often due to gaps in training data or the probabilistic nature of text prediction.\n\nPrompt from lawyer: ‚ÄúCan you provide legal cases where the U.S. Supreme Court ruled that AI-generated evidence is inadmissible in court?‚Äú\nChatGPT: ‚ÄúYes. In the case of Smith v. United States, 2022, the Supreme Court ruled that evidence generated by an AI system without human oversight was inadmissible, citing concerns over transparency and accountability.‚Äú\n\nThere is no case called Smith v. United States (2022) that involves AI-generated evidence. The model fabricated a plausible-sounding court case based on the prompt. It may even invent quotes or legal reasoning that sound real but do not exist in any official ruling.\n\n\n\n\n\nReduce Hallucination with Prompt Engineering\n\n\n\nReducing Hallucination\n\n\n\n\nSpotting Hallucinations\n\nHallucinations are confident but factually incorrect responses generated by LLMs. To spot them look for These Red Flags:\n\nToo specific without source: ‚ÄúThe GDP of Argentina in Q3 2023 was exactly $347.2 billion‚Äù (without citation).\nInvented sources or references: Fake articles, court cases, or journal titles.\nContradictions or inconsistencies within a response.\nOverly confident language in uncertain or speculative topics: ‚ÄúThis is definitely true.‚Äù\nMissing common sense: ‚ÄúThe Eiffel Tower is 1,200 miles tall.‚Äù\n\n\n\n\nWhy Prompting Doesn‚Äôt Guarantee Generative AI Is Good at Math\n\nEven if you give a well-crafted prompt, that doesn‚Äôt mean generative AI will solve math problems correctly.\n\nGenerative AI can imitate math, but it doesn‚Äôt understand it.\nFluency does not necessarily equal Accuracy\nLLMs Predict Language, Not Compute Logic\n\nLLMs Lack Internal Verification\n\nLLMs don‚Äôt check their answers unless explicitly prompted to do so.\nUnlike specific math engines, they don‚Äôt ‚Äúknow‚Äù math rules‚Äîthey approximate them from training examples.\n\nErrors Increase with Complexity\n\n\n\nGive AI a Prompt Evaluation Rubric\n\n\n\nEvaluation_Rubric\n\n\n\n\nPaths Forward in Generative AI\n\nFine-Tuning & Domain Adaptation:\n\nTailoring general models to specific industry or task domains by training it on labeled datasets to improve relevance and reliability.\n\nHybrid Approaches:\n\nCombining symbolic AI (rules-based) with generative models may boost explainability and control.\n\nRegulation & Ethical Frameworks:\n\nEncouraging responsible use through AI governance, transparency, and auditable AI practices.\n\nOpen Collaboration:\n\nContinued progress through open-source communities, academic-industry partnerships, and shared benchmarks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Understanding Generative AI</span>"
    ]
  },
  {
    "objectID": "genAI.html#chapter-3-multimodal-generative-ai",
    "href": "genAI.html#chapter-3-multimodal-generative-ai",
    "title": "GenAI",
    "section": "",
    "text": "Reference: Together, Chapter 1 and 3 of Multimodal Generative AI present an overview of the foundations, architectures, and ethical considerations of multimodal generative systems, and examine how emerging multimodal large language models extend these capabilities with advanced cross-modal reasoning and generation‚Äîwhile grappling with challenges in complexity, data integration, and responsible deployment.\n\n\nGenerative AI\n\nGenerative AI refers to a type of AI that creates new content (text, audio, images) based on patterns learned from training data. It contrasts with predictive AI, which forecasts outcomes from historical data.\nSome Examples:\n\nChatGPT ‚Äì conversational text generation\nCodex / GitHub Copilot ‚Äì code generation and completion\nDALL¬∑E ‚Äì image generation from text prompts\nPerplexity AI ‚Äì conversational search + generative synthesis\n\n\n\n\nWhat is Generative AI?\n\n\nGenerative AI represents a Paradigm Shift\n\n\nLM vs LLM\n\nFrom Generative AI to LLMs\n\nGenerative AI is the broad field of AI that can create new content (text, images, audio, video, code).\n\n\n\n\nA Language Model (LM) is a core branch of GenAI focused on predicting and generating text based on patterns in language data.\n\nLM are designed to predict the likelihood of words or phrases in a sentence.\nIts main tasks include generating text, completing sentences, and suggesting new ideas based on context.\nExample, ‚ÄúThe stock market is‚Ä¶‚Äù\n\n\n\n\nA Large Language Model (LLM) is a scaled-up LMs trained on massive datasets with billions of parameters, enabling advanced capabilities in reasoning, summarization, translation, and dialogue.\n\nYou can refer to an LLM as an advanced type of language model that uses deep learning, especially transformer architectures, to understand complex patterns in large text datasets.\nLLMs, like GPT-3 and GPT-4, can generate human-like text and handle a wide variety of language tasks.\n\n\n\n\nMLLM\n\nA Multimodal Large Language Model (MLLM) refers to a special kind of LLM that can work with more than just text‚Äîit can also process and produce images, audio, and video. MLLMs combine different types of data and are capable of tasks like describing images, understanding memes, or generating website code from a visual prompt.\nThese emergent capabilities of MLLMs are rarely seen in conventional models and are viewed as steps toward Artificial General Intelligence (AGI).\nResearchers across academia and industry are rapidly developing MLLMs that aim to match or surpass the capabilities of models like GPT-4V.\n\n\n\nWhy It Matters Now\n\nThere has recently been an explosion of LLMs and MLLM (e.g., GPT-4, Gemini, Claude)\nThere is a convergence of content generation and decision-making in business, healthcare, security, and creative work\nAI brings transformational potential but introduces new risks\n\nAutomates workflows\nEnhances productivity\nIntroduces bias, explainability, control\n\n\n\n\nAI Evolution\n\nEarly Beginnings: Origins trace back to Pascal‚Äôs mechanical calculator (1642) and Ada Lovelace‚Äôs work on analytical engines (1837).\nThese inventions paved the way for automated computation and logic-based operations.\nModern AI Milestones: Progressed through neural networks, statistical machine learning, and deep learning.\nAdvances in hardware (e.g., GPUs) enabled training of large, complex models.\nGenerative AI Breakthroughs: Tools like GPT-4, DALL¬∑E 2, and Copilot have redefined content creation and automation.\nApplications span IT helpdesks, creative arts, medical advice, and recipe suggestions.\nEconomic Impact: Generative AI is projected to increase global GDP by 7% and could replace up to 300 million knowledge worker jobs.\n\n\n\nInspiration for Game Theory in Gen AI\n\nGame Theory inspires Generative AI by modeling competition, cooperation, and strategic decision-making‚Äîcore elements in adversarial training, multi-agent learning, and safe, interactive AI design like in Generative Adversarial Networks (GANs).\nIn GANs, two players‚Äîthe generator and the discriminator‚Äîcompete:\n\nThe generator tries to create realistic data.\nThe discriminator tries to distinguish real data from generated (fake) data.\n\nThis dynamic mirrors a non-cooperative game, where both improve over time through feedback.\nThe equilibrium of this game is when the Generator fools the Discriminator perfectly.\n\n\n\nGame Theory in Gen AI\n\nData-Driven Workflow:\n\nThe process starts with diverse datasets (text, image, sound, etc.).\nTraining involves iterative learning of patterns from this data.\nFine-tuning further adapts models to specific tasks or domains.\n\nFine-Tuning refers to the process of taking a pretrained foundational model and adapting it to a specific task or domain using additional labeled data. Essential for industry-specific applications of Generative AI.\n\n\n\n\n\nReal-World Application Path\n\nAfter training and fine-tuning, the model is used for inference‚Äîi.e., generating outputs from new inputs.\n\nInference refers to the stage where a trained AI model is used to generate outputs (e.g., answering a question, completing a sentence) based on new input.\n\nThese outputs can power apps, APIs, and digital platforms.\n\n\n\nEarly AI: Chatbots Beginnings\n\n1960s Origins: The earliest chatbots were rule-based systems using predefined keyword responses from expert knowledge bases (e.g., ELIZA).\n\nNot scalable or flexible‚Äîresponses were rigid and failed in open-ended or dynamic conversations.\n\nRise of Statistical AI (1990s):\n\nIntroduced machine learning for pattern recognition from labeled text.\nEnabled more adaptive and context-aware text classification.\n\nNeural Networks & NLP Breakthroughs (2010s):\n\nDeep learning and Recurrent Neural Networks (RNNs) enhanced language understanding.\nImproved contextual awareness in sentence-level processing.\n\n\n\n\nEarly AI: Chatbots Beginnings: Transformers & LLMs:\n\nThe introduction of transformer models (e.g., GPT) revolutionized chatbot capabilities (‚âà2017).\n\nTransformer Architecture is a neural network design that allows models to process sequences (like text) with attention mechanisms, enabling context-aware and parallelized language generation.\n\nTransformers are based on attention mechanisms that allow models to give different weights to inputs they receive, giving ‚Äúmore attention‚Äù to the most relevant information centered in the text sequence, regardless of the order in which it is placed.\n\nTokenization is the process of breaking text into tokens (subwords or characters), which are then used as inputs for LLMs to understand and generate language.\nAttention Mechanisms allow models to focus on the most relevant parts of an input when generating outputs‚Äîcritical for LLMs and multimodal systems.\n\nPowered tools like ChatGPT and Bing Chat, capable of multi-turn conversations and creative output (2020).\n\n\n\nImportance of GPU Innovation\n\nA GPU (Graphics Processing Unit) is a specialized processor designed to accelerate the rendering of images, animations, and video for display on a computer screen. Unlike a CPU (Central Processing Unit), which handles a wide variety of tasks, a GPU is optimized for performing many mathematical operations in parallel‚Äîespecially those involving vectors and matrices.\n\n\n\nEnabling Large-Scale Models:\n\nGPU (Graphics Processing Unit) advancements have been critical in enabling the training and deployment of large language models (LLMs) like GPT-4.\nFaster computation and greater efficiency have made AI more accessible and cost-effective.\n\nModel Accessibility:\n\nEven smaller models can now be deployed on mobile devices, thanks to efficient GPU-based architectures (e.g., Google‚Äôs Palm Prompt2).\n\nDemocratization of AI:\n\nCheaper, more powerful chips allow a broader range of organizations (not just big tech) to build and fine-tune AI models.\nEncourages open-source participation and innovation at scale.\n\n\n\n\nOpen-Source Generative AI Index (GenOS)\n\nThe Generative Open-Source Index (GenOS) is a comprehensive tracker that ranks and evaluates open-source generative AI projects across various modalities and applications.\n\nGenOS helps developers, researchers, and organizations discover, compare, and leverage top-performing open-source GenAI tools.\nThis encourages transparency, collaboration, and accessibility in the generative AI ecosystem.\n\nUses Ranking Criteria: The index evaluates projects based on multiple factors including:\n\nGitHub popularity (stars, forks, issues)\nRecency of updates\nCommunity contributions and forks\nTechnical features and use cases\n\n\n\n\nConnecting GPU‚Äôs to GenOS\n\nGPUs alone don‚Äôt create value ‚Äî Instead, we need systems that organize, orchestrate, and scale AI capabilities across applications.\n\nA Generative AI Operating System (GenOS) builds on GPU-enabled model power. It provides the layer that manages foundation models, prompt engineering, data pipelines, safety mechanisms, and deployment ‚Äî much like how traditional operating systems manage applications and hardware.\n\nIf GPUs are the engines, then GenOS is the driver‚Äôs dashboard and control system ‚Äî turning raw compute into usable, business-ready intelligence.\n\n\n\nTraining Methodologies for LLMs\n\nData Collection:\n\nTraining begins with collecting massive, diverse, and high-quality datasets from sources like web text, books, code, and forums to ensure the model learns varied language patterns.\n\nPretraining:\n\nThe model undergoes unsupervised learning using objectives like next-word prediction (causal language modeling) or masked word prediction (as in BERT), enabling it to learn general language understanding.\n\nMasked word prediction refers to a training technique where certain words in a sentence are intentionally hidden (or ‚Äúmasked‚Äù) and the model is trained to predict the missing words based on the surrounding context.\n\nInput to the model: ‚ÄúThe cat sat on the [MASK].‚Äù\nThe model learns to predict: ‚Äúmat‚Äù\n\n\n\n\n\n\nTraining Methodologies for LLMs Cont. Fine-Tuning (Supervised Training)\n\nAfter a large model is pretrained on broad, general data (often self-supervised), fine-tuning specializes it by training on smaller, labeled datasets.\nAligns the pretrained model with specific tasks (e.g., summarization, question answering, translation, sentiment analysis).\nHow it works:\n\nUses supervised learning: input‚Äìoutput pairs are provided (e.g., an article with its summary).\nAdjusts the weights of the pretrained model slightly (compared to full retraining).\n\nVariants:\n\nFull fine-tuning (all parameters updated).\nParameter-efficient fine-tuning (e.g., LoRA, adapters), where only a fraction of parameters are updated.\n\nBenefit: Much cheaper and faster than pretraining from scratch, while tailoring the model to domain or task.\n\n\n\nTraining Methodologies for LLMs Cross-Modal Embeddings\n\nWhat they are: Representations in a shared vector space that connect different modalities (like text, images, audio, video) by their semantic meaning.\nExample:\n\nAn image of a dog and the word ‚Äúdog‚Äù map close to each other in the embedding space.\nEnables searching for images with text queries (‚Äúgolden retriever playing frisbee‚Äù) or generating captions from images.\n\nWhy it matters:\n\nBreaks down the barrier between modalities.\nPowers applications like multimodal retrieval, captioning, cross-lingual video search, and multimodal reasoning.\n\n\n\n\nTraining Methodologies for LLMs Cont.\n\nReinforcement Learning with Human Feedback (RLHF): A feedback loop where human preferences guide the model‚Äôs responses‚Äîused to make assistant models more aligned, coherent, and safe (e.g., GPT-3.5-turbo, ChatGPT).\n\nRLHF is a specialized fine-tuning methodology that comes after pretraining (and often after supervised fine-tuning). Human feedback is used to adjust the model‚Äôs outputs, rewarding ‚Äúgood‚Äù responses (helpful, safe, aligned) and discouraging ‚Äúbad‚Äù ones (toxic, incoherent, misleading).\nThe goal is to make models more aligned with human values and conversational needs, not just good at predicting the next token.\n\n\n\n\nIn what ways do LLMs handle unstructured, messy web data differently than traditional rule-based systems?\n\n\n\nLLMs vs Rule-based systems\n\n\n\n\nPrompting Using Gen AI\n\nFor extra information review O‚ÄôReilly Video on Prompt Engineering: https://learning.oreilly.com/videos/prompt-engineering/9781835881521/9781835881521-video1_1/\n\n\nRLHF vs Prompt Engineering\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\n\n\nRLHF is part of model training and fine tuning: It shapes the foundation of how the model responds to prompts by making it more ‚Äúinstruction-following‚Äù and aligned.\n\nRLHF = tuning the car‚Äôs steering system so it follows directions well.\n\nPrompt engineering builds on RLHF: Once the model has been aligned with RLHF, prompt engineering is how users leverage that alignment in real-world queries.\n\nPrompt engineering = how you, the driver, actually steer it with the wheel.\n\n\n\n\nPrompt Engineering for Model Customization\n\n\n\nPrompt Engineering for Model Customization\n\n\n\n\nPrompt Engineering\n\nA well-crafted prompt can function like a ‚Äúprogram‚Äù for the LLM, guiding it to generate structured outputs, perform reasoning, or simulate specific roles.\nPrompt Engineering is the art and science of crafting inputs to get desired outputs from AI systems\n\nCore idea: ‚ÄúGarbage in, garbage out‚Äù\nCrucial for improving reliability, tone, and relevance of LLM responses\n\n\n\n\nPrompting Paradigm\n\nPrompting Paradigm refers to the method of adapting LLMs through natural language instructions rather than retraining.\n\nBase models, such as GPT-3 or LLaMA-2, are pretrained on massive amounts of text data. This pretraining allows them to perform a wide variety of general tasks just from prompting.\nAssistant models, like ChatGPT or Claude, take this a step further. They are fine-tuned using Reinforcement Learning with Human Feedback. That means humans guide the model by rewarding helpful responses and discouraging unhelpful ones, shaping it to respond in a more conversational and task-specific way.\n\nWhy it matters\n\nPrompts shape how LLMs behave\nBetter prompts = better outcomes\nUseful across industries\n\n\n\n\nUnderstanding the Prompting Paradigm\n\nPrompting is foundational to in-context learning, where the model draws on prompt examples to infer new tasks dynamically.\n\nChain of Thought refers to a prompting strategy where the model is encouraged to generate step-by-step reasoning before arriving at a conclusion, improving accuracy in logic-based tasks.\nFew-Shot In-Context Learning refers to the ability of LLMs to learn patterns or tasks at inference time based solely on the context provided in a prompt, without requiring additional model training.\n\nPrompting is increasingly used as an interface layer between users and LLMs‚Äîminimizing the need for retraining while enabling flexible task execution.\n\n\n\nPrompt Types\n\n\n\nPrompt Type\n\n\n\n\nPrompt Engineering Iterations and Patterns\n\n\n\nPrompt Engineering Iterations\n\n\n\n\nPrinciples of Prompting\n\n\n\nPrinciples of Prompting\n\n\n\n\nSplit Complex Tasks into Subtasks\n\nMeta Prompt\nYou are an AI assistant that explains prompting paradigms, specifically: instructional, role-based, chain-of-thought, few-shot, and zero-shot.\nFollow these steps:\n\nIdentify which prompting paradigm is relevant to the user‚Äôs request.\nExplain the purpose of that paradigm and how it improves responses.\nProvide a short illustrative example showing the paradigm in action.\nIf asked, find an article related to prompting and summarize it concisely in 3‚Äì4 sentences.\n\nUser\nCan you find an article about the chain-of-thought prompting paradigm and summarize it in 3 sentences with a reference link?\nAnswer\nI found the article ‚ÄúChain-of-Thought Prompting Elicits Reasoning in Large Language Models‚Äù by Google Research. The paper introduces chain-of-thought prompting as a method where models generate intermediate reasoning steps before producing a final answer, which greatly improves performance on arithmetic, commonsense, and symbolic reasoning tasks. It demonstrates that this method is especially powerful when combined with large models, as reasoning accuracy scales with model size.\nüìñ Reference: Wei, J. et al.¬†(2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n\n\nPrompt the Model to Give an Explanation\n\nMeta prompt\n\nYou are a Dash expert that helps users build interactive dashboards in Python. You extract the necessary context from the user‚Äôs request and provide both natural-language explanations and code examples. ALWAYS explain what each part of the code is doing so the user understands how the app works. Take note that app.run_server is deprecated.\n\nUser\n\nCan you make a dashboard that shows the top 3 countries by sales revenue in a bar chart?\n\nAnswer\n\nHere‚Äôs a simple Dash app that displays the top 3 countries by sales revenue in a bar chart. To achieve this, I first created a small pandas DataFrame with sample data for countries and sales revenue. Then I sorted it and selected the top 3 entries. Finally, I built a bar chart using Plotly Express and served it in a Dash layout.\n\n**Provides code to include in python\n\n\n\nAsk for Justification\n\nMeta prompt\nYou are an AI assistant that decides whether a passage demonstrates statistical reasoning by its authors. Classify the passage as one of: Used statistical reasoning, No statistical reasoning, or Unclear. ALWAYS provide a justification that identifies the specific features in the passage that support your decision. Cite the exact part(s) of the passage where the sample size and treatment effect are stated.\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations to the text where the sample size and treatment effect are reported: ‚ÄúIn a randomized controlled trial with 240 participants, the treatment group‚Äôs recovery rate was 12% higher than control (95% CI: 4%‚Äì20%, p = 0.01).‚Äù\nAnswer\nDecision: Used statistical reasoning.\nJustification: The passage demonstrates statistical reasoning by referencing an experimental design (‚Äúrandomized controlled trial‚Äù), providing a sample size (‚Äú240 participants‚Äù), reporting a quantified treatment effect (‚Äú12% higher than control‚Äù), and presenting inferential measures (‚Äú95% CI: 4%‚Äì20%, p = 0.01‚Äù). Together, these show systematic use of statistics to draw conclusions.\n\n\n\nContinuing with an Unclear Example\n\nUser\nRead the following passage and decide whether the authors used statistical reasoning. Justify your answer with evidence from the passage, and include citations (or explain their absence) for the sample size and treatment effect: ‚ÄúThe treatment group recovered more often than the control group.‚Äù\nAnswer\nDecision: Unclear.\nJustification: The passage makes a comparative statement (‚Äúrecovered more often‚Äù), but it does not include statistical details such as the sample size (not provided) or the magnitude of the treatment effect (not quantified). Without these, it is impossible to confirm whether statistical reasoning was applied; the authors only make a descriptive claim rather than presenting inferential evidence.\n\n\n\nLLM Hallucinations\n\nLLM Hallucinations refer to situations where the model generates plausible but false or fabricated content, often due to gaps in training data or the probabilistic nature of text prediction.\n\nPrompt from lawyer: ‚ÄúCan you provide legal cases where the U.S. Supreme Court ruled that AI-generated evidence is inadmissible in court?‚Äú\nChatGPT: ‚ÄúYes. In the case of Smith v. United States, 2022, the Supreme Court ruled that evidence generated by an AI system without human oversight was inadmissible, citing concerns over transparency and accountability.‚Äú\n\nThere is no case called Smith v. United States (2022) that involves AI-generated evidence. The model fabricated a plausible-sounding court case based on the prompt. It may even invent quotes or legal reasoning that sound real but do not exist in any official ruling.\n\n\n\n\n\nReduce Hallucination with Prompt Engineering\n\n\n\nReducing Hallucination\n\n\n\n\nSpotting Hallucinations\n\nHallucinations are confident but factually incorrect responses generated by LLMs. To spot them look for These Red Flags:\n\nToo specific without source: ‚ÄúThe GDP of Argentina in Q3 2023 was exactly $347.2 billion‚Äù (without citation).\nInvented sources or references: Fake articles, court cases, or journal titles.\nContradictions or inconsistencies within a response.\nOverly confident language in uncertain or speculative topics: ‚ÄúThis is definitely true.‚Äù\nMissing common sense: ‚ÄúThe Eiffel Tower is 1,200 miles tall.‚Äù\n\n\n\n\nWhy Prompting Doesn‚Äôt Guarantee Generative AI Is Good at Math\n\nEven if you give a well-crafted prompt, that doesn‚Äôt mean generative AI will solve math problems correctly.\n\nGenerative AI can imitate math, but it doesn‚Äôt understand it.\nFluency does not necessarily equal Accuracy\nLLMs Predict Language, Not Compute Logic\n\nLLMs Lack Internal Verification\n\nLLMs don‚Äôt check their answers unless explicitly prompted to do so.\nUnlike specific math engines, they don‚Äôt ‚Äúknow‚Äù math rules‚Äîthey approximate them from training examples.\n\nErrors Increase with Complexity\n\n\n\nGive AI a Prompt Evaluation Rubric\n\n\n\nEvaluation_Rubric\n\n\n\n\nPaths Forward in Generative AI\n\nFine-Tuning & Domain Adaptation:\n\nTailoring general models to specific industry or task domains by training it on labeled datasets to improve relevance and reliability.\n\nHybrid Approaches:\n\nCombining symbolic AI (rules-based) with generative models may boost explainability and control.\n\nRegulation & Ethical Frameworks:\n\nEncouraging responsible use through AI governance, transparency, and auditable AI practices.\n\nOpen Collaboration:\n\nContinued progress through open-source communities, academic-industry partnerships, and shared benchmarks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Understanding Multimodal Generative AI</span>"
    ]
  },
  {
    "objectID": "multipages.html",
    "href": "multipages.html",
    "title": "Setting Up Multiple Pages",
    "section": "",
    "text": "This module introduces how to structure and build multi-page Dash applications. Students begin by organizing a project shell with an app.py entry file, a pages/ folder for layouts, and an assets/ folder for shared CSS. Using dash.register_page(), each page is defined with a layout and a URL path, while the main app layout (in app.py) includes a navigation bar and a dynamic dash.page_container that automatically renders the selected page.The project demonstrates page-specific designs and interactions:\n\nPage 1 implements a responsive grid layout using custom CSS classes for top, middle, and footer blocks.\nPage 2 introduces interactivity and API integration with a callback that retrieves and displays random cat facts from a public API using requests.\n\nBy the end, students can design organized, scalable Dash apps with multiple pages, shared styling, and dynamic content powered by callbacks and APIs.\n\n\nBuilding the Project Shell\nBefore writing any Dash code, spend a few minutes setting up a clean and organized project shell. This structure will make your application easier to maintain, extend, and style as it grows. At a minimum, you‚Äôll create folders for your pages and assets, along with a main entry file that runs the app.\n\nPlace your main entry file (app.py) at the root of the project.\n\nCreate a pages/ folder to store your individual page layouts.\n\nAdd an assets/ folder for custom CSS or other static files ‚Äî Dash automatically loads files from this directory.\n\nOptionally include additional helper scripts or configuration files as needed.\n\nProject Structure:\nmy_dash_app/ ‚îÇ ‚îú‚îÄ‚îÄ app.py ‚îÇ ‚îú‚îÄ‚îÄ pages/ ‚îÇ ‚îú‚îÄ‚îÄ home.py ‚îÇ ‚îú‚îÄ‚îÄ page1.py ‚îÇ ‚îî‚îÄ‚îÄ page2.py ‚îÇ ‚îî‚îÄ‚îÄ assets/ ‚îî‚îÄ‚îÄ style.css\n\nInitialize the App\n\nimport dash\nfrom dash import dcc, html\nimport dash_bootstrap_components as dbc\n\n#Initialize app\napp = dash.Dash(__name__, use_pages=True, supress_callback_exceptions=True, title=\"Multi-Page-App\")\nserver = app.server #for deployment\n\nuse_pages=True tells Dash to scan the pages/ folder for registered pages.\nsuppress_callback_exceptions=True helps when callbacks span multiple pages.\n\n\nRegister Each Page\n\nimport dash\nfrom dash import html\n\ndash.register_page(__name_,path=\"/\")\n\nlayout = html.Div([...])\n\n\nimport dash\nfrom dash import html\n\ndash.register_page(__name_,path=\"/page1\", name =\"Page 1\")\n\nlayout = html.Div([...])\n\n\nimport dash\nfrom dash import html\n\ndash.register_page(__name_,path=\"/page2\", name =\"Page 2\")\n\nlayout = html.Div([...])\n\ndash.register_page() is used to register a Python file as a page in a multipage Dash app. It tells Dash the page‚Äôs name, URL path, and optional settings like order, title, or description.\n\nFor example, dash.register_page(__name__, path=‚Äú/‚Äù) tells Dash that this file represents a page in the app.\n__name__ ensures the page is uniquely identified.\npath=‚Äú/‚Äù makes this page the home page (root URL).\nEach page file in the pages/ folder needs this call plus a layout variable that defines the page‚Äôs content.\n\n\n\nCreate the Layout in app.py\n\nThis layout ties everything together: a navigation bar for switching pages and a container to render them dynamically.\nNavigation Bar (dbc.NavbarSimple)\n\nCreates a simple top navigation bar with links to each page.\ndbc.NavLink(‚ÄúHome‚Äù, href=‚Äú/‚Äù, active=‚Äúexact‚Äù) defines clickable links.\n\nactive=‚Äúexact‚Äù\n\nEnsures a link is highlighted only when the current URL matches exactly.\nPrevents the Home link (‚Äú/‚Äù) from being active on all pages.\n\ndash.page_container\n\nThis is where the content of the current page (registered with dash.register_page) is displayed.\nActs as a placeholder that updates automatically when the user clicks a link.\n\napp.run(debug=True)\n\nRuns the app locally with hot-reload, so changes appear immediately without restarting.\nOnly include the app.run(‚Ä¶) statement in app.py. Do not add a run command in any of the subpages. The application should be started once from app.py, and it will automatically load all registered pages from the pages/ folder.\n\n\n\napp.layout = html.Div([\n   #Simple navigation bar\n   dbc.NavbarSimple(\n      children=[\n         dbc.NavLink(\"Home\",href=\"/\",active=\"exact\"),\n         dbc.NavLink(\"Page 1\",href=\"/page1\",active=\"exact\"),\n         dbc.NavLink(\"Page 2\",href=\"/page2\",active=\"exact\")\n      ],\n      brand=\"Multi-Page App\",\n   ),\n   dash.page_container\n])\n\nif __name__ == \"__main__\":\n   app.run(debug=True)\n\n\n\nAdd a Layout to home.py\n\nEach subpage should define its content using a layout variable, while the main file (app.py) uses app.layout to define the overall structure of the app, including navigation and the page container.\nYou may also need an app.layout if you have callbacks, since Dash requires a defined layout to reference components in the callback functions.\n\n\nimport dash\nfrom dash import html\n\ndash.register_page(__name__,path=\"/\")\n\nlayout = html.Div([\n   html.H2(\"Welcome to the Home Page\"),\n   html.P(\"This is a simple multipage Dash project.\")\n])\n\n\n\nAdd Styles to style.css\n\nThe stylesheet customizes the hyperlinks (a tags) to look like styled buttons instead of plain links ‚Äî giving them spacing, a border, background color, rounded corners, and hover effects for better visibility and user interaction.\nIn CSS, !important is used to override normal style rules and priority. When applied to a property, it tells the browser: ‚Äúuse this style no matter what, even if other rules conflict.‚Äù\n\n\nbody {\n    background-color: #DFEBE0 !important;\n    font-family: Arial, sans-serif;\n}\n\nh2{\n    color: #2c3e50;\n}\np{\n    font-size: 16px;\n    line-height: 1.4;\n}\n\na {\n    display:inline-block;\n    margin:18px;\n    text-decoration: none;\n    border: 2px solid #ffffff;\n    border-radius:6px;\n    padding: 10px 20px;\n    background-color: #2c3e50;\n    color: #ffffff;\n\n}\n\na:hover{\n    text-decoration: underline;\n    background-color: #65Ab6E;\n}\n\n\nAdd Multi-Item Layout to page1.py\n\nOrganizing the layout into 1 column at the top, 2 columns in the middle, and a footer.\nTop Section\n\nOne full-width block (‚ÄúTop (1 column)‚Äù).\n\nMiddle Section\n\nTwo side-by-side blocks: ‚ÄúMiddle Left‚Äù and ‚ÄúMiddle Right‚Äù.\n\nFooter\n\nA single full-width block labeled ‚ÄúFooter‚Äù.\n\nCSS Classes\n\nclassName=‚Äúblock‚Äù and className=‚Äúrow-2‚Äù connect to the stylesheet in assets/ to control layout and style.\nblock‚Äìtop / block‚Äìfooter are modifier classes that adjust specific blocks (like making the top taller, the footer shorter, or giving them different visual emphasis).\n\n\n\nimport dash\nfrom dash import html\n\ndash.register_page(__name__, path=\"/page1\", name=\"Page 1\")\n\nlayout = html.Div([\n    ##Top Row\n    html.Div(\"Top Row: with 1 Column\", className=\"block block-top\"), \n    \n    ##Middle 2 column\n    html.Div([\n        html.Div(\"Middle Left\", className=\"block\"),\n        html.Div(\"Middle Right\", className=\"block\")\n    ], className=\"row-2\"),\n    \n    ##Footer\n    html.Div(\"Footer\", className=\"block block-footer\")\n    \n], className=\"page1-grid\")\n\n\n\nStyle Page 1 Classes\n\nThis CSS is defining the visual layout for your Page 1:\n\nA flexbox column layout (.page1-grid) that stacks major sections (top, middle, footer).\n\ndisplay: flex turns the container into a flexbox, giving flexible alignment and spacing for child elements.\nflex-direction: column stacks children vertically (like top ‚Üí middle ‚Üí footer) which is useful for high-level page sections.\n\nA grid layout (.row-2) that splits the middle section into two side-by-side blocks, which creates a visual block styling to make the layout easy to see.\n\ndisplay: grid turns the container into a grid layout system.\ngrid-template-columns: 1fr 1fr splits into two equal columns (1fr = one ‚Äúfraction‚Äù of available space).\nUsed here for the middle row, so ‚ÄúMiddle Left‚Äù and ‚ÄúMiddle Right‚Äù sit side by side.\n\nThe @media adjusts for small screens.\n\nResponsive behavior: the two-column grid collapses into one column on narrow screens.\n\n\n\n/*Page 1 styles for blocking elements */\n.page1-grid{\n    display:flex;\n    flex-direction: column;\n    padding: 12px;\n    gap:12px;\n}\n\n.row-2 {\n    display: grid;\n    grid-template-columns: 1fr 1fr;\n    gap: 12px;\n}\n\n.block{\n    border: 2px dashed #cbd5e1;\n    border-radius: 8px;\n    background-color: #F5F7Fa;\n    color: #334155;\n    min-height: 120px;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    font-weight: 600;\n}\n\n.block-top{\n    min-height: 150px;\n}\n\n.block-footer{\n    min-height: 80px;\n}\n\n@media (max-width:768px){\n    .row-2{grid-template-columns: 1fr;}\n}\n\n\nAdjust page2.py to have a callback and a link to an API\n\nLayout\n\nA header (H2), a short description (P), and a button (id=‚Äúbtn-cat‚Äù).\nA dcc.Loading wraps a Div(id=‚Äúcat-fact‚Äù) so you get a spinner while data loads.\nNotice there is no app.run(‚Ä¶) here‚Äîonly in app.py.\n\nCallback wiring\n\n@callback(Output(‚Äúcat-fact‚Äù, ‚Äúchildren‚Äù), Input(‚Äúbtn-cat‚Äù, ‚Äún_clicks‚Äù), prevent_initial_call=True)\nWhen the button is clicked, the callback runs.\nprevent_initial_call=True stops an API call on first page load.\nThe callback returns content for the children of #cat-fact.\n\nAPI call & response\n\nrequests.get(‚Äúhttps://catfact.ninja/fact‚Äù, timeout=5) fetches a random cat fact.\nr.raise_for_status() throws if the HTTP status indicates an error.\nr.json().get(‚Äúfact‚Äù, ‚ÄúNo fact found.‚Äù) extracts the text.\nReturns html.Div(fact) to display the fact.\n\nError handling\n\nexcept requests.RequestException catches network/HTTP timeouts or failures and shows a readable error message.\n\nNotes\n\nRequires pip install requests.\nIDs in the layout (btn-cat, cat-fact) must match the IDs in the callback.\n\n\n\nfrom dash import html, register_page, dcc, callback, Output, Input\nimport requests\n\nregister_page(__name__, path=\"/page2\", name=\"Page 2\")\n\nlayout = html.Div([\n    html.H2(\"Page 2\", className=\"page-title\"),\n    html.P(\"Click to fetch a random cat fact from a public API\", className=\"page-subtitle\"),\n    html.Button(\"Get Cat Fact\", id=\"btn-cat\", n_clicks=0),\n    dcc.Loading(html.Div(id=\"cat-fact\")) \n], className=\"page2-wrap\")\n\n\n@callback(\n    Output(\"cat-fact\", \"children\"),\n    Input(\"btn-cat\", \"n_clicks\")\n)\n\ndef get_cat_fact(n):\n    try:\n        r = requests.get(\"https://catfact.ninja/fact\", timeout=5)\n        r.raise_for_status()\n        fact = r.json().get(\"fact\", \"no fact found\")\n        return html.Div(fact)\n    except requests.RequestException as e:\n        return html.Div(f\"Error contacting API: {e}\")\n\n\n\nAdd Styles for page 2\n\nCreating the overall blocking of the page\nDefines a centered page container with a reasonable max width and padding.\nStyles a primary title to be larger and more prominent for hierarchy.\nStyles a subtitle/lead with lighter color and added spacing below the title.\nUses reusable utility classes to separate layout from content, so the look can be reused across pages.\n\n/* ---Page 2 strong \"blocked\" look ---*/\n.page2-wrap{\n   max-width: 840px;\n   margin: 0 auto;\n   padding: 16px;\n}\n\n.page-title{\n   font-size: 28px;\n   color: #1f2937;   /*dark slate*/\n   margin-top: 6px;\n}\n\n.page-subtitle{\n   color: #475569;  /*slate*/\n   margin-top: 14px;\n}\n\n\nStyle the Button and the Cat-fact id‚Äôs\n\nStyles the primary action (button) and the result area as clear, block-like UI elements with strong borders, padding, and small corner radii for emphasis and readability.\nEstablishes interactive feedback (hover/active states) so users see immediate visual responses to clicks/rollovers.\nUses IDs for unique elements (e.g., one result container) and classes for reusable behaviors (e.g., button hover/active styling).\nIncreases legibility and touch targets with larger font sizes, adequate spacing, and a minimum height to prevent layout jumpiness as content loads.\nKeeps styling centralized in an external stylesheet, separating presentation from Dash layout/callback code and ensuring consistency across pages.\n\n/*cat fact id styling --- id's are styled with the #id while classes have the decimal. \nbefore the class*/\n\n#btn-cat{\n    display:inline-block;\n    font-size: 18px;\n    padding: 10px 18px;\n    border: 2px solid #1f2937;\n    border-radius: 8px;\n    background-color: #0ea5e9;\n    color:#ffffff;\n}\n\n#btn-cat:hover{\n    background-color: #1b4355;\n}\n\n#cat-fact{\n    display:block;\n    margin-top:14px;\n    padding: 14px 16px;\n    background-color: #ffffff;\n    color: #0f172a;\n    font-size:18px;\n    line-height: 1.5;\n    border: 2px solid #1f2937;\n    border-radius: 8px;\n    min-height: 72px;\n\n}",
    "crumbs": [
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Setting Up Multiple Pages</span>"
    ]
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "AI & Data Ethics",
    "section": "",
    "text": "This section surveys the ethical foundations and cybersecurity dimensions of AI, moving from first principles (autonomy, justice, beneficence, non-maleficence, explicability) to practical guardrails for responsible design. It introduces the CIA+A triad (confidentiality, integrity, accountability, availability) and maps key risk areas‚Äîbias in data/labels/algorithms, digital amplification and echo chambers, deepfakes, misuse in autonomous systems, AI-enabled fraud, and militarization. The focus then turns to governance and transparency: explainable AI, zero-trust security, human-in-the-loop oversight, and continuous auditing across demographics. Finally, it clarifies scholarly practice‚Äîhow to cite generative AI and how to verify and format sources‚Äîto protect credibility while deploying AI ethically at scale.\n\n\nReference:\nRead Chapters 3 and 4 in Ravindran, Anton. (2022).\nWill AI Dictate the Future? From Successful Leaders and Managers from Around the World.\nMarshall Cavendish International (Asia) Private Limited.\nAvailable via ProQuest Ebook Central.\n\n\nEthics and Cybersecurity Issues with AI\n\nThe ethics of AI is a relatively new area and fast-changing as AI advances. Ethics is sometimes viewed as too abstract for the technical concerns of data scientists and AI specialists.\n\nFrom a technical perspective, those who design AI systems need to take steps to avoid any potential risks and deploy contingency measures to mitigate any risk and biases in AI algorithms.\nFrom an organizational perspective, there must be robust procedures, guidelines and frameworks to ensure the ethical use of AI.\n\nDiscussion points:\n\nWho is responsible when AI makes a harmful decision?\nWho defines ‚Äúgood‚Äù use?\nHow much control should platforms have?\n\n\n\n\nCore Principles of Ethical AI\n\nAutonomy ‚Äì Respect individual decision-making\n\nThe right of individuals to make informed, uncoerced decisions about how AI systems affect them. This includes clear options, meaningful consent, and respect for personal agency.\n\nJustice ‚Äì Ensure fairness and eliminate bias\n\nThe obligation to design and deploy AI systems that treat all individuals equitably. This means actively identifying and mitigating bias, ensuring access and fairness across different groups.\n\nBeneficence ‚Äì Promote well-being\n\nThe principle of using AI to actively enhance human well-being‚Äîpromoting outcomes that support health, education, safety, and social good.\n\nNon-maleficence ‚Äì Avoid harm\n\nThe duty to prevent harm, such as discriminatory outcomes, misuse of personal data, or unintended consequences of automation. It requires foresight and safeguards.\n\nExplicability ‚Äì Make AI systems transparent and understandable\n\nThe commitment to transparency and accountability‚Äîmaking AI systems understandable to users, regulators, and stakeholders. This includes explaining how decisions are made and who is responsible.\n\n\n\n\nResponsibility in AI\n\nResponsibility in AI development involves designing, deploying, and governing AI in ways that uphold human rights, dignity, and societal values.\nIt emphasizes accountability, traceability, fairness, and ethical foresight.\n\n\n\n\nResponsibility in AI\n\n\n\n\nWhat is Cybersecurity Ethics? CIA+A Triad\n\nUnderstanding these pillars helps us design systems that are both secure and ethically responsible.\n\nConfidentiality ‚Äì Responsible individuals and organizations must protect sensitive data from unauthorized access and ensure that only authorized individuals have access to sensitive data.\nIntegrity - Responsibility means ensuring that data and systems are accurate, consistent, and protected from tampering.\nAccountability - Responsibility is the foundation of accountability where we ensure that actions can be traced back to individuals or systems responsible for them.\nAvailability - Being responsible means designing systems that are resilient, redundant, and responsive, so that users can access the data and tools they need without disruption.\n\n\n\n\nCybersecurity as an Ethical Issue\n\nAI depends on massive datasets which makes it prime targets for attacks.\n\n\n\nEthical duties:\n\nPrevent breaches\nDisclose quickly\nProtect user trust\n\n\n\n\nCase: Equifax breach exposed data of 147M people. Executives sold stock before disclosure.\n\n\n\nChallenges in AI Ethics\n\nAmplification ‚Äì harmful content spreads fast.\nBias ‚Äì in data, labeling, algorithm, and human.\nSecurity ‚Äì data breaches, misuse of access.\nControl ‚Äì platforms enabling harmful use.\nInequality ‚Äì tech-driven disparities grow.\n\n\n\n\nChallenge in AI Ethics\n\n\n\n\nDigital Amplification & Echo Chambers\n\nAlgorithms optimize for clicks and engagement, not truth.\nReinforces user bias (e.g., political extremism).\nCreates self-reinforcing echo chambers through targeting.\n\nExample: Facebook groups fueling misinformation about [XYZ].\n\n\n\n\nThe vast scale, scope, and learning potential of the operating models that embed these algorithms means that harmful messages can be tailored and targeted to, literally, hundreds of millions of people.\nEcho chamber effects refers to where the individuals engaged only with posts that supported their existing views, dismissed opposing perspectives, and joined communities that further reinforced their biases.\n\n\n\nData and Labelling Bias\n\nData Bias\n\nData bias occurs when the training data used for an AI model is unrepresentative, incomplete, or skewed, leading to unfair or inaccurate outcomes.\nTypes of data bias include:\n\nRepresentation bias ‚Äì certain groups or features are over- or under-represented.\n\nSample bias ‚Äì data does not reflect the full population.\nWho is (not) in the data.\n\nMeasurement bias ‚Äì how features or outcomes are recorded is flawed.\n\nHow the data is captured.\n\n\nExample: A facial recognition system trained mostly on lighter-skinned faces may perform poorly on darker-skinned individuals.\n\nLabelling Bias\n\nBias doesn‚Äôt just come from data selection‚Äîit also comes from how data is labeled.\nCommon in crowd-sourced and expert-tagged data.\nExamples:\n\nImage: ‚ÄúWoman & man‚Äù labeled as ‚Äúboss and subordinate.‚Äù\nGender & race bias in facial recognition tagging.\n\n\n\n\n\nAlgorithm and Human Bias\n\nAlgorithm Bias\n\nSystematic and repeatable errors in an AI system caused by flaws in the algorithm itself, such as how it processes data, prioritizes variables, or makes predictions.\nOften originates from how the model is constructed or optimized.\nCan occur even with unbiased data.\nExample: A hiring algorithm that ranks candidates based on keywords from past resumes, unintentionally favoring certain backgrounds.\n\nHuman or Cognitive Bias\n\nBias introduced by developers, data labelers, or users due to personal assumptions, stereotypes, or mental shortcuts.\nInfluences how data is collected, labeled, or interpreted.\nExample: Labelers tagging an image of a man and woman as ‚Äúboss and assistant‚Äù based on stereotype, not actual content.\nCan embed unconscious societal prejudices into AI systems.\n\n\n\n\nSecurity: Abuse or Misuse of AI\n\nDeepfakes are synthetic media‚Äîusually videos, audio, or images‚Äîthat use artificial intelligence (AI), particularly deep learning, to manipulate or fabricate visual and audio content so realistically that it appears authentic.\nDeepfakes typically involve face-swapping, voice cloning, or full-body synthesis, making it seem as though a person said or did something they never did.\nExample: https://ew.com/celebrity/paris-hilton-deepfake-tom-cruise-elton-john-britney-spears-hold-me-closer-tiny-dancer\n\n\n\nAbuse of AI: Deepfakes\n\nCelebrity Face Swaps on YouTube\n\nExample: Jim Carrey‚Äôs face swapped into The Shining, or Tom Cruise TikTok deepfakes.\nUsed for entertainment, but often without consent.\n\nPolitical Disinformation\n\nExample: A deepfakeof Ukrainian President Volodymyr Zelenskyy in 2022 appearing to surrender‚Äîintended to mislead during wartime.\nDangerous in conflict or election contexts.\n\nSynthetic Audio of Public Figures\n\nExample: Fake voice recordings of Barack Obama created to warn about the dangers of misinformation.\nHighlighted by projects like Buzzfeed‚Äôs collaboration with actor Jordan Peele.\n\nFinancial Fraud\n\nCriminals used AI to impersonate the voice of a German parent-company CEO, tricking the UK CFO into transferring ‚Ç¨220,000 to a fraudulent account\n\n\n\n\nMisuse of AI with Autonomous Vehicles\n\nWhen an AV chooses between hitting a pedestrian or crashing, who is responsible? The AI? The manufacturer?\nCybercriminals could remotely hijack or disable AVs, creating safety threats or demanding ransoms.\n\n\n\nTesla ‚ÄúAutopilot‚Äù misuse\n\nUsers filmed sleeping or playing games on their phone while Autopilot was active‚Äîdespite warnings that hands must stay on the wheel. Resulted in crashes and fatalities.\n\nUber AV fatality (2018)\n\nA pedestrian was killed when Uber‚Äôs test AV failed to classify her as a person crossing the street. Safety driver was distracted. Raised questions about accountability and insufficient safeguards.\n\nPhantom braking in self-driving cars\n\nSome vehicles unexpectedly brake for non-existent obstacles, creating rear-end collision risk.\n\n\n\n\nLack of Control: Regulatory and Design Issues with Autonomous Vehicles\n\nLack of standardized safety testing\n\nAV companies vary in how they test and report safety, leaving consumers vulnerable to inconsistent protections.\n\nEthical dilemma scenarios not resolved\n\n‚ÄúTrolley problem‚Äù cases remain unsolved in AI decision trees (e.g., saving passenger vs.¬†pedestrians)\n\n\n\n\nWhat decisions do programmers make?\n\n\n\nControl ‚Äì platforms enabling harmful use\n\n‚ÄúControl‚Äù is about the ethical responsibility and capability of platform owners (like Meta, Google, TikTok) to prevent misuse of their technologies.\nThe lack of governance mechanisms over how platforms are used by third parties.\nThe difficulty of enforcing ethical use at scale.\nExamples include:\n\nThe Cambridge Analytica scandal(Facebook data misuse).\nOpen APIs or app ecosystems being exploited in ways platform designers didn‚Äôt intend (e.g., Google+ 2018 API Breach).\nRogue actors use platforms for coordinated harm:\n\nFailure to prevent livestreaming of violent events (e.g., Christchurch).\nRussian interference via bots & fake accounts.\n\n\nPlatforms struggled to take content down quickly.\nHighlights vulnerabilities of scale and openness.\n\n\n\nAI vs AI: Cybersecurity Arms Race\n\nAI as Both Weapon and Shield:\n\nWhile AI strengthens cybersecurity defenses, cybercriminals also exploit AI to develop smarter, faster, and more personalized attacks like automated phishing and AI-driven brute force attacks.\n\nAI Fighting AI:\n\nThe only scalable way to counter AI-enhanced cyber threats is with AI-enabled defense systems‚Äîmodels that learn from evolving attack patterns and adapt in real-time to new threats.\n\n\n\n\nEmerging Threats Like Data Poisoning:\n\nAttackers can compromise machine learning models by feeding them manipulated or false data, leading to incorrect predictions‚Äîposing long-term and difficult-to-detect risks.\n\nSecurity of AI Systems Themselves:\n\nAI models and training data are vulnerable to breaches; protecting these assets requires encryption, access controls, and data versioning to roll back compromised models.\n\n\n\n\nAI-driven Fraud\n\nAI enables fraudsters to act faster and more covertly, intercepting communication and evading detection, often keeping victims unaware of breaches until it‚Äôs too late.\nWeaponization of AI for Identity Theft\n\nCybercriminals use AI to mimic victims‚Äô online behavior and steal personal data through phishing, synthetic identity creation, and account takeovers.\n\nMassive Financial Impact\n\nVisa prevented 80 million fraudulent transactions worth 40 billion worth in 2023, driven by increased digital transactions and sophisticated AI-enabled scams.\n\n\n\n\nIntelligent Warfare\n\nAI-Powered Combat Systems\n\nAI is transforming warfare through autonomous drones, real-time targeting, satellite surveillance, and smart munitions that can outperform human pilots and strike with precision.\n\nHypersonic and Autonomous Technologies\n\nCountries like China and Russia are using AI to develop hypersonic missile engines and autonomous logistics systems, enhancing speed, accuracy, and military dominance.\n\nGlobal Security Implications\n\nThe rapid militarization of AI raises concerns about untraceable cyberattacks, satellite vulnerabilities, and the ease with which AI-generated weapons (even chemical ones) could be misused.\n\n\n\n\nMaking the Blackbox Transparent\n\n\n\nExplainable AI\n\n\n\n\nAI Governance: Have Explainable AI\n\nExplainable AI, sometimes known as Interpretable AI, refers to methods and techniques that enable humans to understand the results generated by an AI algorithm, hence improving on the governance and ethical dimension of AI.\n\nExplanation: Systems should provide evidence or reason(s) for all output.\nMeaningful: Systems should offer explanations that are understandable to individual users.\nAccuracy: The answer should accurately describe the system‚Äôs process for generating the output.\nKnowledge Limits: The system should only operate under limits or conditions for which it was designed.\n\n\n\n\nSecurity That Thinks\n\nAI security is a set of tools and techniques that leverages AI to autonomously identify any malicious behavior and takes action to defend against potential cyber-threats based on similar or previous activity.\n\nReal-Time Pattern Recognition and Anomaly Detection:\n\nBy analyzing vast volumes of data in real time, AI can identify patterns and anomalies, enhancing threat intelligence and supporting proactive cybersecurity measures.\n\nZero Trust Architecture:\n\nAI enables robust ‚Äúzero trust‚Äù security frameworks using real-time multifactor authentication that incorporates behavioral data such as device ID, location, facial recognition, and even typing patterns.\n\nAugmenting Analysts with Explainability:\n\nExplainable AI helps security teams understand and trust automated decisions, enhancing transparency and complementing human oversight in high-stakes cybersecurity scenarios.\n\n\n\n\n\nDesigning Ethical, Human-Centered AI Systems\n\nInvolve diverse stakeholders early\n\nHelps identify potential blind spots, harms, and unintended consequences before deployment.\n\nUse interpretable models when stakes are high\n\nChoose models that offer transparency (e.g., decision trees, linear models, SHAP) in areas like healthcare, finance, or criminal justice.\nWhen lives or rights are on the line, explainability builds trust and enables accountability.\n\nInclude human-in-the-loop checks and balances\n\nDesign systems where human judgment remains part of critical decisions‚Äîespecially in ambiguous or high-risk situations.\nAutomation should support, not replace, nuanced decision-making.\n\nRegularly audit for unintended harms\n\nMonitor the system‚Äôs impact after deployment, including performance across demographic groups.\nEven well-designed systems can evolve in harmful ways‚Äîongoing auditing is key to ethical resilience.\n\n\n\n\nAPA Citations\n\nIf you quote or paraphrase ChatGPT‚Äôs output, cite it as a source.\nIf ChatGPT Suggests a Citation\n\nDo NOT trust automatically suggested citations without verification.\n\nInstead:\n\nLocate the original source (article, book, report, etc.).\nConfirm details (author, title, year, publisher, DOI/URL).\nCite the verified source, not ChatGPT‚Äôs suggestion.\nIf you cannot verify, do not include it.\n\nKey Takeaways\n\nCite ChatGPT when you directly use its text.\nCite the verified original source when ChatGPT points you to one.\nAlways check accuracy‚Äîyour credibility depends on it.\n\nTo cite ChatGPT use:\n\nOpenAI. (2025). ChatGPT [Large language model]. https://chat.openai.com/\n\nExample in-text citation:\n\nChatGPT suggested that ‚Äú‚Ä¶‚Äù (OpenAI, 2025).\n\n\n\n\nTrimming a URL for APA style\n\nAPA treats ChatGPT as a software (like statistical packages) when you are citing it in your reference list.\nAPA recommends providing the direct, retrievable URL, not the tracking code.\n\nFor example: instead of https://www.journal.com/article/12345?chat-gpt\nYou can trim it to https://www.journal.com/article/12345\n\nBefore making the change\n\nAlways double-check the link in a browser or in your library database.\nIf it works without the tag ‚Üí remove it.\nIf only the tagged link works (rare), keep it ‚Äî but note it‚Äôs unusual.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>AI & Data Ethics</span>"
    ]
  },
  {
    "objectID": "storytelling.html",
    "href": "storytelling.html",
    "title": "Human-centered Storytelling",
    "section": "",
    "text": "This section frames data visualization as human-centered storytelling: choosing visuals that are truthful, interpretable, and purposeful for a specific audience. Building on Wilke (2019), it links aesthetic choices (position, color, shape, size) to perception, then pairs them with sound research methods‚Äîdistinguishing description, prediction, and explanation while avoiding common traps (bad proportions, misleading color scales, poor aspect ratios). You‚Äôll learn to separate correlation from causation, surface confounds and subgroup effects, and recognize reasoning errors (cherry-picking, arbitrary thresholds, misreading axes). Finally, it introduces a practical storytelling workflow‚ÄîWho/What/How ‚Üí Big Idea ‚Üí 3-minute story‚Äîso your graphics do more than decorate: they clarify decisions and drive action.\n\n\nReference:\nWilke, C. O. (2019). Fundamentals of Data Visualization.\nO‚ÄôReilly Media. ISBN: 9781492031086.\n\n\nData Visualization and Why Good Research Methods Matter\n\nWilke (2019) suggests that data visualization combines both art and science.\nIt must accurately represent the data without misleading, while also being visually appealing.\nMisrepresentation, like making unequal values appear similar, undermines the science.\nPoor aesthetics, such as distracting colors or imbalanced design, can hinder interpretation and obscure the message.\n\n\n\nImportance of Research Methods in Data Visualizations\n\nDescribe behavior\n\nIdentify trends, patterns, and outcomes in data.\nUse visualizations to summarize patterns in a clear, audience-friendly way (e.g., bar charts of user activity).\n\nPredict behavior\n\nUse past data to anticipate future actions or outcomes.\nDesign visuals that highlight trends and forecasts, helping stakeholders make informed decisions (e.g., line charts showing sales projections).\n\nExplain behavior\n\nGo beyond correlation to investigate causal relationships.\nGround visualizations in methods that distinguish causation from correlation, avoiding misleading graphics (e.g., control vs.¬†treatment comparison with appropriate labels).\n\nUnderstand behavior\n\nBuild a deeper theoretical and contextual understanding of why patterns occur.\nUse storytelling and layered visuals to provide context that clarifies motivations, environments, or external influences (e.g., dashboards that combine time, geography, and user type).\n\n\n\n\n\nVisualization\n\n\n\n\nAesthetics and Types of Data\n\nLine Width: Lines ranging from thin to thick.\nLine Type: Solid, dashed, dotted, and dash-dot styles.\nShape: Examples of circle, square, diamond, and triangle markers.\nSize: Circles of increasing size.\nColor: A palette of orange, blue, green, and yellow.\nPosition: A coordinate system with x and y axes.\n\nAxes are perpendicular and evenly spaced.\nSimple visualizations need data points placed in distinct locations.\n\n\n\n\n\nAesthetics\n\n\n\n\nColor in Data Viz\n\nThere are three fundamental use cases for color in data visualizations: we can use color to distinguish groups of data from each other, to represent data values, and to highlight.\n\nDistinguish groups: Use color to separate categories without a natural order, like countries on a map or product brands.\nRepresent values: Use color scales to show quantitative data such as income, temperature, or speed.\nHighlight: Use color to draw attention to key elements or categories that support the story.\n\n\n\n\n\nData_Viz\n\n\n\n\nCommon Pitfalls of Color Use\n\nColor is powerful but must be purposeful, clear, and non-distracting.\nPoor color choices can obscure or distort data rather than illuminate it.\n\nEncoding Too Much Information ‚Äì Don‚Äôt assign unique colors to too many categories; use direct labeling or groupings instead.\nDistracting Color Choices ‚Äì Avoid coloring for decoration or using overly saturated hues that obscure the data.\n\nExample: rainbow-colored bars ‚Äî visually striking but purposeless.\n\nMisleading Color Scales ‚Äì Don‚Äôt use nonmonotonic scales like rainbow, which distort value differences and emphasize arbitrary features.\n\nA monochromatic color scheme uses different shades, tints, or tones of a single hue, while a non-monochromatic color scheme uses multiple distinct hues.\n\nNot Designing for Color-Vision Deficiency ‚Äì Always choose color schemes that remain clear for color-blind viewers and test with simulators.\n\nRed‚Äìgreen (deuteranomaly/deuteranopia, protanomaly/protanopia).\nBlue‚Äìyellow (tritanomaly/tritanopia).\n\n\n\n\n\nThe Good, The Bad, The Ugly, and the Just Wrong\n\nUgly: A figure that has aesthetic problems but otherwise is clear and informative\nBad: A figure that has problems related to perception; it may be unclear, confusing, overly complicated, or deceiving\nWrong: A figure that has problems related to mathematics; it is objectively incorrect\n\n\n\n\nDifferent Data Visualization\n\n\n\n\nMonochromatic vs Non-Monochromatic\n\nReference:\nData Source: U.S. Census Bureau. (2023). TIGER/Line Shapefiles: Counties (2023) [Shapefile].\nU.S. Department of Commerce.\nAvailable at: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html\n\n\n\n\nMonochromatic vs Non-Monochromatic\n\n\n\n\nBad Proportions (Pie)\n\nThe figure combines two variables:\n\nConstruction material (steel, wood, iron)\nDate of construction (crafts = before 1870, modern = after 1940)\n\nThe chart is invalid because the percentages add up to more than 100%.\n\nThe issue arises from overlap between the two variables:\n\nAll modern bridges are made of steel.\nMost crafts bridges are made of wood.\n\n\n\n\n\n\nBad Pie\n\n\n\nReference:\nYoram Reich and Steven J. Fenves, via the UCI Machine Learning Repository\n(Dua & Karra Taniskidou, 2017).\n\n\n\nBad Proportions (Bar)\n\nSame data displayed as a bar plot instead of a pie chart.\nUnlike the pie, this chart is not technically wrong because bar heights don‚Äôt have to add up to 100%.\nHowever, it still fails to show overlap between groups (e.g., modern bridges are also steel, crafts are mostly wood).\nFor that reason, it is labeled ‚Äúbad.‚Äù\n\n\n\n\nBad Bar graphs\n\n\n\n\nTo Make that Chart Better\n\nSeparate construction material and era of construction instead of mixing them.\nUse a visualization that shows joint distributions or overlaps (e.g., grouped bar chart, stacked bar chart, or mosaic plot).\nMake it clear that some categories overlap (e.g., most modern bridges are steel, most crafts bridges are wood).\nEnsure percentages or proportions are mutually exclusive and add up properly within each grouping.\nHelps viewers accurately understand relationships between material and construction period.\n\n\n\nReasoning Errors in Data Visualization\n\nA paper by Schmidt et al.¬†(2023) examines how individuals mislead with charts through strategies that go beyond visual distortions, focusing on logical and interpretive manipulations in data presentation.\n\nSchmidt et al.¬†(2023) collected 9,958 Twitter posts containing data visualizations related to the COVID-19 pandemic.\nThese posts were gathered to analyze real-world examples of how charts are used in online discourse.\nThe researchers then categorized and examined these posts for reasoning errors and misleading practices, focusing on arguments and interpretations rather than just visual design flaws.\nThis approach allowed them to study how misinformation spreads through otherwise well-designed charts in a large-scale, real-world dataset.\n\n\n\nReference:\nSchmidt, A., V√§√§n√§nen, K., Goyal, T., Kristensson, P. O., Peters, A., Mueller, S., Williamson, J. R., & Wilson, M. L. (Eds.). (2023).\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems.\nAssociation for Computing Machinery.\nhttps://doi.org/10.1145/3544548\n\n\n\nReasoning Errors (Schmidt et al., 2023)\n\nReasoning Error: Commonly occurring logical attributes that can form the basis of a misleading argument\n\n\nMisreading Charts‚Äì Drawing incorrect conclusions due to visual distortions or misinterpretation of chart elements.\nCherry-Picking‚Äì Selecting only certain data points so the conclusion fits the limited evidence, even though it wouldn‚Äôt hold with a more complete dataset.\nArbitrary Thresholds‚Äì Judging a phenomenon against a threshold that is chosen without clear justification, either as a number or a visual marker on a chart.\nData Quality Issues‚Äì Using data that may be incomplete, inconsistent, or uncertain, particularly during fast-changing situations, without communicating these limitations.\nIgnoring Statistical Nuance‚Äì Overlooking key statistical details (e.g., comparing only one group in an experiment) to make an argument appear stronger than it is.\nMisrepresenting Scientific Research‚Äì Misusing or oversimplifying scientific studies, which undermines public understanding and trust in science.\nFalse Causal Claims‚Äì Inferring cause-and-effect relationships from visual patterns, often without proper evidence, which can be especially misleading when combined with cherry-picked data.\n\n\n\nMisreading Charts: Coordinate Systems and Axes\n\nMisreading charts refers to drawing incorrect conclusions due to visual distortions or misinterpretation of chart elements.\nData visualization requires position scales to determine where data values appear.\nWe want to choose an aspect ratio that ensures that any important differences in position are noticeable.\n\n\n\n\nMisreading Charts\n\n\n\n\nCherry-Picking\n\nCherry-Picking‚Äì Selecting only certain data points so the conclusion fits the limited evidence, even though it wouldn‚Äôt hold with a more complete dataset.\n\nCherry-picking of the data points\nCherry-picking of the time frame\n\n\n\n\n\nCherry Picking\n\n\n\n\nArbitrary Thresholds\nArbitrary Thresholds‚Äì Judging a phenomenon against a threshold that is chosen without clear justification, either as a number or a visual marker on a chart.\n\n\n\nThresholds\n\n\n\n\nData Quality Issues\n\nData Quality Issues‚Äì Using data that may be incomplete, inconsistent, or uncertain, particularly during fast-changing situations, without communicating these limitations.\n\n\n\nA notable example of data quality issues is the case of the COVID-19 dashboard developed by Johns Hopkins University. This dashboard became a critical tool for tracking the pandemic‚Äôs progression, but it faced significant challenges early on related to incomplete and inconsistent data reporting.\n\n\n\nMisrepresenting Scientific Research\n\nScientific literacy is the ability to understand and evaluate scientific information well enough to make informed judgments, especially as a non-expert.\n\nIts goal is to help people cautiously trust science, striking a balance between blindly accepting all scientific claims and rejecting science entirely\n\nMisrepresentation occurs when research findings are oversimplified, cherry-picked, or presented without proper context, leading non-experts to draw misleading conclusions.\n\nA scientifically literate audience is less likely to be misled because they can recognize when data are being exaggerated, causation is implied without evidence, or important nuances are ignored.\n\n\n\n\nIgnoring Statistical Nuance\n\nIgnoring Statistical Nuance‚Äì Overlooking key statistical details (e.g., comparing only one group in an experiment) to make an argument appear stronger than it is.\n\nSubgroup differences ‚Äì Variations in effects or outcomes across different categories within the population, such as age, sex, health status, or other demographic factors.\n\nIgnoring these differences can oversimplify results, since the effect seen in the overall average may not apply to all subgroups.\nExample: A new medication may lower blood pressure more in younger adults than older adults.\n\nCausation vs.¬†correlation ‚Äì Correlation means two variables are related or move together, but it does not prove that one causes the other. Causation means a change in one variable directly produces a change in another.\n\nObservational studies can identify correlations but cannot reliably establish causation.\n\nConfounding factors ‚Äì Variables that are related to both the independent variable and the outcome that can create a misleading association.\n\nFor example, if coffee drinkers also tend to exercise more, the longer lifespan might be due to exercise rather than coffee.\n\n\n\n\n\nCorrelation vs.¬†Causation\n\nCorrelation is a standardized measure of the relationship between two variables, expressed in terms of covariance divided by the product of their standard deviations.\n\nMeasures linear relationship between two variables describing both the strength and direction of the linear relationship.\nThe correlation coefficient may not be a reliable measure in the presence of outliers.\nEven if two variables are highly correlated, one does not necessarily cause the other.\n\n\n\n\n\nCorrelation vs Causation\n\n\n\n\nCorrelation vs.¬†Causation\n\nWhat do we need to determine causation?\n\nStatistically significant relationship between the variables.\nNo other factors can account for the cause.\n\nEliminate Confounds\n\nCausal variable occurred prior to the other variable.\n\nWe understand and have the correct directionality (X ‚Üí Y).\n\n\nWhy are we tempted to interpret findings as causal?\n\nCausal link seems obvious.\nHave a pre-existing bias.\nInterpretations dominated by theoretical orientation.\n\n\n\n\n\nCorrelation vs Causation\n\n\n\n\nConfounding Variables and The Third Variable Problem\n\nThe Third Variable Problem\n\nDefinition: Any variable that is extraneous to the two variables being studied, which may influence or explain the observed relationship.\nAlso known as: Confounding variables\n\nSpurious relationships: Apparent associations that are actually due to coincidence or the presence of a third, unseen factor (a confounding variable).\n\n1975 Taiwan Study: Correlation between electrical appliance ownership and contraceptive use, influenced by socioeconomic status.\nEarly 1900s Pellagra in the Southern U.S.: Cases initially linked to diet, but ultimately explained by poor sanitation and nutrient deficiencies.\n\n\n\nRead more here https://hbr.org/2015/06/beware-spurious-correlations\n\n\n\nCorrelation vs Causal\n\n\n\n\nFalse Causal Claims\n\nFalse causal claims refers to when someone interprets a visual pattern (or any correlation) as evidence of cause-and-effect without proper experimental or statistical support, they are making a false causal claim.\nCherry-picking exacerbates the issue: Selecting only data that fits a desired story can make the misleading visual pattern look more convincing, reinforcing the false causal inference.\n\n\n\n\nFalse Causal Claims\n\n\n\n\nThe Directionality Problem\n\nDirectionality problem: In a correlation between two variables X and Y, it can be unclear which variable, if either, is causing the other.\n\nWe need to understand Temporal Precedence to understand Causation.\n\nThe directionality problem is a common reason people make false causal claims. If you ignore which variable comes first‚Äîor whether a third variable explains the correlation‚Äîyou may wrongly assert that one variable causes the other.\n\nHappiness and Exercise\nPhysical Exercise and Self Esteem\nAggression and video games\n\n\n\n\nBias\n\nBias is closely related to false causal claims because it can distort the data or the interpretation of data, making a causal relationship appear stronger, weaker, or entirely different than it really is.\n\nSample Bias:\n\ni.e., Surveying only gym-goers to conclude that exercise increases happiness ignores people who exercise less but are happy.\n\nMeasurement Bias:\n\ni.e., Using self-reported exercise without verification may overestimate its effect on health outcomes.\n\nConfirmation Bias: Researchers or communicators may focus on data that supports their expected causal story and ignore data that contradicts it.\n\ni.e., Highlighting only studies where coffee drinkers live longer, while ignoring studies showing no effect or harmful effects.\n\nPublication Bias: Studies showing significant or ‚Äúinteresting‚Äù causal effects are more likely to be published, skewing the perceived evidence.\n\n\n\n\nStory Telling with Data\n\nWho, What, How Framework\n\nWho: Know your audience‚Äîspecificity matters\nWhat: Define what they should know or do\nHow: Determine how data will support the message\n\n\n\n\nThe Big Idea & 3-Minute Story\n\nBig Idea: A concise, complete sentence with stakes and point of view\n3-Minute Story: Boil your message down for brief delivery\nThese force clarity and support human-centered understanding\n\n\n\n\nSuccess in data storytelling begins before visualizing data.\n\nClarify purpose, audience, and message\nDifferentiate exploratory vs.¬†explanatory analysis\nUse explanatory: Focus on the two pearls, not the 100 oysters\n\nFor example, using livedatatechnologies.com, we can analyze patterns in arrivals vs.¬†departures over time\n\n\n\nReference: https://www.livedatatechnologies.com/account-tracking\n\nClarify purpose, audience, and message\nDifferentiate exploratory vs.¬†explanatory analysis\nUse explanatory: Focus on the two pearls, not the 100 oysters\n\nFor example, using livedatatechnologies.com, we can analyze patterns in arrivals vs.¬†departures over time\n\n\n\n\n\nLive Data Tracking\n\n\n\n\n\nUnderstand the Context\n\nStep 1: Understand the Context\n\nAnalyze patterns in arrivals vs.¬†departures over time\n\nStep 2: Choose the Right Visual\n\nTime-series bar chart or line graph\n\nStep 3: Eliminate Clutter\n\nUse minimal colors and direct labels\n\nStep 4: Focus Attention\n\nHighlight remote-relevant roles or high-turnover functions\n\nStep 5‚Äì6: Design & Tell a Story\n\nAnnotate with observations (e.g., ‚ÄúSpike in departures from editorial roles‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Human-centered Storytelling</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html",
    "href": "analyticsproblem.html",
    "title": "The Analytics Problem",
    "section": "",
    "text": "Food for Thought",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>The Analytics Problem</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html#the-analytics-problem",
    "href": "analyticsproblem.html#the-analytics-problem",
    "title": "The Analytics Problem",
    "section": "The Analytics Problem",
    "text": "The Analytics Problem\n\nChapters 1 and 2 from Weber and Zwingmann (2024) outline the journey of building a data-driven organization‚Äîfrom understanding the foundations of data acquisition, APIs, and web scraping, to progressing through the data maturity stages (Reactive ‚Üí Active ‚Üí Progressive ‚Üí Fluent) by aligning culture, strategy, people, and technology.\n\nChapter 1 and 2 at Weber, W., & Zwingmann, T. (2024). Augmented analytics. O‚ÄôReilly Media, Inc.¬†Available at https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\n\nHistorical Context: Industrial Transformations\n\nPast revolutions:\n\n1760s: Steam power.\nMid-1800s to 1910s: Electricity & mass production.\nLate 20th century‚Äìpresent: Computerization.\n\nCurrent shift: Digital transformation driven by multiple converging technologies (AI, IoT, cloud, analytics) is faster and more complex than prior eras.\n\n\n\nWhy are Business Transforming?\n\nSpeed of Change\n\nPrevious revolutions took decades; now transformation can occur in a few years.\nExample: Amazon vs.¬†local bookstores; Uber vs.¬†taxis; Industry 4.0 in manufacturing.\nRequires organizational agility and strong leadership.\n\n\n\n\n\nFigure 1-1. The growing amount of data worldwide. Adapted from Statista, as cited in Weber & Zwingmann (2024)\n\n\n\nConvergence of Multiple Technologies\n\nUnlike single-tech revolutions, today‚Äôs changes combine AI, cloud, IoT, and advanced analytics.\nLeads to multidimensional complexity and unpredictable disruption timelines.\n\nImportance of Data\n\nData has shifted from being a byproduct to being a core strategic asset.\nGrowth in unstructured data (text, images, video) creates new challenges.\nThe ‚Äúdata as oil‚Äù analogy is flawed: data increases with use, is not scarce, but needs ‚Äúrefining‚Äù (cleaning, governance) to be valuable.\n\nChanging Consumer Behavior & Customer Centricity\n\n‚ÄúiPhone moments‚Äù reshape entire industries (examples: Shopify, Tesla, Amazon Prime, Netflix).\nDigital transformation now spans all sectors and is often triggered by heightened customer expectations.\n\n\n\n\nIndustries Most Impacted\n\nMcKinsey research highlights industries where big data & analytics are transformative:\n\nAgriculture ‚Äì Precision farming, automation.\nCommercial insurance ‚Äì Pricing, underwriting efficiency.\nFinance ‚Äì Fraud detection, credit risk modeling.\nHealthcare ‚Äì Personalized medicine, predictive diagnostics.\nIT ‚Äì Automation, cybersecurity.\nManufacturing ‚Äì Predictive maintenance, supply chain optimization.\nTransportation ‚Äì Route optimization, demand prediction.\nUtilities ‚Äì Grid stability, renewable integration.\n\n\n\n\n\nFigure 1-2. Industries heavily impacted by big data and analytics. Adapted from McKinsey, as cited in Weber & Zwingmann (2024)\n\n\n\n\nConsequences for Businesses\n\nShift from internal efficiency to customer-centricity: Digital tools allow deep customer journey insights.\nAnalytics adoption gap:\n\nMany analytics teams fail to deliver perceived value.\nTools are often ‚Äútoo technical‚Äù for average employees.\nLesson from history:\n\nWidespread adoption comes from simplicity (e.g., mouse for computers, touchscreens for phones).\n\n\n\n\n\nThe Case for Augmented Analytics\n\nLimitations of traditional analytics:\n\nCan‚Äôt handle the variety of today‚Äôs data (structured, semi-structured, unstructured).\nManual tools like Excel or static BI dashboards are insufficient.\n\nAugmented analytics goal:\n\nBring insights to non-data professionals (80% of workforce).\nMake analytics intuitive, embedded in workflows, and actionable.\n\n\n\n\nData-Driven Culture\n\nDefinition: Culture where decisions routinely reference ‚ÄúWhat does the data say?‚Äù\nCurrent reality: Most companies lack data literacy‚Äîonly ~24% of decision-makers feel confident with data.\nNeed: Foster curiosity, analysis, and communication skills alongside technical tools.\n\n\n\nThe People Problem & Limits of Upskilling\n\nAging populations and shrinking workforces mean you can‚Äôt simply replace staff.\nUpskilling is essential but cannot make everyone a ‚Äúdata person.‚Äù\n\nUpskilling refers to the process of learning new skills or improving existing ones, typically to keep up with changes in technology, industry practices, or job requirements. It often involves acquiring more advanced, specialized, or updated capabilities that make a person more effective in their current role or prepare them for new opportunities.\n\nFor individuals, upskilling helps maintain competitiveness in the job market, adapt to evolving roles, and enhance career growth.\nFor organizations, upskilling initiatives improve workforce productivity, reduce skill gaps, and strengthen adaptability in fast-changing industries.\n\n\nSuggested Solution: Meet people where they are and give them augmented tools rather than forcing advanced analytics expertise.\n\n\n\nTransition from Data-Driven to Insight-Driven\n\nData-driven: Focuses on collecting/analyzing data.\nInsight-driven: Focuses on delivering actionable, user-friendly insights to the majority of employees.\nAugmented analytics is positioned as the ‚Äúmouse‚Äù of the analytics world‚Äîbridging the gap between complexity and usability.\n\n\n\nDeveloping Analytical Maturity\n\n\n\nAnalytical Maturity: The Four-Tier IPTOP Framework\n\nThe IPTOP framework is operational in nature because it guides data teams on infrastructure, tools, and processes.\n\n\n\nInfrastructure: How data is collected, stored, made reliable, and accessible.\nPeople: Cultivating data literacy, a data-driven culture, and ongoing learning.\nTools: The analytics and data tools used at various skill levels, plus reusable frameworks.\nOrganization: Structuring data talent‚Äîcentralized, decentralized, or hybrid models‚Äîfor scalable analytics.\nProcesses: Workflows and practices that support collaboration, consistency, and alignment with business goals.\n\n\n\n\nFigure 2-1. The four-tier IPTOP analytics maturity framework. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nCombining IPTOP and Data Maturity\n\n\n\nThe SPEC Framework for Transformation\n\nThe SPEC framework is strategic because it helps executives align analytics with business vision and culture.\n\nIPTOP = How do we build it? (infrastructure, tools, processes, literacy, governance).\nSPEC = Why and who drives it? (strategy, people, leadership, culture).\n\nStrategy ‚Äì Align analytics vision with business objectives.\nPeople & Organization ‚Äì Build data talent, bridge business and analytics roles, promote continuous learning.\nData Ecosystem ‚Äì Reliable, secure, accessible data infrastructure with governance.\nCultural Change ‚Äì Foster collaboration, experimentation, and data-driven mindsets.\n\n\n\n\nFigure 2-2. The SPEC framework. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nBeing Data Active\n\nThe chart shows the transition from Data Reactive to Data Active in analytics maturity, guided by improvements in culture, strategy, people & organization, and data ecosystem.\n\nCulture (green line)\nEnsure CEO support ‚Äì Top-level commitment is essential.\nInvolve and convince management ‚Äì Get buy-in from leadership.\n\nStrategy (green & red mixed)\n\nDevelop a data strategy ‚Äì Create a plan for how analytics will support business goals.\nAlign with business strategy, finding the purpose ‚Äì Make analytics initiatives serve clear organizational objectives.\n\nPeople & Organization (red line)\n\nConsider the importance of data literacy ‚Äì Raise awareness of skills needed to understand and use data.\n\nData Ecosystem (blue line)\n\nStart with an initial governance ‚Äì Establish basic rules, processes, and ownership for data.\nPursue a consistent use-case-oriented approach ‚Äì Focus on solving specific, high-value problems with analytics rather than abstract projects.\n\nEnd Goal ‚Äì By applying these cultural, strategic, organizational, and technical steps, an organization can move from a reactive approach to data to a proactive, structured use of analytics.\n\n\n\n\nFigure 2-3. Actions on the path from Data Reactive to Data Active. Reprinted from Weber & Zwingmann (2024).\n\n\n\n\nMoving to Data Progressive\n\nCulture (green)\n\nDefine collaboration models to encourage cross-team work.\nDrive adoption of first analytics solutions to show value early.\nFoster a data liberalization approach, making data accessible to more users.\n\nStrategy (green line)\n\nDefine a clear data analytics strategy aligned with business goals.\n\nPeople/Organization (red)\n\nDefine your operation model to structure data initiatives.\nEstablish a center of excellence to centralize expertise.\nDefine roles and personas for clarity in responsibilities.\nSet up a data literacy program to build skills.\nExecute along an analytics transformation roadmap for consistent progress.\nDevelop talents within the organization for long-term capability.\n\nData Ecosystem (blue)\n\nFinalize your target tool stack for consistency in technology.\nSet up a use case pipeline and process to manage analytics projects.\n\nOverall Goal:\n\nTransition from simply being active with data to being progressive, meaning analytics is deeply embedded, strategically driven, culturally embraced, and supported by robust tools, processes, and skilled people.\n\n\n\n\n\nFigure 2-4. Actions on the path from Data Active to Data Progressive. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nOvercoming Gulfs and Chasms\n\n\n\nFigure 2-5. Impact and establishment of the four steps of analytical maturity. Reprinted from Weber & Zwingmann (2024)\n\n\n\nComplexity & Market Establishment:\n\nAs organizations progress, complexity increases (vertical axis on top) and market establishment grows (vertical axis on bottom).\nGulfs and a chasm indicate key transition points where many organizations struggle to advance to the next stage.\n\nMoving from reactive to fluent requires overcoming organizational, technical, and cultural barriers at these gulfs and chasms, with each stage demanding higher sophistication and broader adoption.\n\nGulfs refer to incremental adoption hurdles.\nChasms refer to the big leap from being data-aware to making analytics part of the organizational DNA",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>The Analytics Problem</span>"
    ]
  },
  {
    "objectID": "analyticsproblem.html#augmented-analytics",
    "href": "analyticsproblem.html#augmented-analytics",
    "title": "The Analytics Problem",
    "section": "Augmented Analytics",
    "text": "Augmented Analytics\n\nChapter 3 of Weber and Zwingmann discuss why augmented analytics (AA) is critical in today‚Äôs fast-changing business environment.\n\nChapter 3 at Weber, W., & Zwingmann, T. (2024). Augmented analytics. O‚ÄôReilly Media, Inc.¬†Available at https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\n\nAugmented Analytics (AA)\n\nAugmented analytics means adding value by providing people with access to technology that gives them the analytical leverage they need to accomplish the business task at hand in a better way.\nAugmented analytics offers a path to scaling insights across an organization by making them accessible, intuitive, and embedded in decision-making.\nAA is not just about better tech‚Äîit‚Äôs about human-centric augmentation that finds the right ‚Äúsweet spot‚Äù between automation and judgment.\nDone right, it becomes integrated, essential, and empowering‚Äîhelping organizations progress toward Data Fluent maturity.\n\n\n\nAA maters because it breaks down the data expert vs.¬†business user divide. Embeds analytics in daily work to make data use habitual and unobtrusive. Uses augmented workflows (analytics inside existing processes) and augmented frames (context-specific, just-in-time insights).\n\n\n\nFive Key Components Moving from Data Reactive to Data Fluent\n\nPeople ‚Äì Human creativity, experience, and judgment remain at the center of analytics. Tools support people, but it‚Äôs people who frame questions, interpret results, and make decisions.\nTechnology ‚Äì AI, automation, and analytics platforms provide the computational power to process large datasets and enable advanced analytics.\nAnalytical Leverage ‚Äì Analytics amplifies human thinking by improving speed, scale, accuracy, and predictive ability‚Äîmaking insights more powerful than intuition alone.\nBusiness Task ‚Äì Analytics should always be applied to solve real-world, value-driven business problems, not just generate reports for their own sake.\nBetter Way ‚Äì The goal is to make decisions that are faster, more reliable, and less biased‚Äîleading to better outcomes than gut instinct or outdated methods.\n\n\n\n\nFigure 3-1. Enablers for each maturity stage. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nFive Traits of Effective AA\n\nInsightful ‚Äì turns data into actionable knowledge.\nIntegrated ‚Äì embedded into existing workflows and tools.\nInvisible ‚Äì works seamlessly in the background.\nIndispensable ‚Äì delivers consistent value, becomes essential.\nInclusive ‚Äì usable by all, not just data experts.\n\n\n\n\nFigure 3-2. Augmented workflow efficiency. Reprinted from Weber & Zwingmann (2024)\n\n\n\n\nTypes of Bias\n\nSurvivorship Bias\n\nDefinition: Focusing only on people or things that ‚Äúsurvived‚Äù a process, ignoring those that did not.\nExample: Studying successful companies and assuming their strategies guarantee success, without analyzing the failed ones.\n\nConfirmation Bias\n\nDefinition: Tendency to seek out or favor information that confirms existing beliefs, while ignoring contradictory evidence.\nExample: Only reading news sources that support your political views.\n\nSample Bias\n\nDefinition: Drawing conclusions from a dataset that is not representative of the entire population.\nExample: Running a survey only among college students to estimate national voting behavior.\n\nAvailability Bias\n\nDefinition: Overestimating the importance of information that is easiest to recall, often because it is recent or vivid.\nExample: Believing plane crashes are common after seeing news coverage of one, despite statistics showing they are rare.\n\nOutlier Bias\n\nDefinition: Placing too much emphasis on unusual or extreme cases that may not represent the norm.\nExample: Using one extraordinary sales month to predict future performance.\n\n\n\n\n\nFigure 3-3.Improvability of various types of biases.Reprinted from Weber & Zwingmann (2024)\n\n\n\nSelection Bias\n\nDefinition: Systematic error caused by choosing non-random data that skews results.\nExample: Studying only patients who complete a treatment program, ignoring those who dropped out.\n\nCognitive Bias\n\nDefinition: A systematic pattern of deviation from rational judgment that affects decisions and thinking.\nExample: Stereotyping people based on limited personal experiences.\n\nAnchoring Bias\n\nDefinition: Relying too heavily on the first piece of information (the ‚Äúanchor‚Äù) when making decisions.\nExample: Negotiating a salary based primarily on the initial number offered.\n\nHistorical Bias\n\nDefinition: Bias introduced by data that reflects outdated or inequitable historical conditions.\nExample: Predictive policing models reinforcing past discriminatory arrest patterns.\n\n\n\n\nThe Five AI Archetypes\n\n\n\nFigure 3-4.The five AI archetypes. Reprinted from Weber & Zwingmann (2024).\n\n\nAutomation ‚Äì repeatable, deterministic processes (data prep, reporting, alerts).\nAI archetypes ‚Äì\n\nSupervised ML (prediction, classification, anomaly detection, recommendations)\nNatural Language Processing (NLP) (text analysis, search, summarization, sentiment)\nSpeech (voice-to-text/text-to-voice analytics)\nComputer vision (document/image analysis)\nGenerative AI (text-to-code, automated reports, conversational queries)\n\n\n\nSupervised Learning\n\nThis diagram shows the iterative process of building and maintaining a supervised machine learning model:\n\nCollect Data ‚Äì Gather relevant, high-quality datasets containing both features (inputs) and labels (outputs).\nDefine Features and Labels ‚Äì Identify which variables will be used as predictors (features) and what will be predicted (label).\nTrain/Test Split ‚Äì Divide the data into training and testing sets to evaluate performance fairly.\nFind Best Model ‚Äì Experiment with different algorithms and hyperparameters to determine the most effective model.\nEvaluate ‚Äì Measure the model‚Äôs accuracy, precision, recall, or other metrics on the test set.\nDeploy ‚Äì Integrate the model into a real-world application or workflow.\nMonitor ‚Äì Continuously check performance, retrain when data drifts, and ensure predictions remain accurate over time.\n\nThis loop emphasizes continuous improvement ‚Äî after monitoring, you may need to return to earlier steps to refine the model as new data arrives or conditions change.\n\n\n\n\nFigure 3-5.The supervised ML workflow. Reprinted from Weber & Zwingmann (2024).",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>The Analytics Problem</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Competing in the Age of AI",
    "section": "",
    "text": "This section introduces how organizations evolve from competing through business analytics to competing in the age of AI (CTAI). It explains how data-driven decision-making transforms into AI-enhanced systems that learn, scale, and adapt across business functions. The discussion connects classical frameworks‚Äîlike Porter‚Äôs Five Forces and the Value Chain‚Äîto digital-era dynamics such as network effects, value capture, and platform competition. Drawing on Iansiti & Lakhani (2020), it highlights how firms achieve advantage not just through better data, but through architectures that continuously learn and connect across networks.\n\n\nReference:\nChapter 6 from Iansiti and Lakhani (2020) in Competing in the Age of AI explains how artificial intelligence transforms firms by digitizing activities into scalable, connectable, and self-improving systems.\nThe chapter outlines a strategic framework for AI-driven businesses that leverages network and learning effects while addressing key concepts such as multihoming, disintermediation, and network bridging, using real-world examples like Uber and Airbnb.\n\n\nCompeting Through Business Analytics (CTBA)\n\nCompeting through business analytics (CTBA) means using data, statistical analysis, and predictive modeling to gain a strategic advantage over competitor.\nIt involves making better, faster, and more informed decisions by systematically analyzing data across all areas of the business.\n\n\n\nCTBA and the Organization\n\nFirms that compete through analytics build capabilities in data collection, storage, analysis, and interpretation, making data a strategic asset. These firms often develop a culture of testing, learning, and optimization across the entire organization.\n\nData-Driven Decisions: Relying on insights from data rather than intuition or guesswork.\nPerformance Improvement: Enhancing efficiency, productivity, and outcomes using measurable evidence.\nPredictive Power: Forecasting future trends or behaviors (e.g., customer churn, sales, demand).\nCompetitive Differentiation: Gaining an edge through smarter operations, marketing, customer targeting, or innovation.\n\n\n\n\nWhere is the AI in CTBA?\n\nCTBA is about using data and analysis to drive smarter decisions and outperform competitors. It traditionally involves:\n\nDescriptive analytics - what happened (reports, stats, visualizations)\nDiagnostic analytics - why it happened (causal inference vs.¬†correlation)\nPredictive analytics - what will happen (forecast models)\nPrescriptive analytics - what should we do ((e.g., dynamic pricing recommendations, optimal supply chain routes)\nKPIs - Are we achieving business goals?\n\nAI doesn‚Äôt replace analytics ‚Äìit supercharges it by making it faster, deeper, and more dynamic, allowing business to compete not just with better data - but with better learning.\n\n\n\nWhat does AI Bring to Business?\n\nAI brings to automation, scale, and adaptability to analytics, allowing business to:\n\nContinuously learn from new data (machine learning).\nMake real-time decisions (streaming analytics).\nPersonalize at scale (recommendation systems).\nGo beyond prediction to causal and autonomous decision-making.\n\n\n\n\nUnderstanding AI‚Äôs Impact In Specific Business Domains\n\nMarketing: Customer segmentation, personalization, targeting.\n\nCustomer Segmentation: Grouping customers based on shared characteristics to tailoring marketing or product strategies.\nPersonalization: Delivering individualized experiences, often powered by AI recommendations.\n\nOperations: Inventory management, route optimization, demand forecasting.\n\nDemand Forecasting: Predicting future customer demand using historical data and AI models.\n\nFinance: Risk modeling, algorithmic trading, fraud detection.\n\nAlgorithmic Trading: Automated financial trading using pre-defined AI rules and models.\nFraud Detection: Using data and machine learning to identify unusual patterns that may indicate fraud.\n\nHR: Resume screening, performance prediction, talent analytics.\nHealthcare: Diagnostic tools, patient risk prediction.\n\n\n\nHow AI-driven Decision-Making is Transforming Industries\n\nAI-driven decision-making is transforming industries by enabling faster, more accurate, and more scalable decisions than were previously possible with traditional methods.\nAI transforms how firms:\n\nCompete on speed and scale\nCreate personalized experiences\nOperate with greater efficiency and agility\nContinuously learn and improve from data\n\n\n\n\nStrong vs.¬†Weak AI\n\nStrong AI refers to computer systems that replicate or simulate human reasoning and behavior, aiming to match or exceed human cognitive abilities.\n\nA system that can tutor you in calculus, negotiate a business deal, write a novel in your style, and then cook up a new recipe ‚Äì all with the same underlying intelligence.\n\nWeak AI refers to computer systems designed to perform specific tasks traditionally done by humans, without replicating human consciousness or general reasoning.\n\nSiri, Alexa, or Google Assistant: Can recognize voice commands, set alarms, or fetch weather updates, but cannot engage in deep reasoning in awareness.\nChatGPT (today‚Äôs models): Excellent at generating language, but it doesn‚Äôt ‚Äúunderstand‚Äù the world ‚Äì it predicts patterns in text.\n\n\n\n\nExploring Weak AI Further\n\nWeak AI can be sufficient for an Organization\nTransformative change doesn‚Äôt require human-like ‚Äústrong AI‚Äù ‚Äì just systems that can perform tasks traditionally done by humans.\nPractical applications matter\n\nTasks like prioritizing content, pricing, or analyzing behavior can be effectively handled by imperfect AI.\n\nBusiness impact is already real\n\nEven without perfect replication of human reasoning, weak AI is reshaping how firms function and compete\n\n\n\n\nTransforming Competition\n\nThink of evolution of photography over time\nFrom Disruption to Reinvention: Traditional tech disruptions ( e.g., films vs.¬†digital photography) replaced older models - AI redefines entire industries and operating models.\nDigital Operating Models: AI enables firms to scale, learn, and expand scope rapidly - at near-zero marginal cost - through algorithmic execution.\nNew Breed of Competitors: Companies like Facebook, Tencent, and Amazon weren‚Äôt direct rivals to traditional players like Kodak‚Äìthey operated on new rules and displaced them indirectly.\n\n\n\nStrategic Implications of AI-Driven Firms\n\nValue Creation Shift:\n\nAI firms extract value from data, networks, and user interactions, not just products or services.\n\nOperating Model Advantage:\n\nDigital firms overcome traditional limits of complexity, allowing infinite scalability and adaptability.\n\nCompetitive Collision:\n\nTraditional firms face existential threats ‚Äî not from better versions of themselves, but from companies with fundamentally different architectures and strategies.\n\n\n\nThe collision between traditional and digital operating models\n\n\n\nDigital vs Traditional\n\n\n\n\n\nBusiness Strategy & Competitive Advantage\n\nAI changes how firms create and sustain competitive advantage (e.g., data network effects, faster innovation).\nKey concepts to understand:\n\nCompetitive Advantage: A condition or circumstance that puts a company in a favorable or superior business position.\nPorter‚Äôs Five Forces: A framework for analyzing a company‚Äôs competitive environment: industry rivalry, threat of new entrants, threat of substitutes, bargaining power of buyers, and bargaining power of suppliers.\nNetwork Effects: Network effects occur when the value of a product, service, or platform increases as more people use it.\nValue Capture Dynamics: How a firm retains and monetizes the value created (e.g., pricing, data control, platform fees).\n\n\n\n\nCompetitive Advantage\n\nCompetitive advantage is increasingly defined by the ability to shape and control these networks and harvest the volume and variety of the transactions they carry. Competitive advantage therefore moves toward the organizations that are most central in connecting businesses, aggregating the data that flows between them, and extracting value through powerful analytics and AI (lansiti et al., 2020).\nNow strategy is shifting to the art of managing the firm‚Äôs networks and leveraging the data that flows through them. Just as industry analysis dominated strategy over the past few decades, we believe that network analysis will increasingly shape strategic thinking in the future. (lansiti et al., 2020).\nDiscussion Point: How do firms gain competitive advantage in the market? What makes them unique?\n\n\n\nPorter‚Äôs Five Forces Model\n\n\n\nPorter‚Äôs Five Forces\n\n\n\nPorter‚Äôs Five Forces model is a strategic framework used to analyze the competitive forces that shape every industry and influence its profitability, helping businesses assess their market position and develop effective strategies.\n\nCompetitive Rivalry: Assesses the intensity of competition among existing firms in the industry. High rivalry can limit profitability.\nThreat of New Entrants: Looks at how easy or difficult it is for new competitors to enter the market. Barriers to entry affect the threat level.\nBargaining Power of Suppliers: Evaluates how much power suppliers have to drive up prices or reduce the quality of goods/services.\nBargaining Power of Buyers: Measures the ability of customers to influence pricing and terms. Powerful buyers can demand lower prices or higher quality.\nThreat of Substitutes: Considers the availability of alternative products or services that can perform the same function. More substitutes increase competitive pressure.\n\n\n\n\nThe Value Chain and Network Effects\n\nValue Creation Dynamics describe how a platform generates and expands value for its participants ‚Äì users, complementors, and the platform owner ‚Äì through interactions, data flows, and network effects. These dynamics reinforce each other, creating self-sustaining growth loops:\n\nDirect Network Effects\n\nValue increases as more users join the same side of the platform (e.g., more people on WhatsApp make it more valuable to each user).\n\nIndirect Network Effects\n\nValue increases as participation grows on the other side of the platform (e.g., more app developers make iOS more valuable to iPhone users, and vice verse).\n\nLearning Effects\n\nValue grows as data accumulates and systems improve (e.g., Netflix recommendations improving as viewing data expands.)\n\nComplementor Contributions\n\nExternal firms or individuals add value by creating content, apps, or services that enhance the platform. (e.g., App developers on Apple‚Äôs App Store add value to the iPhone ecosystem by creating apps that enhance user experience and increase platform stickiness.)\n\n\n\n\n\nValue Capture Dynamics\n\nThe appropriability of value refers to the extent to which a firm can capture and retain the economic value created by its platform, rather than having that value flow to users, complementors, or competitors.\nIn other words, even if a platform generates a lot of value through network effects, who gets to keep that value?\nFor example:\n\nApple‚Äôs App Store: Apple appropriates value by charging app developers a commission (historically 30%) on sales. While developers benefit from access to users, Apple captures a large share of the value.\nGoogle Search: While the search platform creates value for users and advertisers, Google appropriates much of it by monetizing through ads and controlling data.\nRide-sharing (Uber/Lyft): Drivers create much of the service value, but the platform appropriates value by taking a percentage of each fare.\n\n\n\n\nSome Factors Affecting Appropriability\n\nThe degree of appropriability depends on factors like:\n\nControl of key assets (data, algorithms, user base).\n\nGoogle Search captures enormous value because it controls the search algorithms, the user base, and the data flows. Competitors may create value in the search market, but Google appropriates most of it due to its asset control.\n\nSwitching and multihoming costs (if users or suppliers can easily move elsewhere, appropriation is weaker).\n\nApple‚Äôs iOS ecosystem locks users in through high switching costs: once you‚Äôve invested in iPhones, AirPods, iCloud, and App Store purchases , moving to Android is costly. This allows Apple to appropriate more value from users and developers. By contrast, in ride-hailing (Uber vs.¬†Lyft), switching costs are low- riders can open both apps and choose the cheaper option- so platforms capture less value.\n\nRegulation and bargaining power (governments or complementors can limit how much value a platform extracts).\n\nApp Store fees show how regulation and complementor power affect appropriation. Apple historically took a 30% commission, but regulatory pressure and bargaining by large developers like Epic Games have forced Apple to reduce or modify fees in certain cases, limiting how much value it can appropriate.\n\n\n\n\n\nMultihoming and Value Capture\n\nMultihoming refers to the practice of users or firms participating in more than one platform at the same time, rather than committing exclusively to a single one.\nFor example:\n\nA consumer might use both Uber and Lyft to compare prices or availability.\nA content creator might post videos on both YouTube and TikTok to reach a wider audience.\nA merchant might list products on Amazon and eBay to capture different customer segments.\n\nMultihoming matters strategically because:\n\nIf multihoming costs are low (easy to join multiple platforms), competition between platforms is fiercer.\nIf multihoming costs are high (due to switching fees, data lock-in, or exclusive contracts), platforms gain more power to capture and retain users.\n\n\n\n\nDisintermediation and Value Capture\n\nDisintermediation is when platforms cut out middleman, creating direct producer- consumer connections and often reshaping entire industries.\nExamples:\n\nTravel booking: Online platforms like Expedia or Airbnb disintermediate traditional travel agents by letting consumers book directly.\nMusic Industry: Streaming services like Spotify or Apple Music reduce the need for record stores and even diminish the role of distributors.\nRetail: Direct-to-consumer brands (like Warby Parker or Glossier) bypass traditional retailers by selling directly through online platforms.\n\n\n\n\nDisintermediation and Factors Affecting Appropriability\n\nControl of key assets\n\nDisintermediation threatens this. If intermediaries (like platforms, marketplaces, or distributors) can be bypassed, then the incumbent loses some of its control over user data, algorithms, or relationships.\n\nSwitching and multihoming costs\n\nDisintermediation often reduces these costs by enabling direct connections between producers and consumers (e.g., a brand selling directly through its website or app instead of through Amazon). Lower switching/multihoming costs weaken appropriability.\n\nRegulation and bargaining power\n\nIn some cases, regulation forces disintermediation (e.g., open banking rules requiring banks to let fintechs directly access customer data), thereby reducing how much value the incumbent can appropriate.\n\n\n\n\nNetwork Bridging and Value Capture\n\nNetwork bridging refers to when a platform (or a firm using the platform) connects two or more otherwise separate networks, allowing value to flow between them and creating new opportunities for growth.\nInstead of just strengthening one network, bridging links distinct user groups, industries, or ecosystems together.\nExamples:\n\nLinkedIn bridges professional networks across industries, letting recruiters, job seekers, and companies interact in ways that wouldn‚Äôt happen within a single firm‚Äôs HR system.\nAmazon Marketplace bridges sellers from diverse industries with millions of global buyers, turning a retail platform into a multi-industry ecosystem.\nApple‚Äôs App Store bridges app developers and iPhone users, creating cross-side network effects that amplify the value of both groups.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Intro to CTAI</span>"
    ]
  },
  {
    "objectID": "rethinkingfirm.html",
    "href": "rethinkingfirm.html",
    "title": "Rethinking the Firm",
    "section": "",
    "text": "This section explores how artificial intelligence is redefining what it means to be a firm in the digital era. It contrasts traditional, asset-based organizations with AI-driven enterprises that scale through data, algorithms, and continuous learning. Becoming an ‚ÄúAI company‚Äù is less about technology adoption and more about transforming strategy, culture, and operations to enable algorithmic decision-making and experimentation at scale. Drawing on Iansiti & Lakhani (2020), the section highlights how AI-ready firms build digital infrastructure, data maturity, and agile operating models that support learning loops, eliminate human bottlenecks, and turn intelligence into a core strategic asset.\n\n\nReference:\nChapter 2 from Iansiti and Lakhani (2020) focuses on how AI reshapes the boundaries, structure, and strategy of firms.\n\n\nWhat Does It Means to Become an AI Company?\n\nBecoming an AI company is not just about adopting new tools‚Äîit‚Äôs about transforming how your organization thinks, decides, and operates.\nAI-driven firms require deep organizational transformation: mission, data architecture, governance, product-centric agility.\nSuccess depends not just on adopting AI tools, but on embedding AI into the firm‚Äôs strategy and operating model.\nCompanies that treat AI as a bolt-on tool (just automation or one-off projects) miss the real value.\nCompanies that use AI as a strategic driver reshape their boundaries, competitive dynamics, and industry positioning.\n\n\n\nBecoming an AI Company\n\nAI isn‚Äôt just a feature; it reshapes how decisions are made, and work is executed. It requires moving beyond basic automation to a new AI-driven operating model.\nFirms must shift from human-centric to algorithm-centric workflows. This shift demands reimagining roles, processes, and accountability.\nAI success is powered by data-driven thinking, agility, and a culture of continuous experimentation. Organizations must encourage learning over certainty, and evidence over intuition.\nBecoming an AI company involves organizational change: new teams, roles, and cross-functional collaboration. Leadership must foster trust in algorithmic decision-making and promote transparency.\n\n\n\nAI Readiness\n\nAI readiness refers to an organization‚Äôs ability to successfully adopt, implement, and scale artificial intelligence technologies to enhance operations, decision-making, and value creation.\n\nDigital Infrastructure: Having the cloud platforms, computing power, and integration tools to support AI systems.\nData Maturity: Accessible, high-quality, well-organized data pipelines that AI systems can learn from.\nTalent & Culture: Teams with AI/ML skills and a culture that supports experimentation, agility, and data-driven decision-making.\nLeadership Commitment: Executives who understand AI‚Äôs strategic importance and invest accordingly.\nExperimentation & Learning: A mindset and capability to test, measure, and refine AI applications over time.\n\nA high level of AI readiness means a firm is not just equipped with technology‚Äîbut aligned across strategy, talent, and process to gain real value from AI.\n\n\n\nAI Readiness and the 350 Firm Study\n\nThe 350 Firm Study is a large-scale analysis of over 350 organizations that measured their AI maturity‚Äîbased on digital infrastructure, data integration, analytics use, and AI deployment‚Äîand demonstrated a strong positive correlation between higher AI maturity and superior financial performance.\nIncluded firms from sectors like manufacturing, consumer goods, financial services, and retail.\n\nUsed an AI maturity index built from about 40 business processes.\nTracked progression from siloed data to integrated AI factories.\nShowed that leaders in AI maturity significantly outperformed laggards in metrics like gross margin, net income, and earnings before taxes (e.g., top firms had 55% gross margin vs.¬†37% for laggards).\n\n\n\n\nAI Readiness Index (350 Firms Study) Key Factors for AI Maturity\n\nDigital infrastructure refers to the scalable, cloud-based systems and modern IT architecture needed to support real-time data processing and AI deployment across the enterprise.\nData accessibility and quality involves integrating siloed data into centralized platforms with strong governance to ensure the data is usable, secure, and valuable for AI-driven decision-making.\nTalent and leadership alignment means recruiting and empowering cross-functional teams‚Äîincluding technical, strategic, and governance leaders‚Äîto drive transformation with clarity, conviction, and collaboration.\nExperimentation capability refers to the organization‚Äôs ability to test and iterate AI applications quickly through agile methods, empowered by modular architectures and a culture that embraces continuous learning and adaptation.\n\n\n\nOperating Models in the Age of AI\n\nStrategy, without a consistent operating model, is where the rubber meets the air. ‚ÄîSomewhat famous Italian proverb\n\n\n\nTraditional firms are built around physical assets & labor.\nAI-driven firms are built around data, algorithms, and digital platforms.\nThis shift transforms how firms scale, diversify, and learn.\n\n\n\nTraditional Vs AI Driven Operating Model\n\nTraditional Operating Model\nOptimized for efficiency in production & coordination.\nKey features:\n\nPhysical supply chains\nHuman decision-making\nGrowth requires proportional increases in people/assets\n\nAI-Driven Operating Model\nCore = AI Factory: data ‚Üí algorithms ‚Üí learning ‚Üí action.\nOperations embedded into digital platforms.\nGrowth comes from:\n\nUser interactions generating data\nAutomated decisions at scale\nAlgorithms continuously improving\n\n\n\n\nScale and Scope Economies\n\nScale Economies: Cost advantages that companies gain as they increase production, often enhanced by AI automation.\nScale Without Mass\n\nTraditional: scaling = more factories, workers, capital.\nAI-driven: scaling = more data & users with minimal costs.\n\n\n\n\nExample: Ant Financial ‚Üí handles millions of loans without adding staff.\nScope Economies: Efficiencies formed by variety (offering multiple products or services), where AI can help leverage shared data and infrastructure.\nScope Without Complexity\n\nTraditional: diversification adds costly coordination layers.\nAI-driven: reuse same data + algorithms + infrastructure across domains.\n\n\n\n\nExample: Amazon uses AI for retail, AWS, logistics, streaming.\n\n\n\nBusiness Model and Operating Model\n\n\n\nFigure 2-1\n\n\n\nAdapted from Figure 2-1, ‚ÄúThe AI factory,‚Äù in Iansiti & Lakhani (2020, p.¬†38)\n\n\n\nContinuous Learning Model\n\nThe learning function of an operating model is essential to driving continuous improvement, increasing operating performance over time, and developing new products and services.\n\nRun frequent A/B tests on products, pricing, or interfaces.\nUse controlled trials to evaluate new algorithms, workflows, or customer journeys.\nBuild feedback loops that connect experimentation results directly back into product design and decision-making.\n\nEach interaction ‚Üí data ‚Üí algorithm refinement.\nCreates positive feedback loops:\n\nMore users ‚Üí more data ‚Üí better service ‚Üí more users.\n\nContinuous experimentation enables firms to learn quickly, adapt strategies, and improve performance in an AI-driven world. Shifts decision-making from intuition-driven to evidence-based.\n\n\n\nStrategic Implications\n\nContinuous experimentation enables firms to learn quickly, adapt strategies, and improve performance in an AI-driven world. Shifts decision-making from intuition-driven to evidence-based.\nAgility as a Competitive Advantage\n\nFirms can pivot quickly as markets, customer preferences, and technologies change.\n\nData-Informed Strategy\n\nStrategic choices are validated with real-world results, not assumptions.\n\nScalable Learning Loops\n\nExperimentation feeds back into product design, operations, and business models.\n\nReduced Risk of Large Failures\n\nSmall, fast experiments minimize costly mistakes while accelerating innovation.\n\nCultural Shift\n\nLeaders and teams adopt a mindset where ‚Äúfailing fast‚Äù is acceptable if it creates learning.\n\n\n\n\nRemoving the Human Bottleneck\n\nHuman decision-making is often too slow, limited in scale, and inconsistent for the speed and complexity of digital environments\nAI removes bottlenecks caused by human limits to facilitate speed, scale, and consistency.\nExamples:\n\nAlgorithmic trading in finance.\nRecommendation engines in retail.\nFraud detection\nDynamic pricing\n\nImplication: Organizations that automate core processes can achieve greater efficiency, adaptability, and competitive advantage in AI-driven markets.\n\n\n\nThe Irresistible Digital Bicycle\n\nWe see ourselves more akin to an Apple, a Tesla, or a Nest or a GoPro‚Äîwhere it‚Äôs a consumer product that has a foundation of sexy hardware technology and sexy software technology. ‚ÄîJohn Foley, founder and CEO, Peloton\n\n\n\nAnalogy: Just as the bicycle amplified human physical power, AI amplifies human cognitive power.\nAmplification Effect: AI enables people to process vast amounts of data, make faster decisions, and extend their problem-solving capacity beyond natural limits.\nAccessibility: Like bicycles, AI tools are becoming widely available and affordable, not just for large firms but also startups and individuals.\nTransformative Impact: AI doesn‚Äôt just make existing tasks more efficient‚Äîit creates new possibilities for innovation, strategy, and value creation.\n\n\n\nTacit vs.¬†Strategic Use of AI\n\nTactically means using AI for specific, short-term goals‚Äîoften focused on operational improvements. It‚Äôs about applying AI as a tool to solve clearly defined problems like automating customer service, improving demand forecasting, or streamlining data entry. Tactical use tends to be incremental, often siloed within departments, and relatively easy to implement without changing the organization‚Äôs core strategy.\n\n\n\nStrategically, on the other hand, means adopting AI in a way that reshapes the organization‚Äôs long-term direction, business model, or competitive advantage. Strategic adoption involves aligning AI with the company‚Äôs mission, investing in infrastructure and talent, rethinking how value is created and delivered, and often reimagining entire workflows or offerings. It‚Äôs about integrating AI into the organization‚Äôs DNA.\nTactical AI is about doing things better, while strategic AI is about doing better things.\n\n\n\nTacit vs.¬†Strategic Use of AI\n\nTacit Use of AI (Incremental, Operational)\n\nAI applied to narrow tasks like automation, simple analytics, local optimizations.\nExample: Using AI to speed up loan approvals at a bank, or to forecast inventory in retail.\nValue is immediate but limited; it doesn‚Äôt fundamentally change the business model.\nAI as a ‚Äútool‚Äù, not a transformation.\n\nStrategic Use of AI (Transformational, Systemic)\n\nAI becomes the core operating model, shaping how the company creates and captures value.\nExample: Microsoft embedding AI into every product and workflow, Fidelity reorganizing around data + agile product teams.\nValue is compounding, as AI drives new platforms, ecosystems, and industry leadership.\nAI as the foundation of a new enterprise architecture.\n\nTacit vs.¬†Strategic Use of AI\n\nTacit Use of AI (Incremental, Operational)\n\nAI applied to narrow tasks like automation, simple analytics, local optimizations.\nExample: Using AI to speed up loan approvals at a bank, or to forecast inventory in retail.\nValue is immediate but limited; it doesn‚Äôt fundamentally change the business model.\nAI as a ‚Äútool‚Äù, not a transformation.\n\nStrategic Use of AI (Transformational, Systemic)\n\nAI becomes the core operating model, shaping how the company creates and captures value.\nExample: Microsoft embedding AI into every product and workflow, Fidelity reorganizing around data + agile product teams.\nValue is compounding, as AI drives new platforms, ecosystems, and industry leadership.\nAI as the foundation of a new enterprise architecture.\n\n\n\n\n\nDiscussion Questions\n\nCan every company become an AI company, or are some better suited than others?\n\n\n\nWhat organizational or cultural barriers might prevent a company from trusting algorithmic decisions?\n\n\n\nValue Creation Capture vs Value Delivery\n\n\n\nFigure 2-2\n\n\n\nAdapted from Figure 2-2, ‚ÄúValue creation and capture versus value delivery,‚Äù in Iansiti & Lakhani (2020, p.¬†39)\n\n\n\nWhat Makes A High Performer?\n\nFirms excelling in the areas above saw stronger growth and profitability.\nAdaptability and learning were central advantages.\n\n\n\nWhich factor (infrastructure, data, talent, experimentation) do you think is hardest to build? Why?\nWhat metrics or indicators might you track to assess a company‚Äôs AI readiness?\n\n\n\nImplementation Scenarios for AI in the Enterprise\n\nAutomation: Streamlining repetitive tasks and decisions.\nPersonalization: Tailoring customer experiences at scale.\nForecasting & Optimization: Enhancing planning with predictive analytics.\nRecommendation Systems: Driving engagement and sales through AI-curated suggestions.\n\n\n\nWhich AI use case (automation, personalization, forecasting, recommendation) would bring the most value in a retail company? What about healthcare?\nHow might implementing AI in one area (e.g., personalization) impact customer trust or privacy concerns?\n\n\n\nThe World‚Äôs Toughest AI Business\n\nHealthcare is described as the most challenging arena for AI adoption.\n\nComplexity of Data: Medical data is highly fragmented (across hospitals, insurers, labs), sensitive (privacy laws like HIPAA), and often unstructured (clinical notes, images).\nHigh Stakes: Mistakes carry life-or-death consequences, unlike other industries where errors may just affect profits.\nRegulatory Environment: Strict oversight makes experimentation, scaling, and deployment much slower than in other industries.\nTrust & Adoption: Doctors, patients, and regulators must trust AI recommendations before adoption; building this trust takes time.\nStrategic Insight: Success in healthcare AI requires deep integration of data, multidisciplinary expertise, and careful governance.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Rethinking the Firm</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Competing Through Artificial Intelligence course explores how organizations achieve competitive advantage through data, analytics, and artificial intelligence. Students examine how firms can leverage AI to transform their operations, structure, and strategy‚Äînot just as a technical upgrade, but as a new way of thinking and working. The class introduces the principles of business strategy in the age of AI, organizational readiness, and the shift from human- to algorithm-centered workflows, guided by case studies and the foundational ideas of Iansiti and Lakhani. Throughout, students learn how analytics, data infrastructure, and AI maturity drive performance and scalability across industries.\nStudents also explore generative AI and multimodal systems, examining how large language models (LLMs) and multimodal LLMs (MLLMs) extend AI‚Äôs capabilities into new domains. This includes understanding model architectures, fine-tuning, GPUs, and ethical design. Ethical frameworks‚Äîautonomy, justice, beneficence, non-maleficence, and explicability‚Äîguide discussions around bias, fairness, transparency, and cybersecurity risks, preparing students to identify and mitigate potential harms of AI technologies. The course emphasizes responsible innovation and governance through applied examples such as deepfakes, algorithmic bias, and data privacy issues.\nFinally, the course transitions from conceptual understanding to hands-on practice. Students gain technical proficiency in Python for data acquisition (APIs, web scraping), integration, visualization, and storytelling. They learn to frame analytics problems, design human-centered dashboards in Dash, and build interactive applications that communicate insights effectively. The course concludes with frameworks for preparing people and organizations for analytics transformation‚Äîdeveloping Centers of Excellence, fostering data literacy, and embedding augmented analytics into workflows. By the end, students are equipped to lead AI-driven initiatives that combine technical skill, ethical judgment, and strategic insight.",
    "crumbs": [
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "preparingpeople.html",
    "href": "preparingpeople.html",
    "title": "Preparing People",
    "section": "",
    "text": "Preparing people for Augmented Analytics (AA) means aligning technical, organizational, and human readiness. Chapter 4 of Augmented Analytics (Weber & Zwingmann, 2024) emphasizes that transformation succeeds only when analytics becomes part of everyday work‚Äîsupported by leadership, literacy, and structured enablement. The chapter outlines four key personas‚Äîleaders, translators, users, and professionals‚Äîeach requiring tailored skills and programs. A Center of Excellence (CoE) anchors this effort by coordinating strategy, training, and governance, ideally evolving from centralized control to a federated model that balances expertise with local ownership.\nThis section also introduces workflow augmentation, where insights are embedded directly into processes through copilots, adaptive assistants, and collaborative tools, rather than delivered via static dashboards. This shift demands cultural change, strong API-based infrastructure, and a curated use-case library to share lessons and scale innovation. Finally, Weber and Zwingmann highlight human barriers‚Äîbias, overconfidence, and learned helplessness‚Äîand stress that sustainable analytics maturity depends on cultivating data literacy, storytelling, and a belief that people, not just technology, drive transformation.\n\n\nReference:\nChapter 4 and 5 from Weber, W., & Zwingmann, T. (2024). Augmented Analytics.\nO‚ÄôReilly Media, Inc.\nAvailable at: https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\n\n\nPreparing people and the organization for Augmented Analytics means building both the skills and the culture needed to embed analytics into daily decision-making. Leaders must champion data-driven practices, analytics translators must bridge business and technical teams, and employees need at least analytics awareness to trust and act on insights. A Center of Excellence (CoE), executive sponsorship, and structured training ensure that AA is not just a technology upgrade but an organizational transformation that empowers all roles to benefit from data in their workflows.\nFocus on roles (leaders, translators, users, professionals) and personas to structure the analytics transformation.\nBuild both technical readiness (data infrastructure, processes) and human readiness (mindset, skills, awareness).\nEstablish a Center of Excellence (CoE) to drive transformation, ideally business-anchored and federated over time.\n\nA CoE is an organizational structure set up to concentrate expertise, best practices, and resources around a specific domain, technology, or strategic priority. Its main purpose is to drive consistency, innovation, and efficiency across an organization.\n\n\n\nTailoring Augmented Analytics for Different Organizational Roles\n\nAnalytics Leader ‚Äì Champions data-driven culture, aligns insights with strategy.\nAnalytics Translator ‚Äì Bridges gap between business and technical teams, ensures use cases deliver value.\nAnalytics User ‚Äì Consumes insights for better decisions; majority of workforce.\nAnalytics Professional ‚Äì Technical experts building and maintaining analytics solutions.\n\n\n\n\nFigure 4-1.Analytics transformation personas in the three skill categories (Weber & Zwingmann, 2024)\n\n\n\n\n\nFigure 4-2. The four top-level roles in the analytics transformation (Weber & Zwingmann, 2024)\n\n\n\n\nCenter of Excellence (CoE)\n\nA CoE is a unit dedicated to organizing the analytics transformation.\nDuring the Data Active maturity phase, it collects and connects all the loose threads of analytics activities that emerge.\n\nPurpose: Organize and guide analytics transformation, connect business units, build culture.\n\nCore responsibilities:\n\nPromoting data literacy and liberalization.\nBuilding quick-win use cases (‚Äúlighthouse‚Äù projects).\nCreating shared governance and culture.\nSupporting business units and connecting their strategies.\nInspiring people across the company to take ownership of analytics\n\n\n\n\n\nFigure 4-4. A center of excellence drawn from both IT and business units (Weber & Zwingmann, 2024)\n\n\n\n\nApproaches to Organizing a CoE\n\nDecentralized Approach\n\nCommon in early-stage, Data Reactive organizations.\nBusiness units develop analytics independently, often using ad hoc tools (Excel, VBA, Python, R, etc.).\nPros: High independence and agility within business domains.\nCons: Lack of governance, scalability issues, silos, and inefficiencies.\nBottom line: Tempting but unsustainable without stronger coordination.\n\nCentralized Approach\n\nCommon in smaller organizations or when business units lack analytical skills.\nA single CoE or IT unit manages analytics, reporting, and infrastructure.\nPros: Efficient, well-designed solutions and processes.\nCons: Bottlenecks, slow responsiveness, weak business insight, lack of shared ownership.\nBottom line: Works for early stages or small orgs but limits growth and responsiveness.\n\n\n\n\nFederated Approach\n\nA hybrid model that balances centralized expertise with decentralized ownership.\nCoE starts as a strong driver, then gradually shifts responsibility to business units as data literacy grows.\nPros:\n\nEncourages shared responsibility and democratization of data.\nBusiness units handle routine analytics while the CoE tackles advanced challenges.\nBuilds a stronger data culture and faster responsiveness.\n\nCons: Requires strong governance, collaboration, and patience.\nBottom line: The most effective model for achieving Data Progressive (stage 3) maturity.\n\n\n\n\nDifficulties Preparing People\n\nInherent bias\n\nMany of us are unaware of our knowledge gaps because we are inherently biased. We don‚Äôt know what we don‚Äôt know.\n\nPerceived solvability\n\nPeople often assume that complex problems can be solved somehow, without actually tackling them and testing the approaches. This is particularly true in the AI environment, where the underlying technology accomplishes wonderful things in vaguely understood ways. It‚Äôs important that people understand how problem solving actually works, because finding a solution usually involves a lot of hard work.\n\nLearned helplessness\n\nRepeated mistakes or negative experiences can lead individuals to believe that they cannot change, creating a state of ‚Äúlearned helplessness.‚Äù Organizations must instill the belief that effort can lead to improvement. With the advent of analytics, there are more opportunities than ever to demonstrate this in action.\n\n\n\n\nCultivating Data Literacy\n\nKey Competencies\n\nAnalytics Awareness\n\nHelps non-specialists understand data processes, quality, visualization, and core AI/ML concepts.\nFosters effective communication with data professionals and realistic expectations for AI projects.\n\nStorytelling with Data\n\nTranslates complex insights into clear narratives for different audiences.\nRequires mastering visualization, decluttering, and tailoring tone/context to make data compelling and actionable.\n\nData-Driven Management\n\nManagers must commit to analytics strategy, ensure data integrity, and integrate analytics into decision-making.\nFocus on aligning analytics with business goals, fostering ownership, and promoting a culture of continuous learning.\n\nLeading in the Age of AI\n\nLeaders need to progress from AI awareness to active engagement.\nCompetencies include identifying AI opportunities, managing AI project lifecycles, and integrating AI into business strategy.\nGoal: build organizational capacity to leverage AI for transformation and innovation.\n\n\n\n\n\n\nFigure 4-7. Four key aspects of data literacy (Weber & Zwingmann, 2024)\n\n\n\n\nEnablement Programs\n\nAnalytics adoption requires different levels of data literacy depending on role.\n\nAnalytics translators need high literacy to identify and develop use cases.\nAnalytics users need analytics awareness‚Äîa general understanding of data‚Äôs value, processes, and visualization‚Äîto effectively use workflows without being experts.\nAnalytics leaders and practitioners need awareness, storytelling, and role-specific competencies.\n\nFor Leaders\n\nInitial workshops, executive roundtables, ThinkLabs, annual leadership summits.\n\nFor Translators\n\nDeep-dives into tools/methods, cross-disciplinary ThinkLabs, mentoring, project presentations\n\nFor Professionals\n\nOngoing technical training (SQL, Python, R, statistics, ML).\n\n\n\n\nWorkflow Augmentation\n\nA workflow is the repeatable sequence of steps, tasks, and decisions employees follow to achieve a business outcome.\nAugmented Analytics succeeds only when insights are embedded inside workflows, not delivered separately in dashboards or reports.\n\n\n\nTypes of Workflow Augmentation\n\nFixed-Rule, High-Confidence Augmentation\n\nAutomated actions when preset conditions are met.\nWorks best for routine, well-defined tasks.\nExample: routing claims or prepopulating CRM entries.\n\n\n\n\n\nIdea & Insight Enrichment\n\nSupports human decision-making with predictions, benchmarks, and visualizations.\nActs as a ‚Äúcopilot,‚Äù surfacing trends or comparisons.\nExample: benchmarking risks in insurance underwriting.\n\nConversational Augmentation\n\nUses GenAI/LLMs in interactive assistants.\nExample: GitHub Copilot for coding, or AI chat tools for summarizing contracts.\n\nContextual (Adaptive) Augmentation\n\nLearns from users‚Äô context, tailoring responses to role, history, or task.\nExample: adaptive email or recommendation systems.\n\nCollaborative Augmentation\n\nEnhances teamwork through shared dashboards, repositories, and chatbots.\nExample: Azure chatbot integrated into Microsoft Teams for compliance support.\n\n\n\n\nFinding Workflows to Augment\n\nUse the Analytics Use-Case Approach: a structured pipeline from idea ‚Üí concept ‚Üí proof of concept ‚Üí prototype ‚Üí pilot ‚Üí product.\n\nEach phase evaluates risk, ROI, and maturity before committing resources.\nSuccess depends on validating assumptions iteratively.\n\nBalancing Automation & Integration\n\nWorkflows vary by automation (how much is done without humans) and integration (how deeply embedded in systems).\n\nFour categories:\n\n\n\nFour Categories\n\n\nBest to start with assistants and copilots before scaling to autopilots and agents.\n\n\n\nThe Use-Case Library\n\nA central repository that tracks all analytics use cases from idea to deployment.\nBenefits: transparency, monitoring, innovation sharing, cultural motivation, visibility of stakeholders.\nOften includes Kanban boards, evaluation matrices, and documentation to foster collaboration and standardization.\n\n\n\n\nKanban Board (Businessmap, n.d.)\n\n\n\n\nTechnical & Organizational Requirements\n\nAPIs & microservices (REST, Python, R) are recommended for flexible, vendor-independent integration.\n\nREST stands for Representational State Transfer. It‚Äôs an architectural style for designing web services and APIs that allow systems to communicate over the internet.\n\nIt decouples front-end and back-end, letting different apps (web, mobile, IoT) consume the same API.\n\nIn the Augmented Workflows chapter, REST APIs are recommended to integrate analytics into business workflows because they are modular, secure, and reusable.\n\nChallenges: legacy systems, IT dependencies, governance, security, and compliance.\nAnalytics contracts (similar to data contracts) are proposed to ensure discoverability, trust, interoperability, and responsible use.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Preparing People</span>"
    ]
  },
  {
    "objectID": "introdash.html",
    "href": "introdash.html",
    "title": "Intro to Dash",
    "section": "",
    "text": "Dash",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Intro to Dash</span>"
    ]
  },
  {
    "objectID": "dataAcquisition.html",
    "href": "dataAcquisition.html",
    "title": "Modern Data Acquisition",
    "section": "",
    "text": "Reference:\nMitchell, R. (2024). Web Scraping with Python (3rd ed.).\nO‚ÄôReilly Media. ISBN: 9781098145354.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modern Data Acquisition</span>"
    ]
  },
  {
    "objectID": "dataAcquisition.html#acquiring-data-from-the-web",
    "href": "dataAcquisition.html#acquiring-data-from-the-web",
    "title": "Modern Data Acquisition",
    "section": "Acquiring Data from The Web",
    "text": "Acquiring Data from The Web\n\nData acquisition is the foundation for all analytics. APIs and web scraping are powerful tools when used appropriately. Next steps: Implementing these techniques in code for real-world projects.\n\n\nAPI vs Web Scraping\n\nAPIs (Application Programming Interfaces)\n\nStandardized interfaces that allow software systems to communicate and exchange data.\nMany companies (e.g., Twitter, Google, OpenWeather) provide APIs to give developers direct, structured access to their data.\nReturns machine-readable formats (JSON, XML) that integrate easily into analytics workflows.\nEnsures consistent, documented, and often real-time data delivery.\n\nWeb Scraping\n\nTechnique for extracting information from the human-readable HTML of websites.\nUseful when no API exists or the API does not provide the needed information.\nInvolves parsing page structure, locating target elements, and cleaning raw data.\nMore fragile than APIs, as changes to page layout can break scraping scripts.\n\n\n\n\nWeb Scraping\n\nWith automated web scraping, you can write the code once, and it‚Äôll get the information that you need many times and from many pages.\n\nWhile some websites don‚Äôt like it when automatic scrapers gather their data, which can lead to legal issues, others don‚Äôt mind it.\nIt‚Äôs a good idea to do some research on your own to make sure you‚Äôre not violating any Terms of Service before you start a large-scale web scraping project.\n\n\n\n\nChallenges of Web Scraping\n\nVariety: Every website is different. While you‚Äôll encounter general structures that repeat themselves, each website is unique and will need personal treatment if you want to extract the relevant information.\n\n\n\nDurability: Websites constantly change. Say you‚Äôve built a shiny new web scraper that automatically cherry-picks what you want from your resource of interest. The first time you run your script, it works flawlessly. But when you run the same script a while later, you run into a discouraging and lengthy stack of tracebacks!\n\n\n\nKey Considerations\n\nUnstructured source ‚Äì extract data from human-oriented HTML\nFragile format ‚Äì page structure may change without warning\nExtra cleanup ‚Äì remove footnotes, symbols, and formatting artifacts\n\n\n\n\nBeautiful Soup\n\n\n\nBeautiful Soup\n\n\n\nBeautiful Soup is a Python library designed for parsing HTML and XML documents. It creates a parse tree from page source code, allowing easy navigation and data extraction from web pages.\nBeautiful Soup is named after a song in Alice‚Äôs Adventures in Wonderland by Lewis Carroll, based on its ability to tackle poorly structured HTML known as tag soup.\nYou‚Äôll often use Beautiful Soup in your web scraping pipeline when scraping static content, while you‚Äôll need additional tools such as Selenium to handle dynamic, JavaScript-rendered pages.\nUsing Beautiful Soup is legal because you only use it for parsing documents. Web scraping in general is also legal if you respect a website‚Äôs terms of service and copyright laws.\n\n\n\nWeb Scraping Basics\n\nUnderstanding the basic structure of HTML or XML languages is crucial.\nBeautiful Soup scrapes data by reading the HTML or XML content and converting it into a parse tree of Python objects. Next, it navigates the parse tree to find elements by their tags, attributes, or text content, before extracting the data.\n\nHTML and XML are tagged languages. HTML is primarily a way to visually present content to users.\nFor example, using &lt;p&gt;Hello&lt;/p&gt;\n\nTags: &lt;p&gt; &lt;/p&gt; means paragraph and the content in it is the text that should be in paragraph format.\nNavigable strings: text within a tag, e.g., the text ‚ÄúHello‚Äù in &lt;p&gt;Hello&lt;/p&gt;, or comments\n\n\n\n\n\nPractical Applications of Beautiful Soup\n\nCompetitor Analysis: Scrape product listings, prices, and reviews from competitors to uncover strategies and market trends.\nSentiment Analysis: Collect user opinions from forums and reviews to understand public sentiment and improve offerings.\nAcademic & Market Research: Aggregate data from news sites, journals, and databases to identify trends and generate insights.\nPrice Monitoring: Track e-commerce prices in real-time to maintain competitive pricing strategies.\nContent Aggregation: Gather news, blogs, and social updates for curated content and industry trend tracking.\n\n\n\nIntegrating Beautiful Soup with Other Tools\n\nBeautiful Soup can work with other Python libraries and tools to combine them into an even more powerful toolkit for web scraping.\n\nPandas: Used for data manipulation and analysis, it makes accessible the cleaning and organizing of the scraped data.\nlxml: Another top XML and HTML processing library within Python that Beautiful Soup can tap into for quicker parsing.\nSelenium is a popular choice for scraping dynamic content. Selenium automates a full browser and can execute JavaScript, allowing you to interact with and retrieve the fully rendered HTML response for your script",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modern Data Acquisition</span>"
    ]
  },
  {
    "objectID": "webscrapingandapi.html",
    "href": "webscrapingandapi.html",
    "title": "Web Scraping and APIs",
    "section": "",
    "text": "Steps to Web Scraping",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Web Scraping and APIs</span>"
    ]
  },
  {
    "objectID": "webscrapingandapi.html#python-weather-api-request-with-annotations",
    "href": "webscrapingandapi.html#python-weather-api-request-with-annotations",
    "title": "Web Scraping and APIs",
    "section": "Python Weather API Request with Annotations",
    "text": "Python Weather API Request with Annotations\nThe following Python script uses the requests library to fetch current weather data for several Virginia cities from the Open-Meteo API and displays the results in a table using pandas.\n\nWeather Data API Request\nThis Python script uses the requests library to fetch current weather data for several Virginia cities from the Open-Meteo API and displays the results in a table using pandas.\n\n\nWeb Scraped Example\n\nimport pandas as pd\nimport requests\n\n# Wikipedia page\nurl = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n\n# Fetch the page with requests (adds headers automatically)\nheaders = {\"User-Agent\": \"Mozilla/5.0\"}\nresponse = requests.get(url, headers=headers)\nresponse.raise_for_status()  # will throw an error if request fails\n\n# Parse all tables from the HTML\ntables = pd.read_html(response.text)\n\n# Heuristic: pick the table with Location + Population\ncandidate = None\nfor t in tables:\n    cols = [c.lower() for c in t.columns.astype(str)]\n    if any(\"location\" in c for c in cols) and any(\"population\" in c for c in cols):\n        candidate = t\n        break\n\nif candidate is None:\n    raise ValueError(\"Could not find a suitable table on the page.\")\n\n# Normalize column names\ncol_map = {}\nfor c in candidate.columns:\n    cl = str(c).lower()\n    if \"location\" in cl:\n        col_map[c] = \"Location\"\n    elif \"population\" in cl:\n        col_map[c] = \"Population\"\n\ndf_scrape = candidate.rename(columns=col_map)[[\"Location\", \"Population\"]].copy()\n\n# Clean Population\ndf_scrape[\"Population\"] = (\n    df_scrape[\"Population\"]\n    .astype(str)\n    .str.replace(r\"\\[.*?\\]\", \"\", regex=True)   # remove footnotes\n    .str.replace(\",\", \"\", regex=False)         # remove commas\n    .str.extract(r\"(\\d+)\", expand=False)       # extract digits\n    .astype(\"Int64\")\n)\n\n# Top 10 countries\ndf_scrape = (\n    df_scrape.dropna(subset=[\"Population\"])\n             .sort_values(\"Population\", ascending=False)\n             .head(10)\n             .reset_index(drop=True)\n)\n\nprint(df_scrape)\n\nWhy this is ‚Äúscraping‚Äù:\n\nYou fetch human-oriented HTML and parse it yourself Columns, order, or markup may change without notice Often needs extra cleaning (footnotes, commas, superscripts, etc.)\n\n\n\nAPI vs Web Scraping\n\n\n\nDiscussion Questions\n\nMuch online content (text, images, code) is protected by copyright. Scraping may be legal for viewing content, but using it to train AI‚Äîa form of reproduction‚Äîcan violate copyright if done without permission.\nExample: The NYT and other publishers are suing AI companies for scraping their content without licensing.\nWhat are the ethical and legal boundaries of scraping data for training AI models?",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Web Scraping and APIs</span>"
    ]
  },
  {
    "objectID": "crashcourse.html",
    "href": "crashcourse.html",
    "title": "Crash Python Course",
    "section": "",
    "text": "This crash course provides a hands-on introduction to Python fundamentals for analytics and data science. It starts with basic arithmetic and variable assignment, then explores strings, including concatenation, indexing, slicing, and built-in methods like .upper() and .find(). Learners move on to lists, tuples, and dictionaries, understanding their structure, mutability, and use cases‚Äîculminating in nested dictionaries that model complex data relationships.The course then introduces conditional statements (if, elif, else), loops (for, while), and functions‚Äîincluding parameters, default values, and return statements. Practical examples demonstrate how to encapsulate logic, make decisions, and control program flow.Finally, the module transitions into NumPy, showing how arrays extend Python‚Äôs list capabilities for efficient, vectorized computation. Students learn to create arrays, loop through elements, and use np.append() and arithmetic operations to manipulate numeric data.By the end, students gain a working foundation in Python syntax, logic, and data structures, preparing them to move into applied analytics, data manipulation, and visualization.\nIn this crash course, all code examples are written and executed in Visual Studio Code (VS Code), but the file is saved as a Jupyter Notebook (.ipynb). A Jupyter Notebook is an interactive environment that combines code, output, and explanatory text in a single document‚Äîideal for teaching, experimentation, and data analysis. Unlike a standard Python file (.py), which runs code sequentially as a script, a notebook lets you execute code cell by cell, view results immediately, and include Markdown notes alongside. This makes it especially useful for learning and documenting analytics workflows.\n\nIn contrast, when building Dash applications, files must be saved as Python files (.py), since Dash apps require executable scripts that define layout and callbacks. Jupyter notebooks are excellent for exploration, but Dash needs Python files to run as full web applications.\n\nBasic Math\n\nPython can function as an interactive calculator, allowing you to perform arithmetic operations directly in the interpreter or notebook without writing full programs. You can type expressions like 2 + 3, 10 / 4, or 2**3 and instantly see results, making Python a powerful tool for quick mathematical exploration, data checking, and computation‚Äîfar beyond the capabilities of a basic calculator. Here are some examples below.\n\n\n1+1\n5-9\n5*6\n-4/2\n1.0 + 2.5\n2**3\n\n8\n\n\n\n\nVariables\n\nx=7\ny=\"data\"\n\nprint(x) #printing the variable x\nprint(y) #printing the variable y\n\n##when naming variables, do not use spaces or special characters\n##If you want to use a space, use an underscore instead\n##It is better to use lower case letters for variable names\nmy_variable = 10\nprint(my_variable) ##printing the variable before adding 5\nmy_variable += 5\nprint(my_variable) ##printing the variable after adding 5\n\n7\ndata\n10\n15\n\n\n\n\nWorking with Strings\n\n\"Im into Data Science\"\nquestion = \"What are you studying?\"\nanswer = \"Analytics!\"\n\nprint(question)\nprint(answer)\n\nprint(question + \" \" + answer) # Concatenating strings with a space in between\n\nprint(question + \"\\n\" +answer) # Concatenating strings with a newline in between\n\ntype(answer) # This will show the type of the variable 'answer'\n\nlen(answer) # This will show the length of the string in 'answer'\n\nWhat are you studying?\nAnalytics!\nWhat are you studying? Analytics!\nWhat are you studying?\nAnalytics!\n\n\n10\n\n\n\n\nIndexing Strings\n\nanswer[0] # This will show the first character of the string in 'answer'\nanswer[2] # This will show the third character of the string in 'answer'\nanswer[9] # This will show the tenth character of the string in 'answer'\nanswer[-1] # This will show the last character of the string in 'answer'\n\n'!'\n\n\n\n\nSlicing\n\ncourse[0:2] ‚Üí ‚ÄòC‚Äô and ‚ÄòT‚Äô (includes index 0 and 1; excludes 2)\nPython slices are start-inclusive and end-exclusive\n\n\ncourse = \"CTBA\"\nlen(course) # This will show the length of the string in 'course'\nprint(course[0:2]) # This will show the first 3 characters of the string in 'course'\n\nCT\n\n\n\n\nMethods and Functions\n\nAssociated with a Python object/class such as strings\n\nCalled by its name on the Python object\n\nExample: st.upper()\n(This works because st is a string)\nInvalid: num.upper() (won‚Äôt work unless num is a string)\n\n\nFunctions\n\nDefined independently from a specific python object/class\nCalled by its name only\n\n\n\nanswer.upper() # This will convert the string in 'answer' to uppercase\nanswer_cap = answer.upper()\nprint(answer_cap) # This will print the uppercase version of 'answer'\nanswer.lower() # This will convert the string in 'answer' to lowercase  \nanswer.find(\"t\")\n\nANALYTICS!\n\n\n5\n\n\n\n\nNew\n\nprint(\"Hello\") #Built in function\n\ntext = \"hello\"\nprint(text.upper()) \n\nHello\nHELLO\n\n\n\n\nAdding text and f-strings\n\nUses + to join strings manually.The variable name must be converted to a string if it isn‚Äôt one already. More prone to formatting issues or errors if types mismatch.\nUses f-strings, introduced in Python 3.6. Allows you to embed variables directly inside {}.Cleaner, more readable, and better for mixing variables and text.\n\n\nname = \"Pamela Schlosser\"\nprint(\"Hello, I am \" + name + \". I have been teaching at WM since 2020.\")    \nprint(f\"Hello, I am {name}. I have been teaching at WM since 2020.\") \n\nHello, I am Pamela Schlosser. I have been teaching at WM since 2020.\nHello, I am Pamela Schlosser. I have been teaching at WM since 2020.\n\n\n\n\nLists\n\nl1 = [1,2,3,4,5]\nl2 = [\"a\", \"hello\", \"c\", 2, 3.6]\nprint(l1 + l2) # This will concatenate the two lists\n\n[1, 2, 3, 4, 5, 'a', 'hello', 'c', 2, 3.6]\n\n\n\nl1.append(6) # This will add 6 to the end of the list l1\nprint(l1) # This will print the updated list l1\n\nl1.pop() # This will remove the last element from the list l1\nprint(l1) # This will print the updated list l1 after popping the last element\n\nl1.sort() # This will sort the list l1 in ascending order\n\n[1, 2, 3, 4, 5, 6]\n[1, 2, 3, 4, 5]\n\n\n\n\nTuple\n\nt1 = (1, 2, 3, 4, 5) # This is a tuple\nprint(t1) # This will print the tuple t1\n\n#t1[0] = 11 # This will raise an error because tuples are immutable\n\n(1, 2, 3, 4, 5)\n\n\n\n\nDictionaries\n\nA dictionary is a built-in Python data type that stores data as key-value pairs.\n\nA key is the identifier used to access a value.\n\nKeys must be unique and immutable (like strings, numbers, or tuples).\nEach key maps to a corresponding value.\nYou use the key inside square brackets or with .get() to retrieve its value.\n\n\nValues can be any data type (including lists, other dictionaries, etc.).\nDictionaries are unordered (prior to Python 3.7) and mutable, meaning you can add, change, or remove items.\n\n\n\nd1 = {\"name\": \"Schlosser\", \"age\": 23, \"city\": \"Williamsburg\"} # This is a dictionary where \"name\", \"age\", and \"city\" are the keys\nprint(d1[\"name\"])     # Output: Schlosser\nd1[\"age\"] = 24         # Updating the age\nd1[\"email\"] = \"pgschlosser@wm.edu\"  # Adding a new key-value pair\nprint(d1)  # Output: {'name': 'Schlosser', 'age': 24, 'city': 'Williamsburg', 'email': '\n\n#Print in a better format using .items method\nfor key, value in d1.items():\n    print(key, \":\", value)\n\nSchlosser\n{'name': 'Schlosser', 'age': 24, 'city': 'Williamsburg', 'email': 'pgschlosser@wm.edu'}\nname : Schlosser\nage : 24\ncity : Williamsburg\nemail : pgschlosser@wm.edu\n\n\n\n\nDictionary of Dictionaries\n\nA dictionary of dictionaries is a nested data structure where each value in the outer dictionary is itself a dictionary.\nIt allows you to organize complex data in a structured, readable way.\nOften used to represent multiple records, like a small database.\nEach person is a nested dictionary with their own name, age, and city.\n\n\npeople = {\n    \"person1\": {\"name\": \"Schlosser\", \"age\": 23, \"city\": \"Williamsburg\"},\n    \"person2\": {\"name\": \"Smith\", \"age\": 30, \"city\": \"Newport News\"}\n}\n\nprint(people)\n\n{'person1': {'name': 'Schlosser', 'age': 23, 'city': 'Williamsburg'}, 'person2': {'name': 'Smith', 'age': 30, 'city': 'Newport News'}}\n\n\n\ndistances = {\n    \"A\": {\"B\": 10, \"C\": 15},\n    \"B\": {\"A\": 10, \"C\": 20},\n    \"C\": {\"A\": 15, \"B\": 20}\n}\n\n\n\nIf Statements in Python\n\nExplanation\n\nThe if keyword checks if a condition is True.\nIf the condition x &gt; 5 is met, the indented code runs.\n\nWhat happens if we change x to 3.\n\n\nx = 10\n\nif x &gt; 5:\n    print(\"x is greater than 5\")\n\nx is greater than 5\n\n\n\n\nIf‚ÄìElse Statements\n\nExplanation\n\n% is the modulo operator (remainder).\n== checks equality.\nelse runs if the if condition is false.\n\nCan you write this to check if x is divisible by 3?\n\n\nx = 4\n\nif x % 2 == 0:\n    print(\"x is even\")\nelse:\n    print(\"x is odd\")\n\nx is even\n\n\n\n\nIf‚ÄìElif‚ÄìElse Chains\n\nExplanation\n\nUse elif (else if) to check multiple conditions.\nOnly the first True block executes.\n\nTry this with different values of x.\n\n\nx = 0\n\nif x &gt; 0:\n    print(\"Positive\")\nelif x == 0:\n    print(\"Zero\")\nelse:\n    print(\"Negative\")\n\nZero\n\n\n\n\nFor Loops\n\nExplanation\n\nrange(5) gives values from 0 to 4.\nfor i in range(5) loops through those values.\n\nModify it to print only even numbers.\n\n\nfor i in range(5):\n    print(\"i is\", i)\n\ni is 0\ni is 1\ni is 2\ni is 3\ni is 4\n\n\n\n\nWhile Loop with If Statement\n\nExplanation\n\nA while loop repeats while the condition is true.\nx += 1 increases x by 1 each time.\n\nWhat would happen if we forgot x += 1?\n\n\nx = 0\n\nwhile x &lt; 5:\n    if x % 2 == 0:\n        print(x, \"is even\")\n    else:\n        print(x, \"is odd\")\n    x += 1\n\n0 is even\n1 is odd\n2 is even\n3 is odd\n4 is even\n\n\n\n\nFunctions\n\ndef my_first_function():\n    \"\"\"     \n    This is where we put the docstring\n    including input parameters, and output\n    \"\"\"\n\n    print(\"This is my first function\")\n\n\ndef sum_up(a, b):\n     print(a+b)\n     \nsum_up(1,2)\n\nsum_up(a=1, b=2)\n\n3\n3\n\n\n\n\nCan set default values\n\nDefault values are preset values assigned to function parameters. If the caller does not provide a value for that parameter, the default is used.\n\nMany built-in and custom functions use default values to make them more flexible.\nThey allow you to omit arguments when calling a function.\nMakes functions easier to use and reduces the need for overloading.\n\n\ndef sum_up(a=1, b=1):\n     print(a+b)\n\n\n\n\nreturn statement\n\nThe return statement is used inside a function to send a value back to the caller of the function.\n\nWithout return, a function returns None by default.\nYou can return any data type: numbers, strings, lists, even other functions.\nYou can return multiple values using commas\n\nThe function below will use the default values of a and b and assign the result to a new variable ‚Äòresult‚Äô\nThis will print the result of the sum_up function\n\n\ndef sum_up(a=1, b=1):\n     return(a+b)\nresult= sum_up()  \nprint(result)   \n\n2\n\n\n\n\nIf Else in a Function\n\nYou can use if/else inside a function to control which statements run based on the input. This lets your function make decisions and return different results depending on conditions.\n\n\ndef abs_value(k):\n    \"\"\"Returns the absolute value of a number.\"\"\"\n    if k &lt; 0:\n        return -k\n    else:\n        return k\n    \nabs(-5)  # This will return 5\nabs(5)  # This will return 5\n\n5\n\n\n\n\nUsing a Function from a Package\n\nPrint a basic Python list\n\n\nlist1 = [1,2,3,4,5]\nprint(list1)\n\n[1, 2, 3, 4, 5]\n\n\n\nImport the NumPy library and alias it as np\n\n\nimport numpy as np\n\n\nCreate and print a NumPy array named arr1 from a list\nlist2 is a list of tuples, treated as a list of rows\narr2 is a 2D NumPy array that now supports array operations\n\n\narr1 = np.array([1,2,3,4,5])\nprint(arr1)\nlist2 = [(1,2,3),(4,5,6)]\nprint(list2)\narr2 = np.array([(1,2,3),(4,5,6)])\nprint(arr2)\n\n[1 2 3 4 5]\n[(1, 2, 3), (4, 5, 6)]\n[[1 2 3]\n [4 5 6]]\n\n\n\nLoop 1 loops through a Python list and print elements.\nLoop 2 using arr1 loops through a NumPy array ‚Äî works the same at this level.\n\n\nlist = [1,2,3]\narr1 = np.array([1,2,3])\nfor e in list:\n    print(e) #Loop through a Python list and print elements\nfor e in arr1:\n    print(e)  # Loop through a NumPy array ‚Äî works the same at this level\n\n1\n2\n3\n1\n2\n3\n\n\n\nBelow, we are exploring how to add elements to a NumPy array, and highlighting the difference between Python lists and NumPy arrays when it comes to appending:\nUse np.append() to add elements to an array\n\narr1.append(4) does not work ‚Äî unlike lists, NumPy arrays do not have an .append() method. It raises an AttributeError.\narr1 = arr1 + [5] is also incorrect ‚Äî adding a list to a NumPy array does not work unless the shapes are compatible, which they are not in this case.\n\n\n\narr1 = np.array([1,2,3])\n# these do not work:\n#arr1.append(4)\n#arr1 = arr1 + [5]\narr1 = np.append(arr1,4)\narr1 = np.append(arr1,[5]) #Append another element\nfor e in arr1:\n    print(e) # Prints updated array values\n\n1\n2\n3\n4\n5\n\n\n\nAdd two arrays element-wise\nPrint the result: each value is doubled\n\n\narr2 = arr1 + arr1\nfor e in arr2:\n    print(e)\n\n2\n4\n6\n8\n10",
    "crumbs": [
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Crash Python Course</span>"
    ]
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Using Git and Github",
    "section": "",
    "text": "This module introduces Git and GitHub as foundational tools for version control, collaboration, and deployment in analytics and programming projects. Git is a decentralized version control system that tracks file changes and manages project history locally, while GitHub is a cloud-based platform built on Git for sharing, collaborating, and managing repositories. Together, they allow multiple contributors to work efficiently through commits, branches, merges, and pull requests. GitLab offers similar features but can be self-hosted for greater organizational control.\nStudents learn to set up Git and GitHub, configure user credentials, and perform essential commands (git init, git add, git commit, git push, etc.) using VS Code or GitHub Desktop. They also explore GitHub CoPilot, an AI-assisted coding tool that autocompletes and suggests code within VS Code.\nThe section covers best practices such as writing clear commit messages, pulling often to stay updated, using .gitignore to exclude unnecessary files, and maintaining a stable main branch. It also outlines common troubleshooting tips for merge conflicts, authentication issues, and accidental commits.\nFinally, the module introduces Render.com, a platform that connects directly to GitHub for seamless web app deployment. Students link their GitHub repositories to Render to host and automatically update their Dash or analytics applications, gaining hands-on experience with real-world deployment workflows.\n\n\nUnderstanding the prompting paradigm equips you to guide AI models effectively‚Äîskills that can be enhanced and shared by leveraging platforms like GitHub to collaborate on prompt libraries, examples, and AI-powered projects.\n\n\n\nPurpose of Git\n\nGit is a decentralized version control system for tracking file changes, especially in software projects with many small text files. It records who made changes and when, supports collaboration, and keeps all past versions and branches.\nWorks best with text files; less effective for binary files like Word docs, audio/video, or VM images. git Command\n\nThe primary way to control Git via the terminal/PowerShell.\nTasks: download projects, commit changes, switch branches, undo edits, etc.\n\n‚ÄúGit‚Äù (capitalized) = the system/concepts;\ngit (lowercase) = the command.\n\n\nIDEs (e.g., Visual Studio) and editors (e.g., VS Code) offer built-in Git tools; web platforms like GitHub/GitLab add extra features (issue tracking, automated tests).\n\n\n\nGit vs GitHub vs GitLab\n\nGit: Works without central servers.\nGitHub: Most popular host; acquired by Microsoft in 2018; free for public and most private projects.\n\nA cloud-based platform for hosting and collaborating on code projects\nBuilt on Git (a distributed version control system)\nSupports version tracking, collaboration, and project management\n\nEnables teamwork on coding projects\nProvides a historical record of changes\nIntegrates with many tools\n\n\nGitLab: Similar features; open-source, can be self-hosted‚Äîgood for organizations that want control.\n\n\n\nSetting Up GitHub\n\n\nCreate an account at github.com\nInstall Git (if using locally): https://gitforwindows.org/\nConfigure Git\n\nbash\ngit config ‚Äìglobal user.name ‚ÄúYour Name‚Äù git config ‚Äìglobal user.email ‚Äúyou@example.com‚Äù\n\nCan install GitHub Desktop (optional) for a GUI\nUse VS Code as Editor\n\n\n\nCoPilot Autofill\n\n\nTo change the setting that makes Copilot ghost text appear as you type.\n\nGo to VS Code Settings\nSearch for Copilot: Inline Suggest.\nEnsure that ‚ÄúEditor ‚Ä∫ Inline Suggest: Enabled‚Äù is checked.\n\n\n\n\nKey Git Concepts\n\nRepository (Repo) ‚Äì where your project‚Äôs code and history live\nCommit ‚Äì a saved snapshot of your code\nBranch ‚Äì an independent line of development\nMerge ‚Äì bringing changes from one branch into another\nPull Request (PR) ‚Äì proposing changes for review\nClone ‚Äì downloading a copy of the repo to your local machine\nPush ‚Äì sending your local changes to GitHub\n\n\n\nCreating Your First Repository\n\nGo to GitHub ‚Üí Click New Repository\nName your repo and choose:\n\nPublic or Private\nDon‚Äôt add a README (We are going to push from VS Code, so it is better if the Repo is Blank)\n\nLocal option: create folder ‚Üí git init ‚Üí link to GitHub repo\nInitial commit example within VS Code:\n\ngit init\ngit add .\ngit commit -m ‚ÄúInitial commit‚Äú\ngit branch ‚ÄìM main\ngit remote add origin https://github.com/USERNAME/REPO_NAME.git\ngit push -u origin main\n\nAlso, notice the source control button on the left of VS Code that has changes to commit.\n\n\n\nBest Practices\n\nWrite clear commit messages (‚ÄúFix login bug‚Äù &gt; ‚Äústuff‚Äù)\nPull often to stay updated:\n\nbash\ngit pull origin main\n\nUse .gitignore to avoid uploading sensitive or unnecessary files\nKeep main branch stable\nUse Issues and Project Boards for task tracking\n\n\n\nTroubleshooting Common Issues\n\nMerge conflicts ‚Äì when two people change the same code section\nAuthentication errors ‚Äì fix with SSH keys or GitHub token\nForgetting to pull ‚Äì always update before pushing\nAccidental commits ‚Äì use git reset or revert commits\n\n\n\nRender.com\n\n\nEasy Git-based Deployment ‚Äì Connect GitHub or GitLab for automatic builds and updates.\nFull-Stack Hosting ‚Äì Run web apps, APIs, static sites, and background jobs on one platform.\nBuilt-in Scaling & Security ‚Äì Automatic HTTPS, DDoS protection, and autoscaling.\nGlobal Performance ‚Äì CDN for static assets and low-latency infrastructure worldwide.\nMake a render account for you to link to your github account.\nConnect it to your CTBA repo.\n\n\n\nhttps://dashboard.render.com/",
    "crumbs": [
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Using Git and Github</span>"
    ]
  },
  {
    "objectID": "github.html#git-and-git-hub",
    "href": "github.html#git-and-git-hub",
    "title": "github",
    "section": "",
    "text": "Understanding the prompting paradigm equips you to guide AI models effectively‚Äîskills that can be enhanced and shared by leveraging platforms like GitHub to collaborate on prompt libraries, examples, and AI-powered projects.\n\n\n\nPurpose of Git\n\nGit is a decentralized version control system for tracking file changes, especially in software projects with many small text files. It records who made changes and when, supports collaboration, and keeps all past versions and branches.\nWorks best with text files; less effective for binary files like Word docs, audio/video, or VM images. git Command\n\nThe primary way to control Git via the terminal/PowerShell.\nTasks: download projects, commit changes, switch branches, undo edits, etc.\n\n‚ÄúGit‚Äù (capitalized) = the system/concepts;\ngit (lowercase) = the command.\n\n\nIDEs (e.g., Visual Studio) and editors (e.g., VS Code) offer built-in Git tools; web platforms like GitHub/GitLab add extra features (issue tracking, automated tests).\n\n\n\nGit vs GitHub vs GitLab\n\nGit: Works without central servers.\nGitHub: Most popular host; acquired by Microsoft in 2018; free for public and most private projects.\n\nA cloud-based platform for hosting and collaborating on code projects\nBuilt on Git (a distributed version control system)\nSupports version tracking, collaboration, and project management\n\nEnables teamwork on coding projects\nProvides a historical record of changes\nIntegrates with many tools\n\n\nGitLab: Similar features; open-source, can be self-hosted‚Äîgood for organizations that want control.\n\n\n\nSetting Up GitHub\n\n\nCreate an account at github.com\nInstall Git (if using locally): https://gitforwindows.org/\nConfigure Git\n\nbash\ngit config ‚Äìglobal user.name ‚ÄúYour Name‚Äù git config ‚Äìglobal user.email ‚Äúyou@example.com‚Äù\n\nCan install GitHub Desktop (optional) for a GUI\nUse VS Code as Editor\n\n\n\nCoPilot Autofill\n\n\nTo change the setting that makes Copilot ghost text appear as you type.\n\nGo to VS Code Settings\nSearch for Copilot: Inline Suggest.\nEnsure that ‚ÄúEditor ‚Ä∫ Inline Suggest: Enabled‚Äù is checked.\n\n\n\n\nKey Git Concepts\n\nRepository (Repo) ‚Äì where your project‚Äôs code and history live\nCommit ‚Äì a saved snapshot of your code\nBranch ‚Äì an independent line of development\nMerge ‚Äì bringing changes from one branch into another\nPull Request (PR) ‚Äì proposing changes for review\nClone ‚Äì downloading a copy of the repo to your local machine\nPush ‚Äì sending your local changes to GitHub\n\n\n\nCreating Your First Repository\n\nGo to GitHub ‚Üí Click New Repository\nName your repo and choose:\n\nPublic or Private\nDon‚Äôt add a README (We are going to push from VS Code, so it is better if the Repo is Blank)\n\nLocal option: create folder ‚Üí git init ‚Üí link to GitHub repo\nInitial commit example within VS Code:\n\ngit init\ngit add .\ngit commit -m ‚ÄúInitial commit‚Äú\ngit branch ‚ÄìM main\ngit remote add origin https://github.com/USERNAME/REPO_NAME.git\ngit push -u origin main\n\nAlso, notice the source control button on the left of VS Code that has changes to commit.\n\n\n\nBest Practices\n\nWrite clear commit messages (‚ÄúFix login bug‚Äù &gt; ‚Äústuff‚Äù)\nPull often to stay updated:\n\nbash\ngit pull origin main\n\nUse .gitignore to avoid uploading sensitive or unnecessary files\nKeep main branch stable\nUse Issues and Project Boards for task tracking\n\n\n\nTroubleshooting Common Issues\n\nMerge conflicts ‚Äì when two people change the same code section\nAuthentication errors ‚Äì fix with SSH keys or GitHub token\nForgetting to pull ‚Äì always update before pushing\nAccidental commits ‚Äì use git reset or revert commits\n\n\n\nRender.com\n\n\nEasy Git-based Deployment ‚Äì Connect GitHub or GitLab for automatic builds and updates.\nFull-Stack Hosting ‚Äì Run web apps, APIs, static sites, and background jobs on one platform.\nBuilt-in Scaling & Security ‚Äì Automatic HTTPS, DDoS protection, and autoscaling.\nGlobal Performance ‚Äì CDN for static assets and low-latency infrastructure worldwide.\nMake a render account for you to link to your github account.\nConnect it to your CTBA repo.\n\n\n\nhttps://dashboard.render.com/",
    "crumbs": [
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>github</span>"
    ]
  },
  {
    "objectID": "makingcallbacks.html",
    "href": "makingcallbacks.html",
    "title": "Writing Callbacks and Accessing API‚Äôs",
    "section": "",
    "text": "Callbacks\nThe lesson concludes with a hands-on example using NASA‚Äôs Astronomy Picture of the Day (APOD) API. Students build a Dash app that lets users select a date, retrieves NASA‚Äôs image or video for that day using the requests library, and displays the title, media, and explanation. Through this exercise, they learn how to combine callbacks, APIs, and conditional logic to create dynamic, data-driven dashboards.\ndef function_name(inputs):\n   #body of the function\n   return outputs",
    "crumbs": [
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Writing Callbacks and Accessing API's</span>"
    ]
  },
  {
    "objectID": "multilayout.html",
    "href": "multilayout.html",
    "title": "Creating a Grid Layout in Dash",
    "section": "",
    "text": "This section demonstrates how to create grid-based layouts in Dash using Dash Bootstrap Components (dbc) to make dashboards organized, responsive, and professional. It begins by contrasting Dash‚Äôs default vertical stacking of components with the flexible row-and-column grid system provided by Bootstrap. Students learn to use dbc.Row() and dbc.Col() to arrange content horizontally, apply embedded styles or external themes, and control spacing and responsiveness.The lesson then builds a full multi-column dashboard that integrates real-world data from the Open-Meteo API. Using the requests and pandas libraries, students fetch 48-hour temperature forecasts for selected Virginia cities and visualize them with Plotly Express. Bootstrap cards are used to display key metrics (current, min, and max temperature), a line chart, and a dynamic summary table‚Äîall arranged neatly within a responsive layout. By the end, students understand how to combine layout design, API integration, and callback interactivity to produce multi-section Dash applications that look clean, adapt to screen size, and display live data through structured and reusable components.\n\n\nDash Layout Structure\n\nDash Default Structure\n\nComponent 1\n‚Üì\nComponent 2\n‚Üì\nComponent 3\n\nWhat if used this horizontal layout?\n\nComponent 1 ‚ÜíComponent 2 ‚Üí Component 3\n\nComponents are stacked vertically (top to bottom).\n\nUseful for dashboards where content is consumed in a specific order (e.g., filters ‚Üí charts ‚Üí details).\nIn Dash, this happens naturally when placing components inside an html.Div() without specifying a grid or flex layout.\nExample: A dropdown filter at the top, followed by a summary chart, then a detailed table.\n\n\n\n\nWhat is Bootstrap?\n\nBootstrap is a popular framework for front-end web development\nProvides grid layout, prebuilt components, and more\nDash Bootstrap Components (dbc & dash-bootstrap-components):\n\nDash library provides Bootstrap components (including the grid system layout), stylesheets, and more\n\nBootstrap layout components\n\nComponents for laying out Dash apps, including the grid system\nTwo main layout components:\n\nRow: container for columns\nCol: where the content is placed\n\nOnly Col components should be immediate children of the Row component\n\n\n\n\nTop Components in dbc\n\n\n\nCreating a Grid Layout: Examples\n\nLayout example 1\nRow\n\n| One of two coulmns | One of two columns |\n\n\n\n#Import Dash Bootstrap Components\nimport dash_bootstrap_components as dbc\nfrom dash import html\n\ndbc.Row(\n   [\n      dbc.Col(html.Div('One of two Columns')),\n      dbc.Col(html.Div('One of two Columns'))\n]\n)\n\n\nLayout example 2\n\nRow | A single column |\nRow | One of two columns | One of two columns |\n\n\n\n#Import Dash Bootstrap Components\nimport dash_bootstrap_components as dbc\nfrom dash import html\n\ndbc.Row(\n   dbc.Col(html.Div('A single column'))\n),\ndbc.Row(\n   [\n      dbc.Col(html.Div('One of two columns')),\n      dbc.Col(html.Div('One of two columns'))\n]\n)\n\n\n\nMaking a 2-column layout\n\ndash_bootstrap_components lets you plug in a full Bootstrap theme via an external stylesheet. This instantly gives your app Bootstrap‚Äôs responsive grid, typography, and utility classes, and it styles all dbc.* components consistently‚Äîno custom CSS required.\n\nYou can swap themes (e.g., dbc.themes.COSMO, LUX, MATERIA, CYBORG) for a new look and still override specifics in your own assets/style.css.\n\n\n\nfrom dash import Dash, html\nimport dash_bootstrap_components as dbc\n\n\napp = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\napp.title = \"Multi Layout App\"\n\n\nEmbedded stylesheets in Dash are simple Python dictionaries you attach via the style prop\n\n\nbox_style = {\n    \"border\": \"2px solid black\",\n    \"borderRadius\": \"5px\",\n    \"margin\": \"5px\",\n    \"padding\": \"20px\", \n    \"backgroundColor\": \"#e0f7fa\"\n}\n\n\nPerfect for quick, local styling and prototypes.\nFor shared, consistent styling across a multi-page app, shift most rules to an external stylesheet in assets/ and reserve embedded styles for small overrides.\n\n\napp.layout = dbc.Container([\n    ##first row\n    dbc.Row(\n        dbc.Col(html.Div(\"Top Row (Full Width)\", style=box_style), width=12)),\n    dbc.Row([\n        dbc.Col(html.Div(\"Left Column\", style=box_style)),\n        dbc.Col(html.Div(\"Right Column\", style=box_style))\n    ]),\n    dbc.Row(dbc.Col(html.Div(\"Footer (Full Width)\", style=box_style), width=12))\n    \n], fluid=True)\n                   \n  \nif __name__ == \"__main__\":\n    app.run(debug=True)\n\n\n\n\nCreating a Multi-Layout App with Weather API\n\n# MultiLayoutWeather.py\nimport requests\nimport pandas as pd #for data frame and manipulation\nfrom dash import Dash, html, dcc, Input, Output \nimport dash_bootstrap_components as dbc #for bootstrap components\nimport plotly.express as px #for data visualization\n\n\n# ---------- Public API helper (Open-Meteo) ----------\n#selecting the cities and their coordinates\n# This is a dictionary mapping city names to their latitude and longitude.\nCITY_COORDS = {\n    \"Williamsburg\": (37.2707, -76.7075),\n    \"Richmond\": (37.5407, -77.4360),\n    \"Virginia Beach\": (36.8529, -75.9780),\n    \"Roanoke\": (37.27097, -79.94143),\n    \"Charlottesville\": (38.0293, -78.4767)\n}\n\n\n\n\nFetching the Hourly Temperature\n\nCreate a function fetch_hourly_temp(lat, lon) that takes a latitude/longitude and returns a Pandas DataFrame of next 48 hours of hourly temperatures.\nBuilds API URL: Uses the Open-Meteo forecast endpoint with query params, where an endpoint is the specific URL where an API resource or service can be accessed.\n\nlatitude, longitude,\nhourly=temperature_2m,\nforecast_days=2 (‚âà48 hours),\ntimezone=auto.\n\nCalls the API safely:\n\nrequests.get(‚Ä¶, timeout=15) and r.raise_for_status() to surface HTTP errors (raises an exception if the HTTP request failed).\n\nParses JSON:\n\nExtracts the ‚Äúhourly‚Äù block, specifically the arrays ‚Äútime‚Äù and ‚Äútemperature_2m‚Äù.\nThe 2m means the temperature is measured (or modeled) at 2 meters above ground level.\nConstructs a DataFrame with two columns:\ntime and temp_C (temperature in ¬∞C from temperature_2m).\n\nCleans timestamps by converting the time column to proper datetime objects with pd.to_datetime.\nReturns the final DataFrame of hourly timestamps and temperatures for the requested location.\n\n\ndef fetch_hourly_temp(lat: float, lon: float) -&gt; pd.DataFrame:\n    \"\"\"Fetch next-48-hours hourly temperature.\"\"\"\n    url = (\n        \"https://api.open-meteo.com/v1/forecast\"\n        f\"?latitude={lat}&longitude={lon}\"\n        \"&hourly=temperature_2m&forecast_days=2&timezone=auto\"\n    )\n    r = requests.get(url, timeout=15)\n    r.raise_for_status()\n    data = r.json()[\"hourly\"]\n    df = pd.DataFrame({\"time\": data[\"time\"], \"temp_C\": data[\"temperature_2m\"]})\n    df[\"time\"] = pd.to_datetime(df[\"time\"])\n    return df\n\n\n\nUsing a Theme for an External Stylesheet\n![](images/externalstyle.png)\n\nhttps://www.dash-bootstrap-components.com/docs/themes/explorer/\nUse Ctrl + I to inspect and select a class or style you would like to apply.\n\n\n\nApplying Classes from the Theme\n\nA top bar (navbar) is built using a Div as the container.\nInside the navbar, a large heading displays Open-Meteo Dashboard in white text.\nA smaller subtitle follows, showing Public API ‚Äì Multi-column layout in white text.\nThe navbar itself uses Bootstrap classes to style it with:\na dark background,\nwhite text suitable for dark themes,\nextra padding on the sides,\nand spacing below to separate it from the rest of the page.\n\n\n# ---------- Dash App ----------\napp = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\napp.title = \"Open-Meteo Dashboard\"\n\n# Top bar\nnavbar = html.Div(\n    [\n        html.H3(\"Open-Meteo Dashboard\", className=\"text-white\"),\n        html.Span(\"Public API - Multi-column layout\", className=\"text-white\"),\n    ],\n    className=\"navbar navbar-dark bg-dark mb-4 px-3\"\n)\n\n\n\nCSS: Using ID‚Äôs vs Classes\n\nIn a multipage Dash app, a single external stylesheet in assets/ is best because it centralizes all styles, ensures consistent look-and-feel across pages, and keeps page files clean‚Äîchange the CSS once and every page updates automatically.\nBonus benefits: no duplicated inline styles, faster iteration and theming, browser caching for performance, and clear separation of concerns (layout in Python, styling in CSS).\nID (id)\n\nPurpose: identifies one unique element on a page; in Dash it‚Äôs also used to wire callbacks.\nCSS selector: #my-id (matches id=‚Äúmy-id‚Äù).\nSpecificity: higher than a class (wins conflicts).\n\nClass (class)\n\nPurpose: labels elements for reusable styling; can be applied to many elements.\nCSS selector: .btn-strong (matches class=‚Äúbtn-strong‚Äù)\nSpecificity: lower than an ID.\n\nID selectors (#‚Ä¶) are more specific than class selectors (‚Ä¶.). Prefer classes for reusable styles; reserve IDs for unique elements or overrides.\n\n\n\nSetting the Controls\n\n# Controls (left column)\ncontrols = dbc.Card([\n        dbc.CardHeader(\"Controls\"),\n        dbc.CardBody(\n            [\n                dbc.Label(\"City\"),\n                dcc.Dropdown(\n                    id=\"city-dd\",\n                    options=[{\"label\": k, \"value\": k} for k in CITY_COORDS.keys()],\n                    value=\"Williamsburg\",\n                    clearable=False,\n                ),\n                html.Br(),\n                dbc.Button(\"Refresh\", id=\"refresh\", n_clicks=0, className=\"w-100\"),\n                html.Hr(),\n                html.Small(\n                    \"Data source: open-meteo.com (no API key required).\",\n                    className=\"text-muted\",\n                ),\n            ]\n        ),\n    ],className=\"mb-3\",)\n\n\nThis code builds a tidy ‚ÄúControls‚Äù panel‚Äîcity selector and refresh button‚Äîwith Bootstrap spacing/utilities and IDs ready for your Dash callbacks.\n\nCreates a ‚ÄúControls‚Äù panel using a card layout: a titled header with the interactive elements grouped in the body for clarity.\nPresents a primary input via a labeled dropdown so the user can pick from a predefined list (with a sensible default to avoid empty states).\n\n‚Äúlabel‚Äù ‚Üí what the user sees in the dropdown\n‚Äúvalue‚Äù ‚Üí the actual value passed into callbacks\n\nProvides an explicit action with a prominent, full-width button that the user clicks to (re)run whatever update/refresh your callbacks perform.\nUses simple spacing elements (line break and divider) to separate inputs from helper text and keep the panel readable.\nShows lightweight helper text (e.g., attribution or instructions) in a muted, smaller style to de-emphasize it while keeping it visible.\nDesigned for callback wiring: the dropdown supplies the selection; the button acts as the trigger; the card is easy to place as a left column in a responsive grid.\nFollows Bootstrap conventions for consistent styling, spacing, and accessibility (clear label, large click target, predictable layout).\n\n\n\n\nSetting Top Row and Middle Column\n\n# KPI cards (top row center/right)\ndef kpi_card(title, id_):\n    return dbc.Card(\n        dbc.CardBody(\n            [\n                html.H6(title, className=\"text-muted mb-1\"),\n                html.H3(id=id_, className=\"mb-0\"),\n            ]\n        ),\n        className=\"h-100\",\n    )\n\nkpi_row = dbc.Row(\n    [\n        dbc.Col(kpi_card(\"Current Temp (¬∞C)\", \"kpi-now\"), md=4),\n        dbc.Col(kpi_card(\"Min (¬∞C/48h)\", \"kpi-min\"), md=4),\n        dbc.Col(kpi_card(\"Max (¬∞C/48h)\", \"kpi-max\"), md=4),\n    ],\n    className=\"g-3 mb-3\",\n)\n\n# Chart (middle column)\nchart_card = dbc.Card(\n    [\n        dbc.CardHeader(\"Hourly Temperature (next 48h)\"),\n        dbc.CardBody(dcc.Graph(id=\"temp-chart\", config={\"displayModeBar\": False})),\n    ]\n)\n\n\nLines 3‚Äì12 ‚Äî kpi_card function\n\nA helper function that creates a Bootstrap Card for displaying Key Performance Indicators (KPIs).\nTakes two parameters:\n\ntitle: The label for the KPI (e.g., ‚ÄúCurrent Temp (¬∞C)‚Äù).\nid_: The HTML id for the numeric value so it can be updated dynamically in callbacks.\n\n\nThe card body contains:\n\nAn html.H6 for the title (muted text, small bottom margin).\nAn html.H3 for the actual KPI value placeholder (no bottom margin).\nclassName=‚Äúh-100‚Äù ensures the card fills the column height.\n\nLines 14‚Äì21 ‚Äî kpi_row\n\nCreates a Bootstrap row with three columns, each holding one KPI card:\n\nCurrent temperature (id=‚Äúkpi-now‚Äù).\nMinimum temperature over 48h (id=‚Äúkpi-min‚Äù).\nMaximum temperature over 48h (id=‚Äúkpi-max‚Äù).\n\nmd=4 means each column takes 4/12ths of the width on medium+ screens.\nclassName=‚Äúg-3 mb-3‚Äù adds spacing between columns (g-3) and bottom margin (mb-3).\n\nLines 24‚Äì29 ‚Äî chart_card\n\nCreates a Bootstrap card for the hourly temperature chart.\nThe header is ‚ÄúHourly Temperature (next 48h)‚Äù.\nThe body contains a Dash Graph (dcc.Graph) with:\n\nid=‚Äútemp-chart‚Äù for callbacks.\nconfig={‚ÄúdisplayModeBar‚Äù: False} to hide the plotly toolbar.\n\n\n\n\n\nDefining the App.layout\n\n# Stats table (right column)\ntable_card = dbc.Card(\n    [\n        dbc.CardHeader(\"Summary Stats\"),\n        dbc.CardBody(html.Div(id=\"stats-table\")),\n    ]\n)\n\n# ---------- Layout: Multi-column grid ----------\napp.layout = dbc.Container(\n    [\n        navbar,\n        dbc.Row(\n            [\n                # Left: controls (md=3)\n                dbc.Col(controls, md=3),\n                # Middle: KPIs + chart (md=6)\n                dbc.Col([kpi_row, chart_card], md=6),\n                # Right: stats table (md=3)\n                dbc.Col(table_card, md=3),\n            ],\n            className=\"g-3\",\n        ),\n        html.Footer(\n            html.Small(\n                \"Built with Dash + dash-bootstrap-components ‚Ä¢ Layout uses Row/Col grid\",\n                className=\"text-muted\",\n            ),\n            className=\"mt-4\",\n        ),\n    ],\n    fluid=True,\n)\n\n\nLines 3‚Äì8 ‚Äî table_card\n\nCreates a Bootstrap Card to display summary statistics.\nCardHeader(‚ÄúSummary Stats‚Äù) is the title.\nCardBody contains a Div with id=‚Äústats-table‚Äù so it can be populated dynamically via a callback.\n\nLines 11‚Äì35 ‚Äî app.layout\n\nThe main page layout wrapped in a dbc.Container with fluid=True so it uses the full screen width.\nFirst element inside: navbar (the top navigation bar defined earlier).\nMain row (dbc.Row) divided into three columns:\nLeft column (md=3) ‚Üí contains the controls card.\nMiddle column (md=6) ‚Üí contains the KPI row (kpi_row) and the chart card (chart_card) stacked vertically.\nRight column (md=3) ‚Üí contains the table_card for summary stats.\nclassName=‚Äúg-3‚Äù on the row adds consistent gutter spacing between columns.\n\nLines 26‚Äì30 ‚Äî Footer\n\nAdds a small, muted text footer that says:\n‚ÄúBuilt with Dash + dash-bootstrap-components ‚Ä¢ Layout uses Row/Col grid‚Äù\nclassName=‚Äúmt-4‚Äù adds margin above the footer for spacing.\n\n\n\n\nCallbacks and Chart\n\n# ---------- Callbacks ----------\n@app.callback(\n    [\n        Output(\"temp-chart\", \"figure\"),\n        Output(\"kpi-now\", \"children\"),\n        Output(\"kpi-min\", \"children\"),\n        Output(\"kpi-max\", \"children\"),\n        Output(\"stats-table\", \"children\"),\n    ],\n    [Input(\"city-dd\", \"value\"), Input(\"refresh\", \"n_clicks\")],\n)\ndef update(city, _):\n    lat, lon = CITY_COORDS[city]\n    df = fetch_hourly_temp(lat, lon)\n\n    # KPIs\n    now = df.iloc[0][\"temp_C\"]\n    tmin = df[\"temp_C\"].min()\n    tmax = df[\"temp_C\"].max()\n\n    # Chart\n    fig = px.line(df, x=\"time\", y=\"temp_C\", markers=True, title=None)\n    fig.update_layout(margin=dict(l=10, r=10, t=10, b=10), yaxis_title=\"¬∞C\", xaxis_title=\"Time\")\n\n\nLines 3‚Äì10 ‚Äî Callback definition\n@app.callback([‚Ä¶], [‚Ä¶]) defines a Dash callback with five outputs:\n\nThe figure for the temperature chart (‚Äútemp-chart‚Äù).\nThe value text for current temp KPI (‚Äúkpi-now‚Äù).\nThe value text for min temp KPI (‚Äúkpi-min‚Äù).\nThe value text for max temp KPI (‚Äúkpi-max‚Äù).\nThe HTML for the stats table (‚Äústats-table‚Äù).\n\nInputs are:\n\nThe selected city from the dropdown (‚Äúcity-dd‚Äù value).\nThe refresh button click count (‚Äúrefresh‚Äù n_clicks).\n\nLines 12‚Äì13 ‚Äî Get city coordinates & data\n\nLooks up the latitude/longitude for the chosen city from CITY_COORDS.\nCalls fetch_hourly_temp(lat, lon) to get hourly temperature data as a DataFrame (df).\n\nLines 16‚Äì18 ‚Äî KPI values\n\nnow: The current temperature (first row in ‚Äútemp_C‚Äù column).\ntmin: The minimum temperature over the dataset.\ntmax: The maximum temperature over the dataset.\n\nLines 21‚Äì22 ‚Äî Chart creation\n\nUses plotly.express.line to plot ‚Äútemp_C‚Äù vs ‚Äútime‚Äù, with markers and no title.\nAdjusts margins and axis labels.\n\n\n\n\nSummary and Return\n\n# Stats table\n    summary = (\n        df.assign(Date=df[\"time\"].dt.date)\n        .groupby(\"Date\")[\"temp_C\"]\n        .agg([\"min\", \"max\", \"mean\"])\n        .round(1)\n        .rename(columns={\"min\": \"Min ¬∞C\", \"max\": \"Max ¬∞C\", \"mean\": \"Avg ¬∞C\"})\n        .reset_index()\n    )\n    table = dbc.Table.from_dataframe(summary, striped=True, bordered=False, hover=True)\n\n    fmt = lambda x: f\"{x:.1f}\"\n    return fig, fmt(now), fmt(tmin), fmt(tmax), table\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\n\nLines 1-9‚Äî Stats table creation\n\nCreates a daily summary table by:\n\nExtracting the date from ‚Äútime‚Äù.\nGrouping by ‚ÄúDate‚Äù.\nAggregating min, max, and mean temperatures.\nRounding values to 1 decimal place.\nRenaming columns for display.\nResetting the index.\n\nConverts this DataFrame into a Bootstrap table (dbc.Table.from_dataframe) with striped=True and hover=True.\n\nLine 12 ‚Äî Formatting function\n\nfmt is a lambda function that formats a number to 1 decimal place with f‚Äù{x:.1f}‚Äú.\n\nlambda x: ‚Üí declares a tiny function that takes one argument, x.\nf‚Äù{x:.1f}‚Äù ‚Üí returns a formatted string showing x with one decimal place.\n\n\nLine 13‚Äî Callback return values\n\nThe chart (fig).\nFormatted current temperature.\nFormatted min temp.\nFormatted max temp.\nThe stats table.",
    "crumbs": [
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Creating a Grid Layout in Dash</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chapters 3 and 4 from Ravindran, Anton. Will AI Dictate the Future? From Successful Leaders and Managers from Around the World, Marshall Cavendish International (Asia) Private Limited, 2022. ProQuest Ebook Central, Retrieved from https://ebookcentral.proquest.com/lib/cwm/detail.action?docID=29354182\n\nChapters 1-4 from Weber, W., & Zwingmann, T. (2024). Augmented analytics. O‚ÄôReilly Media, Inc.¬†Retrieved from https://learning.oreilly.com/library/view/augmented-analytics/9781098151713/\nSchmidt, A., V√§√§n√§nen, K., Goyal, T., Kristensson, P. O., Peters, A., Mueller, S., Williamson, J. R., & Wilson, M. L. (Eds.). (2023). Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery. https://doi.org/10.1145/3544548 Additional Reading Material:\nWilke, C. O. (2019). Fundamentals of data visualization. O‚ÄôReilly Media. ISBN: 9781492031086.Retrieved from https://learning.oreilly.com/library/view/fundamentals-of-data/9781492031079/\nDabbas, E. (2021). Interactive dashboards and data apps with Plotly and Dash. Packt Publishing. ISBN 9781800568914. Retrieved from https://learning.oreilly.com/library/view/interactive-dashboards-and/9781800568914/",
    "crumbs": [
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "makingcallbacks.html#callbacks",
    "href": "makingcallbacks.html#callbacks",
    "title": "Writing Callbacks and Accessing API‚Äôs",
    "section": "",
    "text": "A callback function in Python is a function that is automatically executed (‚Äúcalled back‚Äù) in response to a specific event or change.\nIn Dash (and similar frameworks), callback functions link inputs and outputs ‚Äî when an input component‚Äôs property changes (for example, a dropdown selection or slider value), the callback function runs automatically to update the output component‚Äôs property (such as a graph or text display).\nThese functions act as the ‚Äúglue‚Äù between user interaction and dynamic updates in an app.\nExample (conceptually):\n\n‚ÄúIf the user changes the dropdown, automatically run the callback function to update the graph.‚Äù\n\n\n\n\nFlow:\n\nInput component‚Äôs property\nCallback function(input) -&gt; return output\nOutput component‚Äôs property\n\n\n\nCallbacks in Dash: The Basics\n\nCallback syntax\n\nfrom dash import Input, Output\n\n@app.callback(\n   Output(component_id,component_property), ##Decorator\n   Input(component_id,component_property) ##Decorator\n)\ndef function_name(input_object):    ##Function\n   ''''''                             ## body of the function\n   return output_object             ##End of the function\n\n\nIn Dash, a callback is a Python function automatically triggered when an Input property changes, updating one or more Output properties in your app.\n\nThe @app.callback decorator links Input(s) to Output(s). This special line tells Dash which component to update and what triggers the update.\nThe Inputs describes which component‚Äôs property will trigger the function when it changes.\nThe Outputs describe where the result will be sent (which component and which property)\ncomponent_id refers either to the id property or the variable name of the component.\ncomponent_property = one of the properties of the component (e.g., children of the html.Div figure of a dcc.Graph).\n\n\n\n\nThe Function\n\n\n\n\n\n\nThe function arguments match the order of the Inputs. The return value(s) match the order of the Outputs.\nfunction_name(input_object) receives the value from the Input.\n\nInside the function, you process that value and create the desired output.\nreturn output_object sends that processed output back to the Output you specified.\n\n\n\n    Callback syntax\n\n    from dash import Input, Output\n\n    @app.callback(\n       Output(component_id,component_property), ##Decorator\n       Input(component_id,component_property) ##Decorator\n    )\n    def function_name(input_object):    ##Function\n       ''''''                             ## body of the function\n       return output_object             ##End of the function\n    )\n\n\n\nMultiple Inputs and Outputs\n\nMultiple Inputs:\n\nYou can pass several Input() objects to a single callback.\nThe function will run whenever any of those inputs change.\n\nMultiple Outputs:\n\nReturn a tuple/list with one value for each Output() in the order declared.\n\n\n\n@app.callback(\n   [Output('graph','figure'),\n   Output('summary','children')],\n   [Input('dropdown','value'),\n   Input('slider','value')]\n)\n\ndef update_graph(selected_category, slider_value):\n   fig=make_figure(selected_category, slider_value)\n   text= f\"Selected: {selected_category}, Value: {slider_value}\"\n   return fig, text\n\n\n\nUsing dcc\n\nWhat is dcc?\n\ndcc is short for dash.dcc, which stands for Dash Core Components.\nIt‚Äôs a module in Dash that provides interactive UI elements like input boxes, sliders, dropdowns, graphs, etc.\n\n\n\n\nCallback Example\n\n\n# callback_example.py\nfrom dash import Dash, html, dcc, Input, Output, callback\n\napp = Dash(__name__)\napp.title = \"Callback Example\"\n\napp.layout = html.Div(\n    style={\"maxWidth\": 900, \"margin\": \"40px auto\", \"fontFamily\": \"Georgia, serif\"},\n    children=[\n        html.H1(\"Callback Example\"),\n        html.Ul([\n            html.Li([\"Input box‚Äôs \", html.Code(\"value\"), \" property updates output text\"])\n        ]),\n        dcc.Input(\n            id=\"text-in\",\n            type=\"text\",\n            placeholder=\"type here‚Ä¶\",\n            style={\"width\": \"100%\", \"fontSize\": \"48px\", \"padding\": \"8px\"},\n        ),\n        html.Div(id=\"text-out\", style={\"fontSize\": \"64px\", \"marginTop\": \"20px\"}),\n    ],\n)\n\n@callback(Output(component_id=\"text-out\", component_property=\"children\"),\n          Input(component_id=\"text-in\", component_property=\"value\"))\ndef show_text(value):\n    return f\"Text: {value or ''}\"\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\n\n\ndcc.Input\n\nWhat is dcc.Input?\n\ndcc.Input is a Dash Core Component that creates an HTML input box inside your app.\nIt lets the user type in text, numbers, or other data.\nThe key property of dcc.Input is value ‚Äî this holds whatever the user typed.\n\nYou can connect the value to a callback so that your app reacts instantly when the user types something.\n\n\napp.layout = html.Div(\n    style={\"maxWidth\": 900, \"margin\": \"40px auto\", \"fontFamily\": \"Georgia, serif\"},\n    children=[\n        html.H1(\"Callback Example\"),\n        html.Ul([\n            html.Li([\"Input box‚Äôs \", html.Code(\"value\"), \" property updates output text\"])\n        ]),\n        dcc.Input(\n            id=\"text-in\",\n            type=\"text\",\n            placeholder=\"type here‚Ä¶\",\n            style={\"width\": \"100%\", \"fontSize\": \"48px\", \"padding\": \"8px\"},\n        ),\n        html.Div(id=\"text-out\", style={\"fontSize\": \"64px\", \"marginTop\": \"20px\"}),\n    ],\n)\n\n\nNote, in Dash (and Plotly‚Äôs underlying dash.html components), children is the default first argument, so you can omit ‚Äúchildren=‚Äú if you want\n\n\n\nConnecting the dcc to the Callback\n\n@callback(Output(component_id=\"text-out\", component_property=\"children\"),\n          Input(component_id=\"text-in\", component_property=\"value\"))\ndef show_text(value):\n    return f\"Text: {value or ''}\"\n\n\n@callback(‚Ä¶)\n\nThis is a Dash decorator that links components together.\nIt says: ‚ÄúWhen the input changes, run the function below, and send its return value to the output.‚Äù\n\nOutput(‚Äútext-out‚Äù, ‚Äúchildren‚Äù)\n\nOutput specifies where the result goes.\n‚Äútext-out‚Äù refers to the ID of the component you want to update (in this case, an html.Div).\n‚Äúchildren‚Äù refers to the property of that component you want to change (the inside text of the Div).\n\nInput(‚Äútext-in‚Äù, ‚Äúvalue‚Äù)\n\nInput specifies what triggers the function.\n‚Äútext-in‚Äù refers to the ID of the component to watch (here, a dcc.Input box).\n‚Äúvalue‚Äù refers to the property to monitor (what the user typed in).\n\nThe function show_text(value)\n\nThis function receives the input value from the dcc.Input box.\nIt returns a string that will replace the children of ‚Äútext-out‚Äù.\nvalue or ‚Äô‚Äô means: if value exists, use it, otherwise, if value is none or empty, use an empty string to avoid errors.\n\nNote, you don‚Äôt have to say ‚Äúcomponent_id =‚Äú and ‚Äúcomponent_property =‚Äú if you are using the same order because the parameters are listed first and second.\n\n\n\nMaking a Callback Using NASA‚Äôs API\n\nOur goal is to build a Dash app that connects to NASA‚Äôs Astronomy Picture of the Day (APOD) API so the user can pick a date and instantly see the image or video NASA published for that day, along with its title and description.\n\nimport datetime as dt ‚Äì built-in Python module for working with dates/times; as dt is just a short alias.\nimport requests ‚Äì library for making HTTP requests to APIs.\nfrom dash import we imported core Dash classes\nAPI_KEY is NASA‚Äôs public API key (‚ÄúDEMO_KEY‚Äù).\nAPOD_URL refers to NASA Astronomy Picture of the Day endpoint.\nMIN_DATE ‚Äì first APOD date (June 16, 1995).\nTODAY ‚Äì today‚Äôs date.\n\n\n\n\nimport datetime as dt\nimport requests\nfrom dash import Dash, html, dcc, Input, Output, exceptions\n\nAPI_KEY= \"DEMO_KEY\"  # Replace with your own if you have one\nAPOD_URL= \"https://api.nasa.gov/planetary/apod\"\nMIN_DATE=dt.date(1995,6,16)\nTODAY= dt.date.today()\n\n\n\nSetting the Layout\n\nIn Dash, the layout is the blueprint of your app‚Äôs user interface ‚Äî it defines what components appear on the page and how they‚Äôre arranged.\n\n\n\nThe layout is static in structure but can hold placeholders (components with ids) that get updated dynamically by callbacks.\nYou can nest components, style them, and set their initial properties here ‚Äî the visual skeleton of your app.\n\nhtml.Div(‚Ä¶) ‚Äì main container for the app layout with max width, centered on the page, and padding.\nhtml.H1(‚Ä¶) ‚Äì page title.\ndcc.DatePickerSingle(‚Ä¶) ‚Äì lets the user select a date between MIN_DATE and TODAY; defaults to today‚Äôs date.\ndcc.Loading(‚Ä¶) ‚Äì shows a spinner while the media content is loading; wraps a Div (id=‚Äúmedia‚Äù) where the NASA image or video will appear.\nhtml.Div(id=‚Äúcaption‚Äù) ‚Äì placeholder for the APOD‚Äôs text description, styled with spacing and readable line height.\n\n\n\napp = Dash(__name__)\napp.title = \"NASA APOD\"\n\napp.layout = html.Div(\n    style={\"margin\": \"0 auto\", \"padding\":20},\n    children=[\n        html.H1(\"NASA Astronomy Picture of the Day\"),\n        dcc.DatePickerSingle(\n            id=\"apod-date\",\n            min_date_allowed=MIN_DATE,\n            max_date_allowed=TODAY,\n            date=TODAY,\n            display_format=\"YYYY-MM-DD\",\n            clearable=False,\n        ),\n        dcc.Loading(html.Div(id=\"media\", style={\"marginTop\": 16, \n                                                \"textAlign\": \"center\"})),\n        html.Div(id=\"caption\"),\n    ],\n)\n\n\n\nMaking the Callback\n\n@app.callback(‚Ä¶) if a decorator that tells Dash to run the function below it whenever specified Inputs change, and to send the function‚Äôs return values to specified Outputs.\nThere are Two Ouputs\n\n[Output(‚Äúmedia‚Äù, ‚Äúchildren‚Äù), Output(‚Äúcaption‚Äù, ‚Äúchildren‚Äù)]\nUpdate the contents (children) of the component with id=‚Äúmedia‚Äù (the image/video placeholder).\nUpdate the contents (children) of the component with id=‚Äúcaption‚Äù (the text description).\n\nInput(‚Äúapod-date‚Äù, ‚Äúdate‚Äù) ‚Äì the function will run whenever the date property of the component with id=‚Äúapod-date‚Äù (the date picker) changes.\nIn short, this callback listens for a date change in the date picker and updates both the media display and the caption with the NASA APOD content for that date.\n\n\n@app.callback(\n    [Output(\"media\", \"children\"), Output(\"caption\", \"children\")],\n    Input(\"apod-date\", \"date\"),\n)\n\n\n\nshow(apod) function\n\ndef show_apod(date_str):\n    if not date_str:\n        raise exceptions.PreventUpdate\n\n    try:\n        date_obj = dt.date.fromisoformat(date_str[:10])\n    except Exception:\n        return \"Invalid date.\", \"\"\n\n    params = {\"api_key\": API_KEY, \"date\": date_obj.isoformat()}\n    try:\n        r = requests.get(APOD_URL, params=params, timeout=10)\n        r.raise_for_status()\n        data = r.json()\n    except requests.RequestException as e:\n        return f\"API error: {e}\", \"\"\n\n\nOverall, the show_apod function takes the user-selected date from the date picker, validates it, calls NASA‚Äôs Astronomy Picture of the Day API for that date, and returns either the APOD data (image/video and caption) or an error message if the date is invalid or the API request fails.\n\ndef show_apod(date_str): ‚Äì Defines the callback function, which will run when the date picker changes and receives the selected date as a string (date_str).\nif not date_str: raise exceptions.PreventUpdate ‚Äì If no date is provided, stop the callback without changing anything on the page.\ntry: date_obj = dt.date.fromisoformat(date_str[:10]) ‚Äì Tries to convert the incoming date string (YYYY-MM-DD) into a Python date object. The :10 is because of the size of the date given the date format.\nexcept Exception: ‚Äì If conversion fails, return ‚ÄúInvalid date.‚Äù for the media section and an empty string for the caption.\nparams = {‚Äúapi_key‚Äù: API_KEY, ‚Äúdate‚Äù: date_obj.isoformat()} ‚Äì Creates the query parameters for the NASA APOD API request: the API key and the selected date in YYYY-MM-DD format.\ntry: r = requests.get(APOD_URL, params=params, timeout=10) ‚Äì Sends a GET request to the NASA API with those parameters, allowing up to 10 seconds before timing out.\nr.raise_for_status() ‚Äì Raises an error if the HTTP response status code isn‚Äôt 200 (OK).\ndata = r.json() ‚Äì Parses the API response JSON into a Python dictionary.\nexcept requests.RequestException as e: ‚Äì If any network or request error occurs, return an error message for the media section and leave the caption empty.\n\n\n\n media_type = data.get(\"media_type\", \"\")\n    url = data.get(\"url\", \"\")\n    title = data.get(\"title\", \"APOD\")\n    explanation = data.get(\"explanation\", \"\")\n\n    if media_type == \"image\":\n        media = html.Img(src=url, style={\"maxWidth\": \"100%\", \"borderRadius\": 8}, alt=title)\n    elif media_type == \"video\":\n        media = html.Iframe(src=url, style={\"width\": \"100%\", \"height\": 500, \"border\": 0})\n    else:\n        media = html.Div(\"Unsupported media type.\")\n\n    header = html.H3(f\"{title} ‚Äî {date_obj.isoformat()}\", style={\"marginBottom\": 8})\n    return html.Div([header, media]), explanation\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\n\nExtracts data from the API response using .get() so a default value is returned if the key is missing:\nmedia_type refers to ‚Äúimage‚Äù or ‚Äúvideo‚Äù (empty string if missing).\nurl will link to the media.\ntitle will link to the APOD title (defaults to ‚ÄúAPOD‚Äù).\nexplanation refers to the description text (empty string if missing).\nThe next set chooses how to display the media based on media_type:\n\nIf ‚Äúimage‚Äú, it creates an html.Img component with the URL and styling.\nIf ‚Äúvideo‚Äú, then it creates an html.Iframe to embed the video.\nOtherwise it shows a Div saying the type is unsupported.\n\nCreates a header (html.H3) with the title and selected date.\nReturns two things for the callback‚Äôs Outputs:\n\nA Div containing the header and media.\nThe explanation text for the caption section.",
    "crumbs": [
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Writing Callbacks and Accessing API's</span>"
    ]
  },
  {
    "objectID": "introdash.html#dash",
    "href": "introdash.html#dash",
    "title": "Intro to Dash",
    "section": "",
    "text": "Dash is a Python library for building interactive web applications. Developed by Plotly, the company behind the Plotly visualization library, Dash allows users to create dynamic, data-driven dashboards entirely in Python. It is built on top of Plotly for visualizations, Flask for managing the web server, and React for the front-end interface.\n\n\nDash is designed for data analysts and data scientists with a basic knowledge of Python‚Äîno need for advanced web-development skills.\n\nIt‚Äôs ideal for creating visualizations and dashboards that can be easily shared with customers, executives, and other stakeholders.\n\n\n\nDash layout is built on 2 things\n\nDcc: Dash Core Components\nHTML : Dash HTML Components\n\nInteractive features: callback functions\n\n\nExploring Visualizations\n\nDash vs.¬†Matplotlib vs.¬†Plotly\nUse Matplotlib when you want quick, static visualizations (e.g., for academic papers or PDFs).\nUse Plotly for interactive, browser-based graphs without building full dashboards.\nUse Dash when you want to build full web apps or dashboards with charts, dropdowns, and user controls‚Äîideal for business analytics tools or interactive data portals\n\n\n\n\nDash: Static and Dynamic Content\n\nDash can handle static content: Files that do not change on the server side ‚Äî e.g., images, PDFs, CSS, JavaScript.\nDash can handle dynamic content: Data or components that change depending on user interaction, database queries, API calls, or real-time streaming.\nHow Dash handles it:\n\nCallbacks: Functions decorated with @app.callback() listen for changes in user inputs and update outputs dynamically.\nYou can generate HTML dynamically in Python ‚Äî Dash doesn‚Äôt pre-render your pages, it builds them at runtime.\nData sources:\n\nAPIs (fetch fresh data in callbacks)\nDatabases (query and return results dynamically)\nLive data streams (e.g., WebSocket integrations, or polling APIs with dcc.Interval)\n\n\n\n\n\nCreating your First Dashboard\n\nImports the Dash framework components\n\nDash is the main class used to initialize your web app\nhtml lets you create HTML elements like\n, etc., directly in Python\n\n\n\nfrom dash import Dash, html \n\n\nDash() initializes your web application\n\n\napp=Dash()\n\n\nRemember that there are 2 main components for dash app Layout and Callbacks\nTo Define the layout of your app we add html.methods(‚Äú‚Äú)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)\n\n\nname == ‚Äòmain‚Äô ensures the server starts only when you run this file directly\napp.run(‚Ä¶) starts the local server\n\ndebug=True enables hot reloading, so you can see changes without restarting the server\n\n\n\n\nMy First Dashboard\n\n\n\n\n\n\nWhen you run the code, it will start a local server and you can access the app in your web browser because debug is set to TRUE\n\nNotice that it says that Dash is running on http://127.0.0.1:8050/ in the terminal after you run the code.\n\nYou can also use http://localhost:8050/\n\nYou will see a debug menu on the browser.\n\nPush control + C in the terminal to stop the server when you are done testing the app.\nWhen putting the apps to production, set debug=False to hide the debug menu and improves security and performance\n\n\n\nAdjust the layout to include a title and a paragraph\n\nThere are Python functions from the dash.html module that mimic HTML elements. They are used to build the structure of your web page in a Dash app.\n\n\nfrom dash import Dash, html\n\n#Create the app\napp = Dash(__name__)\napp.title = \"My First Dash App\"\n\n#Define the layout\napp.layout = html.Div([\n   html.H1(\"Hello Dash!\"),\n   html.P(\"This is a simple dashboard.\")\n   \n#Run the app\nif __name__ == \"__main__\":\n   app.run(debug=True)\n])\n\n\n\n\n\n\n\nApp.title sets the browser tab title (like the text you see in the tab at the top of Chrome, Firefox, etc.). It‚Äôs the HTML &lt;title&gt; tag behind the scenes.\n\n\nhtml.Div() is a container element (&lt;div&gt; tag) to hold other elements used to group components like text, headings, graphs, etc.\n\n\nhtml.H1() creates a large heading (&lt;h1&gt; tag), used for titles or main headlines\n\n\nhtml.P() creates a paragraph (&lt;p&gt; tag), used for regular body text\n\n\n\nHTML Components Overview\n\nDash Components has a hierarchical of tree of components\n\nPopular Components are Dash HTML Components dash.html and\nDash Core components dash.dcc\n\n\n\n\nIntro to HTML\nHTML (HyperText Markup Language: The standard markup language for structuring Web pages.¬†\nHTML document -&gt; web browsers -&gt; multimedia web pages\n\n\n\nHTML documents contain HTML elements such as:\n\nSection Headings: h1, h2, h3, h4, h5, h6\nParagraph: p\nContent division: div\nLine Break: br\nAnchor: a ‚Äì to hyperlink to other pages.\n\n\n\n\nDash HTML Component\n\n\n\nAdding a Line Break and a Hyperlink\n\nhtml.Br() creates a line break in the layout, similar to the &lt;br&gt; tag in HTML.\n\nIt doesn‚Äôt display any text‚Äîit just moves the next element to a new line.\n\nhtml.A(‚ÄúClick here‚Äù, href=‚Äúhttps://example.com‚Äù)\n\nCreates a hyperlink.\n‚ÄúClick here‚Äù is the visible text.\nhref=‚Äúhttps://example.com‚Äù tells the browser where to go when clicked.\nWorks just like the HTML &lt;a&gt; tag.\n\n\n\napp.layout=html.Div([\n   html.H1(\"Hello Dash!\"),\n   html.P(\"This is a simple dashboard.\"),\n   html.Br(),\n   html.A(\"Click here\", href=\"https://example.com\")\n])\n\n\n\nHTML Elements\n\nIn regular HTML, tags define the structure of a web page using this pattern: &lt;tagname&gt; content &lt;/tagname&gt;\nExamples:\n\nStart tag content end tag\n&lt;p&gt; This is a paragraph &lt;/p&gt;\n&lt;h1&gt; This is a Heading 1 &lt;/h1&gt;\n\nIn Dash, you use the dash.html module to create the same HTML elements using Python syntax.\nFrom dash import html\n\n\n\n\nStyle\n\nIn Dash apps, the style parameter is used to directly apply CSS styling to a Dash component using a Python dictionary. This allows you to control the appearance (e.g., colors, spacing, fonts, borders) of components without needing a separate CSS file.\nHTML colors are located onhttps://htmlcolorcodes.com/\n\n\n\nhtml.H1(\"Hello Dash\", style={'color':'#381D5C',\n                             'fontSize': '20px',\n                             'backgroundColor':'#E898AA'})\n\n\n\n\nBorders\n\nHere are some key Dash HTML component style parameters for controlling borders, padding, and margin‚Äîall written in Python dictionary format for use in Dash:\n‚Äòborder‚Äô: Shorthand for setting all border properties (width, style, color)\n\n{‚Äòborder‚Äô: ‚Äò1px solid black‚Äô}\n\n‚ÄòborderWidth‚Äô: Sets width of the border\n\n{‚ÄòborderWidth‚Äô: ‚Äò2px‚Äô}\n\n‚ÄòborderStyle‚Äô: Sets line style (e.g., solid, dashed)\n\n{‚ÄòborderStyle‚Äô: ‚Äòdotted‚Äô}\n\n‚ÄòborderColor‚Äô: Sets color of the border\n\n{‚ÄòborderColor‚Äô: ‚Äògray‚Äô}\n\n‚ÄòborderRadius‚Äô: Rounds corners of the border\n\n{‚ÄòborderRadius‚Äô: ‚Äò10px‚Äô}\n\n\n\n\nPadding\n\nPadding refers to the space inside the element\n‚Äòpadding‚Äô: Sets padding on all sides\n‚Üí {‚Äòpadding‚Äô: ‚Äò15px‚Äô}\n‚ÄòpaddingTop‚Äô, ‚ÄòpaddingBottom‚Äô, ‚ÄòpaddingLeft‚Äô, ‚ÄòpaddingRight‚Äô: Control sides individually\n‚Üí {‚ÄòpaddingTop‚Äô: ‚Äò20px‚Äô, ‚ÄòpaddingBottom‚Äô: ‚Äò5px‚Äô}\n\n\n\nIn Python, key-value pairs in dictionaries must be separated by commas.\n\n\nhtml.P(\"This is a simple dashboard.\",\n         style={'border' : '1px solid black'})\n\n\n\n\nMargin\n\nMargin refers to the space outside the element\n‚Äòmargin‚Äô: Sets margin on all sides: {‚Äòmargin‚Äô: ‚Äò20px‚Äô}\n‚ÄòmarginTop‚Äô, ‚ÄòmarginBottom‚Äô, ‚ÄòmarginLeft‚Äô, ‚ÄòmarginRight‚Äô: Control sides individually\n{‚ÄòmarginLeft‚Äô: ‚Äòauto‚Äô, ‚ÄòmarginRight‚Äô: ‚Äòauto‚Äô} (useful for centering)\n\n\nhtml.P(\"This is a simple dashboard.\",\n         style={'border':'1px solid black',\n                'padding': '20px', 'margin': '50px'})\n\n\n\n\n\n\n\n\nCSS in Dash: External Stylesheets\n\nTells Dash to load extra CSS files in addition to the default styles\nYou can make a styles.css for the entire app\nAlso accepts a list of URLs or dictionaries pointing to CSS resources\nHow it works\n\nThe browser loads the CSS when the app starts\nStyles from these files apply to all app components\n\nIf you make an assets folder within your working directory, and drop a .css file in that, python will automatically use it with the dash app.\n\n\n\nGive General Stylings for the Body\n\nbody,html{\n   padding: 40px; /* increased padding around context */\n   background: #dfe9e1 /*light gray background */\n   color: #1f1e1e; /*dark text color */\n   font: 16px Arial, sans-serif; /*increased base font size */\n}\n\n\nChange the Paragraph Background Color\np{background-color: #d4cece;}\n\n\n\nGive Stylings to the Hyperlink\n\n\n\n\n\n/* Rounded, colored hyperlink box */\na{\n   display: inline-block;\n   padding: 25px; /*increased padding inside box */\n   border-radius: 9999px;         /*pill shape */\n   background-color: #3b82f6;     /*blue*/\n   color: #ffffff;                /*white text*/\n   text-decoration: none;   /*remove underline*/\n   font-size: 24px;     /*larger text */\n} \n\nNotice comments in css are made with /* and */\nThis makes the hyperlink rounded\n\n\n\nAdding a Change in Style on Hover\n/* Hover style change */\na:hover{\n   background-color: #474d59;   /*darker gray on hover */\n}\n\n:link ‚Üí default style of an unvisited link.\n:visited ‚Üí style for a link the user has already clicked (and the browser remembers in history).\n:hover ‚Üí when the pointer (mouse, stylus, etc.) is over the element.\n:active ‚Üí the moment the element is being clicked (mouse pressed down but not released yet)",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Intro to Dash</span>"
    ]
  }
]